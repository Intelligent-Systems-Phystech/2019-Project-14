{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from deepSymmetry.src import load_data\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from se3cnn import SE3Convolution, SE3Dropout, SE3BNConvolution\n",
    "from se3cnn.blocks import GatedBlock\n",
    "from se3cnn.non_linearities import ScalarActivation\n",
    "from se3cnn.dropout import SE3Dropout\n",
    "from se3cnn import kernel\n",
    "from se3cnn.filter import low_pass_filter\n",
    "\n",
    "from tensorflow.python.framework import dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/dataReady0\n",
      "Extracting data/dataReady0_label\n",
      "(39785, 13824)\n"
     ]
    }
   ],
   "source": [
    "train_name = 'data/dataReady0'\n",
    "train_set = load_data.read_data_set(train_name, dtype=dtypes.float16, seed = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_custom_loss(output, target):\n",
    "    order_out = output[:, 0 : NUM_CLASSES]\n",
    "    order_target = target[:, 0 : 1].type(torch.LongTensor).squeeze_()\n",
    "    axis_out = output[:, NUM_CLASSES : NUM_CLASSES + 6]\n",
    "    axis_target = target[:, 1 : 7]\n",
    "\n",
    "    loss = 0.5 * nn.CrossEntropyLoss()(order_out, order_target) + nn.MSELoss(reduction='sum')(axis_out, axis_target)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residential network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResEquiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = SE3BNConvolution(repr_in_1, repr_out_1, size=4)\n",
    "        self.pool1 = nn.AvgPool3d(pool_size, pool_stride)\n",
    "        self.conv2 = SE3BNConvolution(repr_in_2, repr_out_2, size=4)\n",
    "        self.pool2 = nn.AvgPool3d(pool_size, pool_stride)\n",
    "        \n",
    "        self.lin1 = nn.Linear(n_input_1, n_output_1)\n",
    "        self.drop1 = nn.Dropout(prob)\n",
    "        self.lin2 = nn.Linear(n_output_1, n_output_2)\n",
    "        self.drop2 = nn.Dropout(prob)\n",
    "        self.lin3 = nn.Linear(n_output_2, NUM_CLASSES+6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        prev_layer = x.expand(100,200,24,24,24)\n",
    "        x = self.pool1(self.conv1(x))\n",
    "        x = torch.cat([torch.zeros(100,200,7,10,10), x, torch.zeros(100,200,7,10,10)], 2)\n",
    "        x = torch.cat([torch.zeros(100,200,24,7,10), x, torch.zeros(100,200,24,7,10)], 3)\n",
    "        x = torch.cat([torch.zeros(100,200,24,24,7), x, torch.zeros(100,200,24,24,7)], 4)\n",
    "        x = torch.add(x, prev_layer)\n",
    "        x = self.pool2(self.conv2(x))\n",
    "        x = x.view(batch_size,-1) \n",
    "        x = F.leaky_relu(self.lin1(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.drop2(x)\n",
    "        return self.lin3(x)\n",
    "    \n",
    "def train(model, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate):\n",
    "    model.train()\n",
    "    flag = True\n",
    "    new_epoch = True\n",
    "    \n",
    "    if new_epoch:\n",
    "        batch_idx = 1\n",
    "        new_epoch = False\n",
    "        data, target, _ = train_set.next_batch(batch_size)\n",
    "        data = torch.from_numpy(data.reshape(batch_size,1,24,24,24)).type(torch.FloatTensor)\n",
    "        target = torch.from_numpy(target.reshape(batch_size,-1)).type(torch.FloatTensor)\n",
    "        cnt = epoch // per_epoch\n",
    "        if ((epoch+1) // per_epoch > cnt) and flag:\n",
    "            lr = 0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            lr *= decr_rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            flag = False\n",
    "        if ((epoch+1) // per_epoch <= cnt):\n",
    "            flag = True\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss_fn = nn.MSELoss(reduction='sum')\n",
    "        # loss = loss_fn(output, target)\n",
    "        loss = weighted_custom_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    while (train_set._index_in_epoch + batch_size) < train_set._num_examples:\n",
    "        batch_idx += 1\n",
    "        data, target, _ = train_set.next_batch(batch_size)\n",
    "        data = torch.from_numpy(data.reshape(batch_size,1,24,24,24)).type(torch.FloatTensor)\n",
    "        target = torch.from_numpy(target.reshape(batch_size,-1)).type(torch.FloatTensor)\n",
    "        cnt = epoch // per_epoch\n",
    "        if ((epoch+1) // per_epoch > cnt) and flag:\n",
    "            lr = 0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            lr *= decr_rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            flag = False\n",
    "        if ((epoch+1) // per_epoch <= cnt):\n",
    "            flag = True\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss_fn = nn.MSELoss(reduction='sum')\n",
    "        # loss = loss_fn(output, target)\n",
    "        loss = weighted_custom_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, train_set._num_examples,\n",
    "                100. * batch_idx / train_set._num_examples, loss.item()))\n",
    "\n",
    "def test(model, device, test_set):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_set:\n",
    "            output = model(data)\n",
    "            loss_fn = nn.MSELoss(reduction='sum')\n",
    "            test_loss += loss_fn(output, target) \n",
    "            # pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += int(torch.argmax(output) == torch.argmax(target))\n",
    "\n",
    "    test_loss /= len(test_set)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_set),\n",
    "        100. * correct / len(test_set)))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_in_1 = [(1,0)]\n",
    "repr_out_1 = [(2,0),(2,1),(2,2),(2,3),(2,4),(2,5),(2,6),(2,7),(2,8),(2,9)]\n",
    "repr_in_2 = [(2,0),(2,1),(2,2),(2,3),(2,4),(2,5),(2,6),(2,7),(2,8),(2,9)]\n",
    "repr_out_2 = [(1,0),(2,1),(2,2),(2,3)]\n",
    "size = 4\n",
    "activation = (None, F.leaky_relu)\n",
    "pool_size = 2\n",
    "pool_stride = 2\n",
    "bias = True\n",
    "\n",
    "n_input_1 = 837\n",
    "n_output_1 = 1000 \n",
    "n_output_2 = 50\n",
    "\n",
    "batch_size = 100\n",
    "prob = 0.5\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(1)\n",
    "\n",
    "model_tenth_order = ResEquiNet().to(device)\n",
    "learning_rate = 5e-3\n",
    "optimizer = torch.optim.Adam(model_tenth_order.parameters(), lr=learning_rate)\n",
    "\n",
    "per_epoch = 10\n",
    "decr_rate = 0.995\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model_tenth_order, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate)\n",
    "    # test(model_hard, device, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 0.]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.zeros(2,1,3)\n",
    "c[:,:,1] = torch.Tensor([1])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)]))\n",
    "    return torch.index_select(a, dim, order_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile(c,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.],\n",
       "         [0., 2., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 2., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 2., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 2., 0.]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(list(torch.split(c, 2, dim=1))*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.ones(2,2,3), c.expand(2,2,3), torch.ones(2,2,3)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
