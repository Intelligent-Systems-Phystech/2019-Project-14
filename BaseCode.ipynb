{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import load_data\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from se3cnn import SE3Convolution, SE3Dropout\n",
    "from se3cnn.blocks import GatedBlock\n",
    "from se3cnn.non_linearities import ScalarActivation\n",
    "from se3cnn.dropout import SE3Dropout\n",
    "from se3cnn import kernel\n",
    "from se3cnn.filter import low_pass_filter\n",
    "\n",
    "from tensorflow.python.framework import dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_1(t):\n",
    "    return torch.flip(t, (3, )).transpose(4, 3)\n",
    "\n",
    "def untransformed(n, size):\n",
    "    untransf = []\n",
    "    for i in range(n):\n",
    "        a_i = torch.zeros(1,1,size,size,size)\n",
    "        for j in range(size):\n",
    "            a_i[0,0,j,j,0] = np.random.randn()\n",
    "            a_i[0,0,j,0,j] = a_i[0,0,j,j,0]\n",
    "            a_i[0,0,0,j,j] = a_i[0,0,j,j,0]\n",
    "            \n",
    "        untransf.extend([(a_i, torch.tensor([1,1,1], dtype=torch.float32)), \n",
    "                         (rotation_1(a_i), torch.tensor([-1,1,1], dtype=torch.float32)), \n",
    "                         (rotation_1(rotation_1(a_i)), torch.tensor([-1,1,-1], dtype=torch.float32)), \n",
    "                         (rotation_1(rotation_1(rotation_1(a_i))), torch.tensor([1,1,-1], dtype=torch.float32))\n",
    "                        ])\n",
    "    return untransf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.gated = PoolGatedBlock(repr_in, repr_out, size, activation=activation, \n",
    "                                    #pool_size=pool_size, pool_stride=pool_stride, bias=bias)\n",
    "        # self.conv = nn.Conv3d(1, 2, 2, 2, 1)\n",
    "        self.conv1 = SE3Convolution(repr_in_1, repr_out_2, size=4)\n",
    "        self.pool1 = nn.AvgPool3d(pool_size, pool_stride)\n",
    "        self.conv2 = SE3Convolution(repr_in_2, repr_out_2, size=4)\n",
    "        self.pool2 = nn.AvgPool3d(pool_size, pool_stride)\n",
    "        \n",
    "        self.lin1 = nn.Linear(n_input_1, n_output_1)\n",
    "        self.drop1 = nn.Dropout(prob)\n",
    "        self.lin2 = nn.Linear(n_output_1, n_output_2)\n",
    "        self.drop2 = nn.Dropout(prob)\n",
    "        self.lin3 = nn.Linear(n_output_2, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.gated(x)\n",
    "        x = self.pool1(self.conv1(x))\n",
    "        #x = self.pool2(self.conv2(x))\n",
    "        x = x.view(batch_size,-1) # tf.reshape(x,[batchSize,-1])\n",
    "        x = F.leaky_relu(self.lin1(x))\n",
    "        # x = self.drop1(x)\n",
    "        # x = F.relu(self.lin2(x))\n",
    "        # x = self.drop2(x)\n",
    "        return self.lin2(x) #self.lin3(x)\n",
    "    \n",
    "    \n",
    "def train(model, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate):\n",
    "    model.train()\n",
    "    flag = True\n",
    "    new_epoch = True\n",
    "    print(train_set._index_in_epoch)\n",
    "    print(train_set._num_examples)\n",
    "    \n",
    "    if new_epoch:\n",
    "        batch_idx = 1\n",
    "        new_epoch = False\n",
    "        data, target, _ = train_set.next_batch(batch_size)\n",
    "        data = torch.from_numpy(data.reshape(batch_size,1,24,24,24)).type(torch.FloatTensor)\n",
    "        target = torch.from_numpy(target.reshape(batch_size,-1)).type(torch.FloatTensor)\n",
    "        cnt = epoch // per_epoch\n",
    "        if ((epoch+1) // per_epoch > cnt) and flag:\n",
    "            lr = 0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            print(lr)\n",
    "            lr *= decr_rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            flag = False\n",
    "        else:\n",
    "            flag = True\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss_fn = nn.MSELoss(reduction='sum')\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    while (train_set._index_in_epoch + batch_size) < train_set._num_examples:\n",
    "        batch_idx += 1\n",
    "        data, target, _ = train_set.next_batch(batch_size)\n",
    "        data = torch.from_numpy(data.reshape(batch_size,1,24,24,24)).type(torch.FloatTensor)\n",
    "        target = torch.from_numpy(target.reshape(batch_size,-1)).type(torch.FloatTensor)\n",
    "        cnt = epoch // per_epoch\n",
    "        if ((epoch+1) // per_epoch > cnt) and flag:\n",
    "            lr = 0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            print(lr)\n",
    "            lr *= decr_rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            flag = False\n",
    "        else:\n",
    "            flag = True\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss_fn = nn.MSELoss(reduction='sum')\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, train_set._num_examples,\n",
    "                100. * batch_idx / train_set._num_examples, loss.item()))\n",
    "\n",
    "def test(model, device, test_set):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_set:\n",
    "            # data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss_fn = nn.MSELoss(reduction='sum')\n",
    "            test_loss += loss_fn(output, target) # sum up batch loss\n",
    "            # pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += int(torch.argmax(output) == torch.argmax(target))\n",
    "\n",
    "    test_loss /= len(test_set)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_set),\n",
    "        100. * correct / len(test_set)))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_in_1 = [(1,0)]\n",
    "repr_out_1 = [(2,0),(2,1),(2,2)]\n",
    "repr_in_2 = [(2,0),(2,1),(2,2)]\n",
    "repr_out_2 = [(1,0),(2,1)]\n",
    "size = 4\n",
    "activation = (None, F.leaky_relu)\n",
    "pool_size = 2\n",
    "pool_stride = 2\n",
    "bias = True\n",
    "\n",
    "n_input_1 = 7000\n",
    "n_output_1 = 3500 \n",
    "n_output_2 = 7 \n",
    "\n",
    "batch_size = 100\n",
    "prob = 0.5\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../deepSymmetry/data/fromScripts/dataReady0\n",
      "Extracting ../deepSymmetry/data/fromScripts/dataReady0_label\n",
      "(39785, 13824)\n"
     ]
    }
   ],
   "source": [
    "train_name = '../deepSymmetry/data/fromScripts/dataReady0'\n",
    "train_set = load_data.read_data_set(train_name, dtype=dtypes.float16, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "39785\n",
      "Train Epoch: 1 [1000/39785 (0%)]\tLoss: 2721.561279\n",
      "Train Epoch: 1 [2000/39785 (0%)]\tLoss: 1074.573975\n",
      "Train Epoch: 1 [3000/39785 (0%)]\tLoss: 973.752808\n",
      "Train Epoch: 1 [4000/39785 (0%)]\tLoss: 829.442627\n",
      "Train Epoch: 1 [5000/39785 (0%)]\tLoss: 574.667908\n",
      "Train Epoch: 1 [6000/39785 (0%)]\tLoss: 739.444763\n",
      "Train Epoch: 1 [7000/39785 (0%)]\tLoss: 558.614746\n",
      "Train Epoch: 1 [8000/39785 (0%)]\tLoss: 556.047913\n",
      "Train Epoch: 1 [9000/39785 (0%)]\tLoss: 472.887207\n",
      "Train Epoch: 1 [10000/39785 (0%)]\tLoss: 657.138245\n",
      "Train Epoch: 1 [11000/39785 (0%)]\tLoss: 715.385254\n",
      "Train Epoch: 1 [12000/39785 (0%)]\tLoss: 561.910278\n",
      "Train Epoch: 1 [13000/39785 (0%)]\tLoss: 463.862244\n",
      "Train Epoch: 1 [14000/39785 (0%)]\tLoss: 558.785278\n",
      "Train Epoch: 1 [15000/39785 (0%)]\tLoss: 489.248169\n",
      "Train Epoch: 1 [16000/39785 (0%)]\tLoss: 550.416016\n",
      "Train Epoch: 1 [17000/39785 (0%)]\tLoss: 524.253906\n",
      "Train Epoch: 1 [18000/39785 (0%)]\tLoss: 577.391418\n",
      "Train Epoch: 1 [19000/39785 (0%)]\tLoss: 370.317200\n",
      "Train Epoch: 1 [20000/39785 (1%)]\tLoss: 350.959076\n",
      "Train Epoch: 1 [21000/39785 (1%)]\tLoss: 376.429077\n",
      "Train Epoch: 1 [22000/39785 (1%)]\tLoss: 438.304474\n",
      "Train Epoch: 1 [23000/39785 (1%)]\tLoss: 499.927246\n",
      "Train Epoch: 1 [24000/39785 (1%)]\tLoss: 527.434448\n",
      "Train Epoch: 1 [25000/39785 (1%)]\tLoss: 357.267456\n",
      "Train Epoch: 1 [26000/39785 (1%)]\tLoss: 393.522675\n",
      "Train Epoch: 1 [27000/39785 (1%)]\tLoss: 407.494904\n",
      "Train Epoch: 1 [28000/39785 (1%)]\tLoss: 455.798004\n",
      "Train Epoch: 1 [29000/39785 (1%)]\tLoss: 417.936035\n",
      "Train Epoch: 1 [30000/39785 (1%)]\tLoss: 426.208160\n",
      "Train Epoch: 1 [31000/39785 (1%)]\tLoss: 356.392303\n",
      "Train Epoch: 1 [32000/39785 (1%)]\tLoss: 387.358856\n",
      "Train Epoch: 1 [33000/39785 (1%)]\tLoss: 372.442474\n",
      "Train Epoch: 1 [34000/39785 (1%)]\tLoss: 553.408936\n",
      "Train Epoch: 1 [35000/39785 (1%)]\tLoss: 362.076813\n",
      "Train Epoch: 1 [36000/39785 (1%)]\tLoss: 466.152374\n",
      "Train Epoch: 1 [37000/39785 (1%)]\tLoss: 363.427643\n",
      "Train Epoch: 1 [38000/39785 (1%)]\tLoss: 379.101440\n",
      "Train Epoch: 1 [39000/39785 (1%)]\tLoss: 366.372711\n",
      "39700\n",
      "39785\n",
      "Train Epoch: 2 [1000/39785 (0%)]\tLoss: 373.133301\n",
      "Train Epoch: 2 [2000/39785 (0%)]\tLoss: 425.483948\n",
      "Train Epoch: 2 [3000/39785 (0%)]\tLoss: 381.429382\n",
      "Train Epoch: 2 [4000/39785 (0%)]\tLoss: 405.510559\n",
      "Train Epoch: 2 [5000/39785 (0%)]\tLoss: 404.624878\n",
      "Train Epoch: 2 [6000/39785 (0%)]\tLoss: 362.764374\n",
      "Train Epoch: 2 [7000/39785 (0%)]\tLoss: 360.868927\n",
      "Train Epoch: 2 [8000/39785 (0%)]\tLoss: 328.055725\n",
      "Train Epoch: 2 [9000/39785 (0%)]\tLoss: 364.830261\n",
      "Train Epoch: 2 [10000/39785 (0%)]\tLoss: 395.013672\n",
      "Train Epoch: 2 [11000/39785 (0%)]\tLoss: 299.700409\n",
      "Train Epoch: 2 [12000/39785 (0%)]\tLoss: 344.179535\n",
      "Train Epoch: 2 [13000/39785 (0%)]\tLoss: 349.492310\n",
      "Train Epoch: 2 [14000/39785 (0%)]\tLoss: 406.132141\n",
      "Train Epoch: 2 [15000/39785 (0%)]\tLoss: 369.175201\n",
      "Train Epoch: 2 [16000/39785 (0%)]\tLoss: 385.865570\n",
      "Train Epoch: 2 [17000/39785 (0%)]\tLoss: 347.413635\n",
      "Train Epoch: 2 [18000/39785 (0%)]\tLoss: 371.663086\n",
      "Train Epoch: 2 [19000/39785 (0%)]\tLoss: 341.475433\n",
      "Train Epoch: 2 [20000/39785 (1%)]\tLoss: 303.618713\n",
      "Train Epoch: 2 [21000/39785 (1%)]\tLoss: 405.141510\n",
      "Train Epoch: 2 [22000/39785 (1%)]\tLoss: 336.218964\n",
      "Train Epoch: 2 [23000/39785 (1%)]\tLoss: 328.992188\n",
      "Train Epoch: 2 [24000/39785 (1%)]\tLoss: 360.944824\n",
      "Train Epoch: 2 [25000/39785 (1%)]\tLoss: 334.881012\n",
      "Train Epoch: 2 [26000/39785 (1%)]\tLoss: 337.808197\n",
      "Train Epoch: 2 [27000/39785 (1%)]\tLoss: 368.615814\n",
      "Train Epoch: 2 [28000/39785 (1%)]\tLoss: 291.533234\n",
      "Train Epoch: 2 [29000/39785 (1%)]\tLoss: 330.601593\n",
      "Train Epoch: 2 [30000/39785 (1%)]\tLoss: 469.786591\n",
      "Train Epoch: 2 [31000/39785 (1%)]\tLoss: 501.517456\n",
      "Train Epoch: 2 [32000/39785 (1%)]\tLoss: 326.504791\n",
      "Train Epoch: 2 [33000/39785 (1%)]\tLoss: 319.685425\n",
      "Train Epoch: 2 [34000/39785 (1%)]\tLoss: 339.767944\n",
      "Train Epoch: 2 [35000/39785 (1%)]\tLoss: 311.304260\n",
      "Train Epoch: 2 [36000/39785 (1%)]\tLoss: 287.793976\n",
      "Train Epoch: 2 [37000/39785 (1%)]\tLoss: 348.792664\n",
      "Train Epoch: 2 [38000/39785 (1%)]\tLoss: 338.446198\n",
      "Train Epoch: 2 [39000/39785 (1%)]\tLoss: 294.141510\n",
      "39715\n",
      "39785\n",
      "Train Epoch: 3 [1000/39785 (0%)]\tLoss: 316.870392\n",
      "Train Epoch: 3 [2000/39785 (0%)]\tLoss: 270.212341\n",
      "Train Epoch: 3 [3000/39785 (0%)]\tLoss: 282.261047\n",
      "Train Epoch: 3 [4000/39785 (0%)]\tLoss: 411.363708\n",
      "Train Epoch: 3 [5000/39785 (0%)]\tLoss: 314.312347\n",
      "Train Epoch: 3 [6000/39785 (0%)]\tLoss: 333.565704\n",
      "Train Epoch: 3 [7000/39785 (0%)]\tLoss: 278.240021\n",
      "Train Epoch: 3 [8000/39785 (0%)]\tLoss: 352.677216\n",
      "Train Epoch: 3 [9000/39785 (0%)]\tLoss: 289.879913\n",
      "Train Epoch: 3 [10000/39785 (0%)]\tLoss: 278.604218\n",
      "Train Epoch: 3 [11000/39785 (0%)]\tLoss: 296.492981\n",
      "Train Epoch: 3 [12000/39785 (0%)]\tLoss: 279.346161\n",
      "Train Epoch: 3 [13000/39785 (0%)]\tLoss: 292.275482\n",
      "Train Epoch: 3 [14000/39785 (0%)]\tLoss: 280.404633\n",
      "Train Epoch: 3 [15000/39785 (0%)]\tLoss: 333.741211\n",
      "Train Epoch: 3 [16000/39785 (0%)]\tLoss: 285.597412\n",
      "Train Epoch: 3 [17000/39785 (0%)]\tLoss: 259.183441\n",
      "Train Epoch: 3 [18000/39785 (0%)]\tLoss: 260.687653\n",
      "Train Epoch: 3 [19000/39785 (0%)]\tLoss: 380.583374\n",
      "Train Epoch: 3 [20000/39785 (1%)]\tLoss: 294.521698\n",
      "Train Epoch: 3 [21000/39785 (1%)]\tLoss: 335.027313\n",
      "Train Epoch: 3 [22000/39785 (1%)]\tLoss: 249.949707\n",
      "Train Epoch: 3 [23000/39785 (1%)]\tLoss: 281.514862\n",
      "Train Epoch: 3 [24000/39785 (1%)]\tLoss: 257.662415\n",
      "Train Epoch: 3 [25000/39785 (1%)]\tLoss: 338.321442\n",
      "Train Epoch: 3 [26000/39785 (1%)]\tLoss: 316.041626\n",
      "Train Epoch: 3 [27000/39785 (1%)]\tLoss: 266.406830\n",
      "Train Epoch: 3 [28000/39785 (1%)]\tLoss: 342.366028\n",
      "Train Epoch: 3 [29000/39785 (1%)]\tLoss: 258.859680\n",
      "Train Epoch: 3 [30000/39785 (1%)]\tLoss: 279.044800\n",
      "Train Epoch: 3 [31000/39785 (1%)]\tLoss: 284.550598\n",
      "Train Epoch: 3 [32000/39785 (1%)]\tLoss: 322.054718\n",
      "Train Epoch: 3 [33000/39785 (1%)]\tLoss: 325.543732\n",
      "Train Epoch: 3 [34000/39785 (1%)]\tLoss: 353.139252\n",
      "Train Epoch: 3 [35000/39785 (1%)]\tLoss: 306.309113\n",
      "Train Epoch: 3 [36000/39785 (1%)]\tLoss: 262.950806\n",
      "Train Epoch: 3 [37000/39785 (1%)]\tLoss: 256.766632\n",
      "Train Epoch: 3 [38000/39785 (1%)]\tLoss: 267.368988\n",
      "Train Epoch: 3 [39000/39785 (1%)]\tLoss: 171.918701\n",
      "39730\n",
      "39785\n",
      "Train Epoch: 4 [1000/39785 (0%)]\tLoss: 272.752502\n",
      "Train Epoch: 4 [2000/39785 (0%)]\tLoss: 233.141037\n",
      "Train Epoch: 4 [3000/39785 (0%)]\tLoss: 234.345337\n",
      "Train Epoch: 4 [4000/39785 (0%)]\tLoss: 199.220322\n",
      "Train Epoch: 4 [5000/39785 (0%)]\tLoss: 227.209961\n",
      "Train Epoch: 4 [6000/39785 (0%)]\tLoss: 250.912537\n",
      "Train Epoch: 4 [7000/39785 (0%)]\tLoss: 465.915558\n",
      "Train Epoch: 4 [8000/39785 (0%)]\tLoss: 308.197601\n",
      "Train Epoch: 4 [9000/39785 (0%)]\tLoss: 273.829407\n",
      "Train Epoch: 4 [10000/39785 (0%)]\tLoss: 246.045761\n",
      "Train Epoch: 4 [11000/39785 (0%)]\tLoss: 262.834961\n",
      "Train Epoch: 4 [12000/39785 (0%)]\tLoss: 248.500732\n",
      "Train Epoch: 4 [13000/39785 (0%)]\tLoss: 199.997101\n",
      "Train Epoch: 4 [14000/39785 (0%)]\tLoss: 269.756958\n",
      "Train Epoch: 4 [15000/39785 (0%)]\tLoss: 210.989182\n",
      "Train Epoch: 4 [16000/39785 (0%)]\tLoss: 247.296967\n",
      "Train Epoch: 4 [17000/39785 (0%)]\tLoss: 283.359497\n",
      "Train Epoch: 4 [18000/39785 (0%)]\tLoss: 273.472076\n",
      "Train Epoch: 4 [19000/39785 (0%)]\tLoss: 305.510468\n",
      "Train Epoch: 4 [20000/39785 (1%)]\tLoss: 253.763931\n",
      "Train Epoch: 4 [21000/39785 (1%)]\tLoss: 277.836029\n",
      "Train Epoch: 4 [22000/39785 (1%)]\tLoss: 234.083496\n",
      "Train Epoch: 4 [23000/39785 (1%)]\tLoss: 229.587708\n",
      "Train Epoch: 4 [24000/39785 (1%)]\tLoss: 250.768646\n",
      "Train Epoch: 4 [25000/39785 (1%)]\tLoss: 258.534393\n",
      "Train Epoch: 4 [26000/39785 (1%)]\tLoss: 243.993622\n",
      "Train Epoch: 4 [27000/39785 (1%)]\tLoss: 285.173004\n",
      "Train Epoch: 4 [28000/39785 (1%)]\tLoss: 210.731186\n",
      "Train Epoch: 4 [29000/39785 (1%)]\tLoss: 254.474396\n",
      "Train Epoch: 4 [30000/39785 (1%)]\tLoss: 265.300354\n",
      "Train Epoch: 4 [31000/39785 (1%)]\tLoss: 193.142319\n",
      "Train Epoch: 4 [32000/39785 (1%)]\tLoss: 298.063263\n",
      "Train Epoch: 4 [33000/39785 (1%)]\tLoss: 280.352142\n",
      "Train Epoch: 4 [34000/39785 (1%)]\tLoss: 273.968170\n",
      "Train Epoch: 4 [35000/39785 (1%)]\tLoss: 269.336151\n",
      "Train Epoch: 4 [36000/39785 (1%)]\tLoss: 249.001038\n",
      "Train Epoch: 4 [37000/39785 (1%)]\tLoss: 270.405121\n",
      "Train Epoch: 4 [38000/39785 (1%)]\tLoss: 232.573257\n",
      "Train Epoch: 4 [39000/39785 (1%)]\tLoss: 195.812042\n",
      "39745\n",
      "39785\n",
      "Train Epoch: 5 [1000/39785 (0%)]\tLoss: 208.323517\n",
      "Train Epoch: 5 [2000/39785 (0%)]\tLoss: 201.830231\n",
      "Train Epoch: 5 [3000/39785 (0%)]\tLoss: 216.887726\n",
      "Train Epoch: 5 [4000/39785 (0%)]\tLoss: 298.961151\n",
      "Train Epoch: 5 [5000/39785 (0%)]\tLoss: 194.217163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [6000/39785 (0%)]\tLoss: 267.314728\n",
      "Train Epoch: 5 [7000/39785 (0%)]\tLoss: 250.307434\n",
      "Train Epoch: 5 [8000/39785 (0%)]\tLoss: 281.507568\n",
      "Train Epoch: 5 [9000/39785 (0%)]\tLoss: 182.773804\n",
      "Train Epoch: 5 [10000/39785 (0%)]\tLoss: 257.191284\n",
      "Train Epoch: 5 [11000/39785 (0%)]\tLoss: 200.231445\n",
      "Train Epoch: 5 [12000/39785 (0%)]\tLoss: 229.285095\n",
      "Train Epoch: 5 [13000/39785 (0%)]\tLoss: 229.772919\n",
      "Train Epoch: 5 [14000/39785 (0%)]\tLoss: 212.128021\n",
      "Train Epoch: 5 [15000/39785 (0%)]\tLoss: 199.787247\n",
      "Train Epoch: 5 [16000/39785 (0%)]\tLoss: 271.689301\n",
      "Train Epoch: 5 [17000/39785 (0%)]\tLoss: 221.210098\n",
      "Train Epoch: 5 [18000/39785 (0%)]\tLoss: 274.165039\n",
      "Train Epoch: 5 [19000/39785 (0%)]\tLoss: 268.127228\n",
      "Train Epoch: 5 [20000/39785 (1%)]\tLoss: 301.598602\n",
      "Train Epoch: 5 [21000/39785 (1%)]\tLoss: 254.278824\n",
      "Train Epoch: 5 [22000/39785 (1%)]\tLoss: 271.156189\n",
      "Train Epoch: 5 [23000/39785 (1%)]\tLoss: 238.583755\n",
      "Train Epoch: 5 [24000/39785 (1%)]\tLoss: 270.412384\n",
      "Train Epoch: 5 [25000/39785 (1%)]\tLoss: 171.141373\n",
      "Train Epoch: 5 [26000/39785 (1%)]\tLoss: 285.815338\n",
      "Train Epoch: 5 [27000/39785 (1%)]\tLoss: 296.217194\n",
      "Train Epoch: 5 [28000/39785 (1%)]\tLoss: 264.005432\n",
      "Train Epoch: 5 [29000/39785 (1%)]\tLoss: 289.116821\n",
      "Train Epoch: 5 [30000/39785 (1%)]\tLoss: 258.763000\n",
      "Train Epoch: 5 [31000/39785 (1%)]\tLoss: 335.968781\n",
      "Train Epoch: 5 [32000/39785 (1%)]\tLoss: 226.553360\n",
      "Train Epoch: 5 [33000/39785 (1%)]\tLoss: 195.801315\n",
      "Train Epoch: 5 [34000/39785 (1%)]\tLoss: 197.727524\n",
      "Train Epoch: 5 [35000/39785 (1%)]\tLoss: 252.461700\n",
      "Train Epoch: 5 [36000/39785 (1%)]\tLoss: 255.407883\n",
      "Train Epoch: 5 [37000/39785 (1%)]\tLoss: 341.161987\n",
      "Train Epoch: 5 [38000/39785 (1%)]\tLoss: 287.979828\n",
      "Train Epoch: 5 [39000/39785 (1%)]\tLoss: 266.048035\n",
      "39760\n",
      "39785\n",
      "Train Epoch: 6 [1000/39785 (0%)]\tLoss: 263.800568\n",
      "Train Epoch: 6 [2000/39785 (0%)]\tLoss: 231.357697\n",
      "Train Epoch: 6 [3000/39785 (0%)]\tLoss: 267.711517\n",
      "Train Epoch: 6 [4000/39785 (0%)]\tLoss: 204.704285\n",
      "Train Epoch: 6 [5000/39785 (0%)]\tLoss: 238.467972\n",
      "Train Epoch: 6 [6000/39785 (0%)]\tLoss: 202.053879\n",
      "Train Epoch: 6 [7000/39785 (0%)]\tLoss: 183.699051\n",
      "Train Epoch: 6 [8000/39785 (0%)]\tLoss: 236.372910\n",
      "Train Epoch: 6 [9000/39785 (0%)]\tLoss: 167.631424\n",
      "Train Epoch: 6 [10000/39785 (0%)]\tLoss: 236.838272\n",
      "Train Epoch: 6 [11000/39785 (0%)]\tLoss: 264.322998\n",
      "Train Epoch: 6 [12000/39785 (0%)]\tLoss: 239.833572\n",
      "Train Epoch: 6 [13000/39785 (0%)]\tLoss: 232.058334\n",
      "Train Epoch: 6 [14000/39785 (0%)]\tLoss: 220.763763\n",
      "Train Epoch: 6 [15000/39785 (0%)]\tLoss: 277.308777\n",
      "Train Epoch: 6 [16000/39785 (0%)]\tLoss: 149.465073\n",
      "Train Epoch: 6 [17000/39785 (0%)]\tLoss: 175.793686\n",
      "Train Epoch: 6 [18000/39785 (0%)]\tLoss: 183.692398\n",
      "Train Epoch: 6 [19000/39785 (0%)]\tLoss: 153.945770\n",
      "Train Epoch: 6 [20000/39785 (1%)]\tLoss: 231.405640\n",
      "Train Epoch: 6 [21000/39785 (1%)]\tLoss: 213.292877\n",
      "Train Epoch: 6 [22000/39785 (1%)]\tLoss: 237.406693\n",
      "Train Epoch: 6 [23000/39785 (1%)]\tLoss: 194.084061\n",
      "Train Epoch: 6 [24000/39785 (1%)]\tLoss: 238.880768\n",
      "Train Epoch: 6 [25000/39785 (1%)]\tLoss: 223.505661\n",
      "Train Epoch: 6 [26000/39785 (1%)]\tLoss: 286.673676\n",
      "Train Epoch: 6 [27000/39785 (1%)]\tLoss: 226.010010\n",
      "Train Epoch: 6 [28000/39785 (1%)]\tLoss: 231.456696\n",
      "Train Epoch: 6 [29000/39785 (1%)]\tLoss: 207.397568\n",
      "Train Epoch: 6 [30000/39785 (1%)]\tLoss: 166.633224\n",
      "Train Epoch: 6 [31000/39785 (1%)]\tLoss: 295.817413\n",
      "Train Epoch: 6 [32000/39785 (1%)]\tLoss: 269.557312\n",
      "Train Epoch: 6 [33000/39785 (1%)]\tLoss: 221.859222\n",
      "Train Epoch: 6 [34000/39785 (1%)]\tLoss: 175.779785\n",
      "Train Epoch: 6 [35000/39785 (1%)]\tLoss: 226.286362\n",
      "Train Epoch: 6 [36000/39785 (1%)]\tLoss: 307.028320\n",
      "Train Epoch: 6 [37000/39785 (1%)]\tLoss: 331.548950\n",
      "Train Epoch: 6 [38000/39785 (1%)]\tLoss: 327.751221\n",
      "Train Epoch: 6 [39000/39785 (1%)]\tLoss: 311.501831\n",
      "39775\n",
      "39785\n",
      "Train Epoch: 7 [1000/39785 (0%)]\tLoss: 302.838654\n",
      "Train Epoch: 7 [2000/39785 (0%)]\tLoss: 190.187134\n",
      "Train Epoch: 7 [3000/39785 (0%)]\tLoss: 162.256699\n",
      "Train Epoch: 7 [4000/39785 (0%)]\tLoss: 495.794250\n",
      "Train Epoch: 7 [5000/39785 (0%)]\tLoss: 182.563705\n",
      "Train Epoch: 7 [6000/39785 (0%)]\tLoss: 209.299438\n",
      "Train Epoch: 7 [7000/39785 (0%)]\tLoss: 216.529419\n",
      "Train Epoch: 7 [8000/39785 (0%)]\tLoss: 213.502701\n",
      "Train Epoch: 7 [9000/39785 (0%)]\tLoss: 198.528061\n",
      "Train Epoch: 7 [10000/39785 (0%)]\tLoss: 275.372162\n",
      "Train Epoch: 7 [11000/39785 (0%)]\tLoss: 211.514252\n",
      "Train Epoch: 7 [12000/39785 (0%)]\tLoss: 172.328201\n",
      "Train Epoch: 7 [13000/39785 (0%)]\tLoss: 184.192688\n",
      "Train Epoch: 7 [14000/39785 (0%)]\tLoss: 308.091766\n",
      "Train Epoch: 7 [15000/39785 (0%)]\tLoss: 172.239334\n",
      "Train Epoch: 7 [16000/39785 (0%)]\tLoss: 158.121887\n",
      "Train Epoch: 7 [17000/39785 (0%)]\tLoss: 223.047531\n",
      "Train Epoch: 7 [18000/39785 (0%)]\tLoss: 227.314392\n",
      "Train Epoch: 7 [19000/39785 (0%)]\tLoss: 270.182892\n",
      "Train Epoch: 7 [20000/39785 (1%)]\tLoss: 181.042130\n",
      "Train Epoch: 7 [21000/39785 (1%)]\tLoss: 239.456635\n",
      "Train Epoch: 7 [22000/39785 (1%)]\tLoss: 168.487335\n",
      "Train Epoch: 7 [23000/39785 (1%)]\tLoss: 182.808945\n",
      "Train Epoch: 7 [24000/39785 (1%)]\tLoss: 192.427444\n",
      "Train Epoch: 7 [25000/39785 (1%)]\tLoss: 252.307770\n",
      "Train Epoch: 7 [26000/39785 (1%)]\tLoss: 200.761108\n",
      "Train Epoch: 7 [27000/39785 (1%)]\tLoss: 213.576279\n",
      "Train Epoch: 7 [28000/39785 (1%)]\tLoss: 221.767838\n",
      "Train Epoch: 7 [29000/39785 (1%)]\tLoss: 221.097778\n",
      "Train Epoch: 7 [30000/39785 (1%)]\tLoss: 234.046494\n",
      "Train Epoch: 7 [31000/39785 (1%)]\tLoss: 167.306320\n",
      "Train Epoch: 7 [32000/39785 (1%)]\tLoss: 212.412384\n",
      "Train Epoch: 7 [33000/39785 (1%)]\tLoss: 181.329895\n",
      "Train Epoch: 7 [34000/39785 (1%)]\tLoss: 181.027084\n",
      "Train Epoch: 7 [35000/39785 (1%)]\tLoss: 144.770279\n",
      "Train Epoch: 7 [36000/39785 (1%)]\tLoss: 239.940018\n",
      "Train Epoch: 7 [37000/39785 (1%)]\tLoss: 226.200668\n",
      "Train Epoch: 7 [38000/39785 (1%)]\tLoss: 275.451050\n",
      "Train Epoch: 7 [39000/39785 (1%)]\tLoss: 197.696213\n",
      "39690\n",
      "39785\n",
      "Train Epoch: 8 [1000/39785 (0%)]\tLoss: 148.969437\n",
      "Train Epoch: 8 [2000/39785 (0%)]\tLoss: 207.253403\n",
      "Train Epoch: 8 [3000/39785 (0%)]\tLoss: 151.632401\n",
      "Train Epoch: 8 [4000/39785 (0%)]\tLoss: 136.538239\n",
      "Train Epoch: 8 [5000/39785 (0%)]\tLoss: 146.508438\n",
      "Train Epoch: 8 [6000/39785 (0%)]\tLoss: 178.905167\n",
      "Train Epoch: 8 [7000/39785 (0%)]\tLoss: 227.331055\n",
      "Train Epoch: 8 [8000/39785 (0%)]\tLoss: 183.494949\n",
      "Train Epoch: 8 [9000/39785 (0%)]\tLoss: 145.746811\n",
      "Train Epoch: 8 [10000/39785 (0%)]\tLoss: 164.911667\n",
      "Train Epoch: 8 [11000/39785 (0%)]\tLoss: 194.936813\n",
      "Train Epoch: 8 [12000/39785 (0%)]\tLoss: 166.797989\n",
      "Train Epoch: 8 [13000/39785 (0%)]\tLoss: 310.727020\n",
      "Train Epoch: 8 [14000/39785 (0%)]\tLoss: 174.815811\n",
      "Train Epoch: 8 [15000/39785 (0%)]\tLoss: 247.253876\n",
      "Train Epoch: 8 [16000/39785 (0%)]\tLoss: 262.578217\n",
      "Train Epoch: 8 [17000/39785 (0%)]\tLoss: 250.863892\n",
      "Train Epoch: 8 [18000/39785 (0%)]\tLoss: 214.875305\n",
      "Train Epoch: 8 [19000/39785 (0%)]\tLoss: 182.387283\n",
      "Train Epoch: 8 [20000/39785 (1%)]\tLoss: 162.222168\n",
      "Train Epoch: 8 [21000/39785 (1%)]\tLoss: 185.984848\n",
      "Train Epoch: 8 [22000/39785 (1%)]\tLoss: 178.189987\n",
      "Train Epoch: 8 [23000/39785 (1%)]\tLoss: 224.184052\n",
      "Train Epoch: 8 [24000/39785 (1%)]\tLoss: 228.403229\n",
      "Train Epoch: 8 [25000/39785 (1%)]\tLoss: 193.338257\n",
      "Train Epoch: 8 [26000/39785 (1%)]\tLoss: 240.927536\n",
      "Train Epoch: 8 [27000/39785 (1%)]\tLoss: 242.149551\n",
      "Train Epoch: 8 [28000/39785 (1%)]\tLoss: 178.824097\n",
      "Train Epoch: 8 [29000/39785 (1%)]\tLoss: 153.323349\n",
      "Train Epoch: 8 [30000/39785 (1%)]\tLoss: 206.422195\n",
      "Train Epoch: 8 [31000/39785 (1%)]\tLoss: 191.701828\n",
      "Train Epoch: 8 [32000/39785 (1%)]\tLoss: 214.426285\n",
      "Train Epoch: 8 [33000/39785 (1%)]\tLoss: 196.492615\n",
      "Train Epoch: 8 [34000/39785 (1%)]\tLoss: 209.156418\n",
      "Train Epoch: 8 [35000/39785 (1%)]\tLoss: 154.070480\n",
      "Train Epoch: 8 [36000/39785 (1%)]\tLoss: 301.522308\n",
      "Train Epoch: 8 [37000/39785 (1%)]\tLoss: 261.089844\n",
      "Train Epoch: 8 [38000/39785 (1%)]\tLoss: 214.429153\n",
      "Train Epoch: 8 [39000/39785 (1%)]\tLoss: 246.100494\n",
      "39705\n",
      "39785\n",
      "Train Epoch: 9 [1000/39785 (0%)]\tLoss: 214.725769\n",
      "Train Epoch: 9 [2000/39785 (0%)]\tLoss: 231.771149\n",
      "Train Epoch: 9 [3000/39785 (0%)]\tLoss: 283.021454\n",
      "Train Epoch: 9 [4000/39785 (0%)]\tLoss: 167.552567\n",
      "Train Epoch: 9 [5000/39785 (0%)]\tLoss: 151.115280\n",
      "Train Epoch: 9 [6000/39785 (0%)]\tLoss: 130.986206\n",
      "Train Epoch: 9 [7000/39785 (0%)]\tLoss: 160.879303\n",
      "Train Epoch: 9 [8000/39785 (0%)]\tLoss: 217.411621\n",
      "Train Epoch: 9 [9000/39785 (0%)]\tLoss: 179.991440\n",
      "Train Epoch: 9 [10000/39785 (0%)]\tLoss: 202.476959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [11000/39785 (0%)]\tLoss: 159.807724\n",
      "Train Epoch: 9 [12000/39785 (0%)]\tLoss: 203.979172\n",
      "Train Epoch: 9 [13000/39785 (0%)]\tLoss: 256.048859\n",
      "Train Epoch: 9 [14000/39785 (0%)]\tLoss: 234.559647\n",
      "Train Epoch: 9 [15000/39785 (0%)]\tLoss: 132.976486\n",
      "Train Epoch: 9 [16000/39785 (0%)]\tLoss: 133.622467\n",
      "Train Epoch: 9 [17000/39785 (0%)]\tLoss: 250.525925\n",
      "Train Epoch: 9 [18000/39785 (0%)]\tLoss: 147.256393\n",
      "Train Epoch: 9 [19000/39785 (0%)]\tLoss: 201.704956\n",
      "Train Epoch: 9 [20000/39785 (1%)]\tLoss: 182.743790\n",
      "Train Epoch: 9 [21000/39785 (1%)]\tLoss: 169.760818\n",
      "Train Epoch: 9 [22000/39785 (1%)]\tLoss: 213.394302\n",
      "Train Epoch: 9 [23000/39785 (1%)]\tLoss: 196.216064\n",
      "Train Epoch: 9 [24000/39785 (1%)]\tLoss: 182.808990\n",
      "Train Epoch: 9 [25000/39785 (1%)]\tLoss: 180.911133\n",
      "Train Epoch: 9 [26000/39785 (1%)]\tLoss: 185.825043\n",
      "Train Epoch: 9 [27000/39785 (1%)]\tLoss: 224.164673\n",
      "Train Epoch: 9 [28000/39785 (1%)]\tLoss: 137.947769\n",
      "Train Epoch: 9 [29000/39785 (1%)]\tLoss: 258.190155\n",
      "Train Epoch: 9 [30000/39785 (1%)]\tLoss: 200.913788\n",
      "Train Epoch: 9 [31000/39785 (1%)]\tLoss: 196.239487\n",
      "Train Epoch: 9 [32000/39785 (1%)]\tLoss: 207.063309\n",
      "Train Epoch: 9 [33000/39785 (1%)]\tLoss: 162.872055\n",
      "Train Epoch: 9 [34000/39785 (1%)]\tLoss: 217.594345\n",
      "Train Epoch: 9 [35000/39785 (1%)]\tLoss: 176.365646\n",
      "Train Epoch: 9 [36000/39785 (1%)]\tLoss: 258.563141\n",
      "Train Epoch: 9 [37000/39785 (1%)]\tLoss: 205.594925\n",
      "Train Epoch: 9 [38000/39785 (1%)]\tLoss: 164.951828\n",
      "Train Epoch: 9 [39000/39785 (1%)]\tLoss: 147.557068\n",
      "39720\n",
      "39785\n",
      "Train Epoch: 10 [1000/39785 (0%)]\tLoss: 156.747986\n",
      "Train Epoch: 10 [2000/39785 (0%)]\tLoss: 144.986832\n",
      "Train Epoch: 10 [3000/39785 (0%)]\tLoss: 237.510803\n",
      "Train Epoch: 10 [4000/39785 (0%)]\tLoss: 186.856781\n",
      "Train Epoch: 10 [5000/39785 (0%)]\tLoss: 222.245712\n",
      "Train Epoch: 10 [6000/39785 (0%)]\tLoss: 122.862068\n",
      "Train Epoch: 10 [7000/39785 (0%)]\tLoss: 196.174591\n",
      "Train Epoch: 10 [8000/39785 (0%)]\tLoss: 261.163300\n",
      "Train Epoch: 10 [9000/39785 (0%)]\tLoss: 176.698425\n",
      "Train Epoch: 10 [10000/39785 (0%)]\tLoss: 227.805908\n",
      "Train Epoch: 10 [11000/39785 (0%)]\tLoss: 159.263123\n",
      "Train Epoch: 10 [12000/39785 (0%)]\tLoss: 138.509705\n",
      "Train Epoch: 10 [13000/39785 (0%)]\tLoss: 214.354065\n",
      "Train Epoch: 10 [14000/39785 (0%)]\tLoss: 185.748703\n",
      "Train Epoch: 10 [15000/39785 (0%)]\tLoss: 147.103424\n",
      "Train Epoch: 10 [16000/39785 (0%)]\tLoss: 134.028351\n",
      "Train Epoch: 10 [17000/39785 (0%)]\tLoss: 189.388565\n",
      "Train Epoch: 10 [18000/39785 (0%)]\tLoss: 181.052872\n",
      "Train Epoch: 10 [19000/39785 (0%)]\tLoss: 141.033112\n",
      "Train Epoch: 10 [20000/39785 (1%)]\tLoss: 131.952911\n",
      "Train Epoch: 10 [21000/39785 (1%)]\tLoss: 157.408676\n",
      "Train Epoch: 10 [22000/39785 (1%)]\tLoss: 222.304962\n",
      "Train Epoch: 10 [23000/39785 (1%)]\tLoss: 207.045334\n",
      "Train Epoch: 10 [24000/39785 (1%)]\tLoss: 177.712799\n",
      "Train Epoch: 10 [25000/39785 (1%)]\tLoss: 208.411972\n",
      "Train Epoch: 10 [26000/39785 (1%)]\tLoss: 181.510330\n",
      "Train Epoch: 10 [27000/39785 (1%)]\tLoss: 177.166458\n",
      "Train Epoch: 10 [28000/39785 (1%)]\tLoss: 165.944763\n",
      "Train Epoch: 10 [29000/39785 (1%)]\tLoss: 176.857513\n",
      "Train Epoch: 10 [30000/39785 (1%)]\tLoss: 192.744034\n",
      "Train Epoch: 10 [31000/39785 (1%)]\tLoss: 169.394638\n",
      "Train Epoch: 10 [32000/39785 (1%)]\tLoss: 191.452225\n",
      "Train Epoch: 10 [33000/39785 (1%)]\tLoss: 172.984375\n",
      "Train Epoch: 10 [34000/39785 (1%)]\tLoss: 230.592651\n",
      "Train Epoch: 10 [35000/39785 (1%)]\tLoss: 189.556427\n",
      "Train Epoch: 10 [36000/39785 (1%)]\tLoss: 163.990158\n",
      "Train Epoch: 10 [37000/39785 (1%)]\tLoss: 146.303436\n",
      "Train Epoch: 10 [38000/39785 (1%)]\tLoss: 187.130905\n",
      "Train Epoch: 10 [39000/39785 (1%)]\tLoss: 204.112976\n",
      "39735\n",
      "39785\n",
      "Train Epoch: 11 [1000/39785 (0%)]\tLoss: 148.713928\n",
      "Train Epoch: 11 [2000/39785 (0%)]\tLoss: 204.431473\n",
      "Train Epoch: 11 [3000/39785 (0%)]\tLoss: 220.582047\n",
      "Train Epoch: 11 [4000/39785 (0%)]\tLoss: 160.419342\n",
      "Train Epoch: 11 [5000/39785 (0%)]\tLoss: 174.637466\n",
      "Train Epoch: 11 [6000/39785 (0%)]\tLoss: 184.049042\n",
      "Train Epoch: 11 [7000/39785 (0%)]\tLoss: 175.898727\n",
      "Train Epoch: 11 [8000/39785 (0%)]\tLoss: 133.698105\n",
      "Train Epoch: 11 [9000/39785 (0%)]\tLoss: 178.938995\n",
      "Train Epoch: 11 [10000/39785 (0%)]\tLoss: 173.863510\n",
      "Train Epoch: 11 [11000/39785 (0%)]\tLoss: 205.096313\n",
      "Train Epoch: 11 [12000/39785 (0%)]\tLoss: 173.613586\n",
      "Train Epoch: 11 [13000/39785 (0%)]\tLoss: 179.921616\n",
      "Train Epoch: 11 [14000/39785 (0%)]\tLoss: 135.932739\n",
      "Train Epoch: 11 [15000/39785 (0%)]\tLoss: 171.500366\n",
      "Train Epoch: 11 [16000/39785 (0%)]\tLoss: 173.691055\n",
      "Train Epoch: 11 [17000/39785 (0%)]\tLoss: 189.298691\n",
      "Train Epoch: 11 [18000/39785 (0%)]\tLoss: 193.725159\n",
      "Train Epoch: 11 [19000/39785 (0%)]\tLoss: 138.608292\n",
      "Train Epoch: 11 [20000/39785 (1%)]\tLoss: 214.864761\n",
      "Train Epoch: 11 [21000/39785 (1%)]\tLoss: 184.035858\n",
      "Train Epoch: 11 [22000/39785 (1%)]\tLoss: 189.560516\n",
      "Train Epoch: 11 [23000/39785 (1%)]\tLoss: 208.757721\n",
      "Train Epoch: 11 [24000/39785 (1%)]\tLoss: 159.328369\n",
      "Train Epoch: 11 [25000/39785 (1%)]\tLoss: 166.038101\n",
      "Train Epoch: 11 [26000/39785 (1%)]\tLoss: 157.509003\n",
      "Train Epoch: 11 [27000/39785 (1%)]\tLoss: 140.805252\n",
      "Train Epoch: 11 [28000/39785 (1%)]\tLoss: 136.942093\n",
      "Train Epoch: 11 [29000/39785 (1%)]\tLoss: 139.097122\n",
      "Train Epoch: 11 [30000/39785 (1%)]\tLoss: 155.823853\n",
      "Train Epoch: 11 [31000/39785 (1%)]\tLoss: 132.457153\n",
      "Train Epoch: 11 [32000/39785 (1%)]\tLoss: 150.167038\n",
      "Train Epoch: 11 [33000/39785 (1%)]\tLoss: 222.322479\n",
      "Train Epoch: 11 [34000/39785 (1%)]\tLoss: 228.558426\n",
      "Train Epoch: 11 [35000/39785 (1%)]\tLoss: 180.689362\n",
      "Train Epoch: 11 [36000/39785 (1%)]\tLoss: 216.550354\n",
      "Train Epoch: 11 [37000/39785 (1%)]\tLoss: 348.592194\n",
      "Train Epoch: 11 [38000/39785 (1%)]\tLoss: 219.962677\n",
      "Train Epoch: 11 [39000/39785 (1%)]\tLoss: 206.382996\n",
      "39750\n",
      "39785\n",
      "Train Epoch: 12 [1000/39785 (0%)]\tLoss: 165.176178\n",
      "Train Epoch: 12 [2000/39785 (0%)]\tLoss: 144.636108\n",
      "Train Epoch: 12 [3000/39785 (0%)]\tLoss: 119.619553\n",
      "Train Epoch: 12 [4000/39785 (0%)]\tLoss: 169.418457\n",
      "Train Epoch: 12 [5000/39785 (0%)]\tLoss: 281.774414\n",
      "Train Epoch: 12 [6000/39785 (0%)]\tLoss: 158.440033\n",
      "Train Epoch: 12 [7000/39785 (0%)]\tLoss: 200.181213\n",
      "Train Epoch: 12 [8000/39785 (0%)]\tLoss: 150.123840\n",
      "Train Epoch: 12 [9000/39785 (0%)]\tLoss: 155.236450\n",
      "Train Epoch: 12 [10000/39785 (0%)]\tLoss: 129.489197\n",
      "Train Epoch: 12 [11000/39785 (0%)]\tLoss: 130.818298\n",
      "Train Epoch: 12 [12000/39785 (0%)]\tLoss: 115.732971\n",
      "Train Epoch: 12 [13000/39785 (0%)]\tLoss: 171.341904\n",
      "Train Epoch: 12 [14000/39785 (0%)]\tLoss: 139.046570\n",
      "Train Epoch: 12 [15000/39785 (0%)]\tLoss: 146.131058\n",
      "Train Epoch: 12 [16000/39785 (0%)]\tLoss: 115.127205\n",
      "Train Epoch: 12 [17000/39785 (0%)]\tLoss: 140.024155\n",
      "Train Epoch: 12 [18000/39785 (0%)]\tLoss: 145.112610\n",
      "Train Epoch: 12 [19000/39785 (0%)]\tLoss: 218.613876\n",
      "Train Epoch: 12 [20000/39785 (1%)]\tLoss: 167.818909\n",
      "Train Epoch: 12 [21000/39785 (1%)]\tLoss: 166.058914\n",
      "Train Epoch: 12 [22000/39785 (1%)]\tLoss: 200.884567\n",
      "Train Epoch: 12 [23000/39785 (1%)]\tLoss: 127.194771\n",
      "Train Epoch: 12 [24000/39785 (1%)]\tLoss: 131.837952\n",
      "Train Epoch: 12 [25000/39785 (1%)]\tLoss: 159.538452\n",
      "Train Epoch: 12 [26000/39785 (1%)]\tLoss: 113.382393\n",
      "Train Epoch: 12 [27000/39785 (1%)]\tLoss: 184.769730\n",
      "Train Epoch: 12 [28000/39785 (1%)]\tLoss: 269.131073\n",
      "Train Epoch: 12 [29000/39785 (1%)]\tLoss: 420.088104\n",
      "Train Epoch: 12 [30000/39785 (1%)]\tLoss: 302.933624\n",
      "Train Epoch: 12 [31000/39785 (1%)]\tLoss: 299.044342\n",
      "Train Epoch: 12 [32000/39785 (1%)]\tLoss: 272.777405\n",
      "Train Epoch: 12 [33000/39785 (1%)]\tLoss: 238.378738\n",
      "Train Epoch: 12 [34000/39785 (1%)]\tLoss: 180.049850\n",
      "Train Epoch: 12 [35000/39785 (1%)]\tLoss: 171.318253\n",
      "Train Epoch: 12 [36000/39785 (1%)]\tLoss: 176.913651\n",
      "Train Epoch: 12 [37000/39785 (1%)]\tLoss: 150.993362\n",
      "Train Epoch: 12 [38000/39785 (1%)]\tLoss: 221.238083\n",
      "Train Epoch: 12 [39000/39785 (1%)]\tLoss: 289.645172\n",
      "39765\n",
      "39785\n",
      "Train Epoch: 13 [1000/39785 (0%)]\tLoss: 121.303268\n",
      "Train Epoch: 13 [2000/39785 (0%)]\tLoss: 139.365250\n",
      "Train Epoch: 13 [3000/39785 (0%)]\tLoss: 255.885727\n",
      "Train Epoch: 13 [4000/39785 (0%)]\tLoss: 288.075806\n",
      "Train Epoch: 13 [5000/39785 (0%)]\tLoss: 131.974869\n",
      "Train Epoch: 13 [6000/39785 (0%)]\tLoss: 176.902939\n",
      "Train Epoch: 13 [7000/39785 (0%)]\tLoss: 182.111755\n",
      "Train Epoch: 13 [8000/39785 (0%)]\tLoss: 151.403656\n",
      "Train Epoch: 13 [9000/39785 (0%)]\tLoss: 121.689301\n",
      "Train Epoch: 13 [10000/39785 (0%)]\tLoss: 167.341736\n",
      "Train Epoch: 13 [11000/39785 (0%)]\tLoss: 158.681366\n",
      "Train Epoch: 13 [12000/39785 (0%)]\tLoss: 152.022049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [13000/39785 (0%)]\tLoss: 106.710693\n",
      "Train Epoch: 13 [14000/39785 (0%)]\tLoss: 134.318665\n",
      "Train Epoch: 13 [15000/39785 (0%)]\tLoss: 139.144791\n",
      "Train Epoch: 13 [16000/39785 (0%)]\tLoss: 133.970505\n",
      "Train Epoch: 13 [17000/39785 (0%)]\tLoss: 160.414810\n",
      "Train Epoch: 13 [18000/39785 (0%)]\tLoss: 145.912033\n",
      "Train Epoch: 13 [19000/39785 (0%)]\tLoss: 104.092735\n",
      "Train Epoch: 13 [20000/39785 (1%)]\tLoss: 200.826721\n",
      "Train Epoch: 13 [21000/39785 (1%)]\tLoss: 155.518921\n",
      "Train Epoch: 13 [22000/39785 (1%)]\tLoss: 137.370850\n",
      "Train Epoch: 13 [23000/39785 (1%)]\tLoss: 159.411438\n",
      "Train Epoch: 13 [24000/39785 (1%)]\tLoss: 1535.654663\n",
      "Train Epoch: 13 [25000/39785 (1%)]\tLoss: 1012.830933\n",
      "Train Epoch: 13 [26000/39785 (1%)]\tLoss: 5798.372070\n",
      "Train Epoch: 13 [27000/39785 (1%)]\tLoss: 750.386230\n",
      "Train Epoch: 13 [28000/39785 (1%)]\tLoss: 436.498260\n",
      "Train Epoch: 13 [29000/39785 (1%)]\tLoss: 425.761597\n",
      "Train Epoch: 13 [30000/39785 (1%)]\tLoss: 410.461060\n",
      "Train Epoch: 13 [31000/39785 (1%)]\tLoss: 365.869720\n",
      "Train Epoch: 13 [32000/39785 (1%)]\tLoss: 256.866272\n",
      "Train Epoch: 13 [33000/39785 (1%)]\tLoss: 342.960815\n",
      "Train Epoch: 13 [34000/39785 (1%)]\tLoss: 258.756287\n",
      "Train Epoch: 13 [35000/39785 (1%)]\tLoss: 250.893463\n",
      "Train Epoch: 13 [36000/39785 (1%)]\tLoss: 213.257172\n",
      "Train Epoch: 13 [37000/39785 (1%)]\tLoss: 246.573059\n",
      "Train Epoch: 13 [38000/39785 (1%)]\tLoss: 257.026398\n",
      "Train Epoch: 13 [39000/39785 (1%)]\tLoss: 258.547760\n",
      "39780\n",
      "39785\n",
      "Train Epoch: 14 [1000/39785 (0%)]\tLoss: 842.447571\n",
      "Train Epoch: 14 [2000/39785 (0%)]\tLoss: 9190.779297\n",
      "Train Epoch: 14 [3000/39785 (0%)]\tLoss: 1164.495239\n",
      "Train Epoch: 14 [4000/39785 (0%)]\tLoss: 703.057922\n",
      "Train Epoch: 14 [5000/39785 (0%)]\tLoss: 868.481018\n",
      "Train Epoch: 14 [6000/39785 (0%)]\tLoss: 738.331421\n",
      "Train Epoch: 14 [7000/39785 (0%)]\tLoss: 510.548157\n",
      "Train Epoch: 14 [8000/39785 (0%)]\tLoss: 553.758911\n",
      "Train Epoch: 14 [9000/39785 (0%)]\tLoss: 465.566681\n",
      "Train Epoch: 14 [10000/39785 (0%)]\tLoss: 524.275574\n",
      "Train Epoch: 14 [11000/39785 (0%)]\tLoss: 421.862518\n",
      "Train Epoch: 14 [12000/39785 (0%)]\tLoss: 437.805206\n",
      "Train Epoch: 14 [13000/39785 (0%)]\tLoss: 389.646759\n",
      "Train Epoch: 14 [14000/39785 (0%)]\tLoss: 541.741394\n",
      "Train Epoch: 14 [15000/39785 (0%)]\tLoss: 484.275238\n",
      "Train Epoch: 14 [16000/39785 (0%)]\tLoss: 367.468231\n",
      "Train Epoch: 14 [17000/39785 (0%)]\tLoss: 519.649231\n",
      "Train Epoch: 14 [18000/39785 (0%)]\tLoss: 328.996155\n",
      "Train Epoch: 14 [19000/39785 (0%)]\tLoss: 290.773834\n",
      "Train Epoch: 14 [20000/39785 (1%)]\tLoss: 284.464874\n",
      "Train Epoch: 14 [21000/39785 (1%)]\tLoss: 390.648102\n",
      "Train Epoch: 14 [22000/39785 (1%)]\tLoss: 324.877472\n",
      "Train Epoch: 14 [23000/39785 (1%)]\tLoss: 387.107788\n",
      "Train Epoch: 14 [24000/39785 (1%)]\tLoss: 360.706512\n",
      "Train Epoch: 14 [25000/39785 (1%)]\tLoss: 390.417816\n",
      "Train Epoch: 14 [26000/39785 (1%)]\tLoss: 567.196167\n",
      "Train Epoch: 14 [27000/39785 (1%)]\tLoss: 411.522369\n",
      "Train Epoch: 14 [28000/39785 (1%)]\tLoss: 386.725616\n",
      "Train Epoch: 14 [29000/39785 (1%)]\tLoss: 305.016998\n",
      "Train Epoch: 14 [30000/39785 (1%)]\tLoss: 353.020966\n",
      "Train Epoch: 14 [31000/39785 (1%)]\tLoss: 317.530304\n",
      "Train Epoch: 14 [32000/39785 (1%)]\tLoss: 359.245026\n",
      "Train Epoch: 14 [33000/39785 (1%)]\tLoss: 349.470459\n",
      "Train Epoch: 14 [34000/39785 (1%)]\tLoss: 293.489227\n",
      "Train Epoch: 14 [35000/39785 (1%)]\tLoss: 301.701721\n",
      "Train Epoch: 14 [36000/39785 (1%)]\tLoss: 257.165131\n",
      "Train Epoch: 14 [37000/39785 (1%)]\tLoss: 313.090546\n",
      "Train Epoch: 14 [38000/39785 (1%)]\tLoss: 252.077698\n",
      "Train Epoch: 14 [39000/39785 (1%)]\tLoss: 402.838623\n",
      "39695\n",
      "39785\n",
      "Train Epoch: 15 [1000/39785 (0%)]\tLoss: 191.767349\n",
      "Train Epoch: 15 [2000/39785 (0%)]\tLoss: 348.947174\n",
      "Train Epoch: 15 [3000/39785 (0%)]\tLoss: 224.994339\n",
      "Train Epoch: 15 [4000/39785 (0%)]\tLoss: 198.230728\n",
      "Train Epoch: 15 [5000/39785 (0%)]\tLoss: 232.214066\n",
      "Train Epoch: 15 [6000/39785 (0%)]\tLoss: 324.142181\n",
      "Train Epoch: 15 [7000/39785 (0%)]\tLoss: 222.405273\n",
      "Train Epoch: 15 [8000/39785 (0%)]\tLoss: 265.953491\n",
      "Train Epoch: 15 [9000/39785 (0%)]\tLoss: 347.234955\n",
      "Train Epoch: 15 [10000/39785 (0%)]\tLoss: 226.738770\n",
      "Train Epoch: 15 [11000/39785 (0%)]\tLoss: 262.553680\n",
      "Train Epoch: 15 [12000/39785 (0%)]\tLoss: 221.785934\n",
      "Train Epoch: 15 [13000/39785 (0%)]\tLoss: 261.955170\n",
      "Train Epoch: 15 [14000/39785 (0%)]\tLoss: 232.323929\n",
      "Train Epoch: 15 [15000/39785 (0%)]\tLoss: 292.329071\n",
      "Train Epoch: 15 [16000/39785 (0%)]\tLoss: 218.486237\n",
      "Train Epoch: 15 [17000/39785 (0%)]\tLoss: 256.027283\n",
      "Train Epoch: 15 [18000/39785 (0%)]\tLoss: 252.969971\n",
      "Train Epoch: 15 [19000/39785 (0%)]\tLoss: 291.078979\n",
      "Train Epoch: 15 [20000/39785 (1%)]\tLoss: 289.920502\n",
      "Train Epoch: 15 [21000/39785 (1%)]\tLoss: 286.349915\n",
      "Train Epoch: 15 [22000/39785 (1%)]\tLoss: 302.296967\n",
      "Train Epoch: 15 [23000/39785 (1%)]\tLoss: 222.439499\n",
      "Train Epoch: 15 [24000/39785 (1%)]\tLoss: 244.644638\n",
      "Train Epoch: 15 [25000/39785 (1%)]\tLoss: 293.329498\n",
      "Train Epoch: 15 [26000/39785 (1%)]\tLoss: 182.315125\n",
      "Train Epoch: 15 [27000/39785 (1%)]\tLoss: 250.388214\n",
      "Train Epoch: 15 [28000/39785 (1%)]\tLoss: 251.297836\n",
      "Train Epoch: 15 [29000/39785 (1%)]\tLoss: 5356.240234\n",
      "Train Epoch: 15 [30000/39785 (1%)]\tLoss: 3133.477783\n",
      "Train Epoch: 15 [31000/39785 (1%)]\tLoss: 1051.229370\n",
      "Train Epoch: 15 [32000/39785 (1%)]\tLoss: 800.526123\n",
      "Train Epoch: 15 [33000/39785 (1%)]\tLoss: 610.539856\n",
      "Train Epoch: 15 [34000/39785 (1%)]\tLoss: 480.001282\n",
      "Train Epoch: 15 [35000/39785 (1%)]\tLoss: 401.391327\n",
      "Train Epoch: 15 [36000/39785 (1%)]\tLoss: 395.440491\n",
      "Train Epoch: 15 [37000/39785 (1%)]\tLoss: 447.638214\n",
      "Train Epoch: 15 [38000/39785 (1%)]\tLoss: 306.164490\n",
      "Train Epoch: 15 [39000/39785 (1%)]\tLoss: 287.846893\n",
      "39710\n",
      "39785\n",
      "Train Epoch: 16 [1000/39785 (0%)]\tLoss: 281.395386\n",
      "Train Epoch: 16 [2000/39785 (0%)]\tLoss: 480.362671\n",
      "Train Epoch: 16 [3000/39785 (0%)]\tLoss: 437.126556\n",
      "Train Epoch: 16 [4000/39785 (0%)]\tLoss: 628.821472\n",
      "Train Epoch: 16 [5000/39785 (0%)]\tLoss: 361.501251\n",
      "Train Epoch: 16 [6000/39785 (0%)]\tLoss: 226.575333\n",
      "Train Epoch: 16 [7000/39785 (0%)]\tLoss: 283.000854\n",
      "Train Epoch: 16 [8000/39785 (0%)]\tLoss: 255.876846\n",
      "Train Epoch: 16 [9000/39785 (0%)]\tLoss: 246.060043\n",
      "Train Epoch: 16 [10000/39785 (0%)]\tLoss: 462.149506\n",
      "Train Epoch: 16 [11000/39785 (0%)]\tLoss: 339.911163\n",
      "Train Epoch: 16 [12000/39785 (0%)]\tLoss: 263.094299\n",
      "Train Epoch: 16 [13000/39785 (0%)]\tLoss: 288.788910\n",
      "Train Epoch: 16 [14000/39785 (0%)]\tLoss: 356.493744\n",
      "Train Epoch: 16 [15000/39785 (0%)]\tLoss: 189.483490\n",
      "Train Epoch: 16 [16000/39785 (0%)]\tLoss: 277.234528\n",
      "Train Epoch: 16 [17000/39785 (0%)]\tLoss: 240.689209\n",
      "Train Epoch: 16 [18000/39785 (0%)]\tLoss: 188.256393\n",
      "Train Epoch: 16 [19000/39785 (0%)]\tLoss: 291.643127\n",
      "Train Epoch: 16 [20000/39785 (1%)]\tLoss: 287.582794\n",
      "Train Epoch: 16 [21000/39785 (1%)]\tLoss: 243.081818\n",
      "Train Epoch: 16 [22000/39785 (1%)]\tLoss: 731.354614\n",
      "Train Epoch: 16 [23000/39785 (1%)]\tLoss: 373.485382\n",
      "Train Epoch: 16 [24000/39785 (1%)]\tLoss: 299.579865\n",
      "Train Epoch: 16 [25000/39785 (1%)]\tLoss: 239.135742\n",
      "Train Epoch: 16 [26000/39785 (1%)]\tLoss: 203.932663\n",
      "Train Epoch: 16 [27000/39785 (1%)]\tLoss: 204.868378\n",
      "Train Epoch: 16 [28000/39785 (1%)]\tLoss: 193.989731\n",
      "Train Epoch: 16 [29000/39785 (1%)]\tLoss: 246.263519\n",
      "Train Epoch: 16 [30000/39785 (1%)]\tLoss: 280.900360\n",
      "Train Epoch: 16 [31000/39785 (1%)]\tLoss: 411.867371\n",
      "Train Epoch: 16 [32000/39785 (1%)]\tLoss: 218.443817\n",
      "Train Epoch: 16 [33000/39785 (1%)]\tLoss: 184.863968\n",
      "Train Epoch: 16 [34000/39785 (1%)]\tLoss: 210.542480\n",
      "Train Epoch: 16 [35000/39785 (1%)]\tLoss: 187.342361\n",
      "Train Epoch: 16 [36000/39785 (1%)]\tLoss: 278.209686\n",
      "Train Epoch: 16 [37000/39785 (1%)]\tLoss: 243.984467\n",
      "Train Epoch: 16 [38000/39785 (1%)]\tLoss: 304.634338\n",
      "Train Epoch: 16 [39000/39785 (1%)]\tLoss: 269.896057\n",
      "39725\n",
      "39785\n",
      "Train Epoch: 17 [1000/39785 (0%)]\tLoss: 3665.122559\n",
      "Train Epoch: 17 [2000/39785 (0%)]\tLoss: 1183.149658\n",
      "Train Epoch: 17 [3000/39785 (0%)]\tLoss: 822.130676\n",
      "Train Epoch: 17 [4000/39785 (0%)]\tLoss: 690.165222\n",
      "Train Epoch: 17 [5000/39785 (0%)]\tLoss: 491.772583\n",
      "Train Epoch: 17 [6000/39785 (0%)]\tLoss: 381.899750\n",
      "Train Epoch: 17 [7000/39785 (0%)]\tLoss: 408.696533\n",
      "Train Epoch: 17 [8000/39785 (0%)]\tLoss: 368.030121\n",
      "Train Epoch: 17 [9000/39785 (0%)]\tLoss: 293.344604\n",
      "Train Epoch: 17 [10000/39785 (0%)]\tLoss: 345.813843\n",
      "Train Epoch: 17 [11000/39785 (0%)]\tLoss: 390.810822\n",
      "Train Epoch: 17 [12000/39785 (0%)]\tLoss: 350.321991\n",
      "Train Epoch: 17 [13000/39785 (0%)]\tLoss: 292.660492\n",
      "Train Epoch: 17 [14000/39785 (0%)]\tLoss: 427.906158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [15000/39785 (0%)]\tLoss: 305.975708\n",
      "Train Epoch: 17 [16000/39785 (0%)]\tLoss: 338.773560\n",
      "Train Epoch: 17 [17000/39785 (0%)]\tLoss: 365.518311\n",
      "Train Epoch: 17 [18000/39785 (0%)]\tLoss: 254.789993\n",
      "Train Epoch: 17 [19000/39785 (0%)]\tLoss: 391.823395\n",
      "Train Epoch: 17 [20000/39785 (1%)]\tLoss: 361.137756\n",
      "Train Epoch: 17 [21000/39785 (1%)]\tLoss: 238.595108\n",
      "Train Epoch: 17 [22000/39785 (1%)]\tLoss: 311.331635\n",
      "Train Epoch: 17 [23000/39785 (1%)]\tLoss: 269.847229\n",
      "Train Epoch: 17 [24000/39785 (1%)]\tLoss: 256.381744\n",
      "Train Epoch: 17 [25000/39785 (1%)]\tLoss: 238.524673\n",
      "Train Epoch: 17 [26000/39785 (1%)]\tLoss: 196.899612\n",
      "Train Epoch: 17 [27000/39785 (1%)]\tLoss: 305.801971\n",
      "Train Epoch: 17 [28000/39785 (1%)]\tLoss: 268.996948\n",
      "Train Epoch: 17 [29000/39785 (1%)]\tLoss: 13286.778320\n",
      "Train Epoch: 17 [30000/39785 (1%)]\tLoss: 1313.130127\n",
      "Train Epoch: 17 [31000/39785 (1%)]\tLoss: 1179.322876\n",
      "Train Epoch: 17 [32000/39785 (1%)]\tLoss: 782.432617\n",
      "Train Epoch: 17 [33000/39785 (1%)]\tLoss: 605.575012\n",
      "Train Epoch: 17 [34000/39785 (1%)]\tLoss: 521.162964\n",
      "Train Epoch: 17 [35000/39785 (1%)]\tLoss: 385.380493\n",
      "Train Epoch: 17 [36000/39785 (1%)]\tLoss: 418.665253\n",
      "Train Epoch: 17 [37000/39785 (1%)]\tLoss: 431.931946\n",
      "Train Epoch: 17 [38000/39785 (1%)]\tLoss: 450.378235\n",
      "Train Epoch: 17 [39000/39785 (1%)]\tLoss: 361.119141\n",
      "39740\n",
      "39785\n",
      "Train Epoch: 18 [1000/39785 (0%)]\tLoss: 325.444519\n",
      "Train Epoch: 18 [2000/39785 (0%)]\tLoss: 284.352997\n",
      "Train Epoch: 18 [3000/39785 (0%)]\tLoss: 286.142181\n",
      "Train Epoch: 18 [4000/39785 (0%)]\tLoss: 380.714081\n",
      "Train Epoch: 18 [5000/39785 (0%)]\tLoss: 274.201660\n",
      "Train Epoch: 18 [6000/39785 (0%)]\tLoss: 276.249756\n",
      "Train Epoch: 18 [7000/39785 (0%)]\tLoss: 328.944000\n",
      "Train Epoch: 18 [8000/39785 (0%)]\tLoss: 263.188293\n",
      "Train Epoch: 18 [9000/39785 (0%)]\tLoss: 55526.093750\n",
      "Train Epoch: 18 [10000/39785 (0%)]\tLoss: 3004.002686\n",
      "Train Epoch: 18 [11000/39785 (0%)]\tLoss: 3071.859863\n",
      "Train Epoch: 18 [12000/39785 (0%)]\tLoss: 1079.282104\n",
      "Train Epoch: 18 [13000/39785 (0%)]\tLoss: 854.202820\n",
      "Train Epoch: 18 [14000/39785 (0%)]\tLoss: 685.489014\n",
      "Train Epoch: 18 [15000/39785 (0%)]\tLoss: 724.813110\n",
      "Train Epoch: 18 [16000/39785 (0%)]\tLoss: 911.608582\n",
      "Train Epoch: 18 [17000/39785 (0%)]\tLoss: 648.094543\n",
      "Train Epoch: 18 [18000/39785 (0%)]\tLoss: 479.612640\n",
      "Train Epoch: 18 [19000/39785 (0%)]\tLoss: 502.122925\n",
      "Train Epoch: 18 [20000/39785 (1%)]\tLoss: 396.732574\n",
      "Train Epoch: 18 [21000/39785 (1%)]\tLoss: 358.245270\n",
      "Train Epoch: 18 [22000/39785 (1%)]\tLoss: 503.396790\n",
      "Train Epoch: 18 [23000/39785 (1%)]\tLoss: 448.938293\n",
      "Train Epoch: 18 [24000/39785 (1%)]\tLoss: 426.070465\n",
      "Train Epoch: 18 [25000/39785 (1%)]\tLoss: 334.272858\n",
      "Train Epoch: 18 [26000/39785 (1%)]\tLoss: 330.701813\n",
      "Train Epoch: 18 [27000/39785 (1%)]\tLoss: 334.357086\n",
      "Train Epoch: 18 [28000/39785 (1%)]\tLoss: 323.293091\n",
      "Train Epoch: 18 [29000/39785 (1%)]\tLoss: 421.364777\n",
      "Train Epoch: 18 [30000/39785 (1%)]\tLoss: 351.050812\n",
      "Train Epoch: 18 [31000/39785 (1%)]\tLoss: 293.255005\n",
      "Train Epoch: 18 [32000/39785 (1%)]\tLoss: 302.278107\n",
      "Train Epoch: 18 [33000/39785 (1%)]\tLoss: 285.820709\n",
      "Train Epoch: 18 [34000/39785 (1%)]\tLoss: 306.227234\n",
      "Train Epoch: 18 [35000/39785 (1%)]\tLoss: 392.354370\n",
      "Train Epoch: 18 [36000/39785 (1%)]\tLoss: 421.794617\n",
      "Train Epoch: 18 [37000/39785 (1%)]\tLoss: 288.702545\n",
      "Train Epoch: 18 [38000/39785 (1%)]\tLoss: 264.963318\n",
      "Train Epoch: 18 [39000/39785 (1%)]\tLoss: 221.828827\n",
      "39755\n",
      "39785\n",
      "Train Epoch: 19 [1000/39785 (0%)]\tLoss: 293.585632\n",
      "Train Epoch: 19 [2000/39785 (0%)]\tLoss: 235.296265\n",
      "Train Epoch: 19 [3000/39785 (0%)]\tLoss: 302.727356\n",
      "Train Epoch: 19 [4000/39785 (0%)]\tLoss: 220.303665\n",
      "Train Epoch: 19 [5000/39785 (0%)]\tLoss: 228.726181\n",
      "Train Epoch: 19 [6000/39785 (0%)]\tLoss: 224.548706\n",
      "Train Epoch: 19 [7000/39785 (0%)]\tLoss: 251.011154\n",
      "Train Epoch: 19 [8000/39785 (0%)]\tLoss: 226.837372\n",
      "Train Epoch: 19 [9000/39785 (0%)]\tLoss: 8817.190430\n",
      "Train Epoch: 19 [10000/39785 (0%)]\tLoss: 7143.634766\n",
      "Train Epoch: 19 [11000/39785 (0%)]\tLoss: 2948.967041\n",
      "Train Epoch: 19 [12000/39785 (0%)]\tLoss: 2563.681396\n",
      "Train Epoch: 19 [13000/39785 (0%)]\tLoss: 904.395386\n",
      "Train Epoch: 19 [14000/39785 (0%)]\tLoss: 742.718384\n",
      "Train Epoch: 19 [15000/39785 (0%)]\tLoss: 680.586914\n",
      "Train Epoch: 19 [16000/39785 (0%)]\tLoss: 710.862549\n",
      "Train Epoch: 19 [17000/39785 (0%)]\tLoss: 509.232574\n",
      "Train Epoch: 19 [18000/39785 (0%)]\tLoss: 553.945557\n",
      "Train Epoch: 19 [19000/39785 (0%)]\tLoss: 462.745880\n",
      "Train Epoch: 19 [20000/39785 (1%)]\tLoss: 448.273438\n",
      "Train Epoch: 19 [21000/39785 (1%)]\tLoss: 382.000488\n",
      "Train Epoch: 19 [22000/39785 (1%)]\tLoss: 395.991394\n",
      "Train Epoch: 19 [23000/39785 (1%)]\tLoss: 508.906525\n",
      "Train Epoch: 19 [24000/39785 (1%)]\tLoss: 427.815338\n",
      "Train Epoch: 19 [25000/39785 (1%)]\tLoss: 474.843353\n",
      "Train Epoch: 19 [26000/39785 (1%)]\tLoss: 385.486084\n",
      "Train Epoch: 19 [27000/39785 (1%)]\tLoss: 375.747528\n",
      "Train Epoch: 19 [28000/39785 (1%)]\tLoss: 317.974243\n",
      "Train Epoch: 19 [29000/39785 (1%)]\tLoss: 300.945801\n",
      "Train Epoch: 19 [30000/39785 (1%)]\tLoss: 394.131073\n",
      "Train Epoch: 19 [31000/39785 (1%)]\tLoss: 342.387573\n",
      "Train Epoch: 19 [32000/39785 (1%)]\tLoss: 393.078156\n",
      "Train Epoch: 19 [33000/39785 (1%)]\tLoss: 310.992035\n",
      "Train Epoch: 19 [34000/39785 (1%)]\tLoss: 313.101135\n",
      "Train Epoch: 19 [35000/39785 (1%)]\tLoss: 381.650848\n",
      "Train Epoch: 19 [36000/39785 (1%)]\tLoss: 303.821594\n",
      "Train Epoch: 19 [37000/39785 (1%)]\tLoss: 358.617554\n",
      "Train Epoch: 19 [38000/39785 (1%)]\tLoss: 313.614014\n",
      "Train Epoch: 19 [39000/39785 (1%)]\tLoss: 432.304199\n",
      "39770\n",
      "39785\n",
      "Train Epoch: 20 [1000/39785 (0%)]\tLoss: 352.042786\n",
      "Train Epoch: 20 [2000/39785 (0%)]\tLoss: 364.473755\n",
      "Train Epoch: 20 [3000/39785 (0%)]\tLoss: 302.142700\n",
      "Train Epoch: 20 [4000/39785 (0%)]\tLoss: 253.196091\n",
      "Train Epoch: 20 [5000/39785 (0%)]\tLoss: 260.038818\n",
      "Train Epoch: 20 [6000/39785 (0%)]\tLoss: 319.981873\n",
      "Train Epoch: 20 [7000/39785 (0%)]\tLoss: 309.136169\n",
      "Train Epoch: 20 [8000/39785 (0%)]\tLoss: 5394.937500\n",
      "Train Epoch: 20 [9000/39785 (0%)]\tLoss: 6812.352539\n",
      "Train Epoch: 20 [10000/39785 (0%)]\tLoss: 7145.721680\n",
      "Train Epoch: 20 [11000/39785 (0%)]\tLoss: 2797.677979\n",
      "Train Epoch: 20 [12000/39785 (0%)]\tLoss: 2030.055542\n",
      "Train Epoch: 20 [13000/39785 (0%)]\tLoss: 1779.241333\n",
      "Train Epoch: 20 [14000/39785 (0%)]\tLoss: 1043.632324\n",
      "Train Epoch: 20 [15000/39785 (0%)]\tLoss: 926.387451\n",
      "Train Epoch: 20 [16000/39785 (0%)]\tLoss: 814.169861\n",
      "Train Epoch: 20 [17000/39785 (0%)]\tLoss: 542.141907\n",
      "Train Epoch: 20 [18000/39785 (0%)]\tLoss: 721.216797\n",
      "Train Epoch: 20 [19000/39785 (0%)]\tLoss: 575.312439\n",
      "Train Epoch: 20 [20000/39785 (1%)]\tLoss: 766.586731\n",
      "Train Epoch: 20 [21000/39785 (1%)]\tLoss: 564.664429\n",
      "Train Epoch: 20 [22000/39785 (1%)]\tLoss: 577.468201\n",
      "Train Epoch: 20 [23000/39785 (1%)]\tLoss: 463.271851\n",
      "Train Epoch: 20 [24000/39785 (1%)]\tLoss: 409.179077\n",
      "Train Epoch: 20 [25000/39785 (1%)]\tLoss: 841.081665\n",
      "Train Epoch: 20 [26000/39785 (1%)]\tLoss: 331.284485\n",
      "Train Epoch: 20 [27000/39785 (1%)]\tLoss: 399.166016\n",
      "Train Epoch: 20 [28000/39785 (1%)]\tLoss: 325.508759\n",
      "Train Epoch: 20 [29000/39785 (1%)]\tLoss: 323.367310\n",
      "Train Epoch: 20 [30000/39785 (1%)]\tLoss: 402.524536\n",
      "Train Epoch: 20 [31000/39785 (1%)]\tLoss: 381.541779\n",
      "Train Epoch: 20 [32000/39785 (1%)]\tLoss: 412.035248\n",
      "Train Epoch: 20 [33000/39785 (1%)]\tLoss: 336.929657\n",
      "Train Epoch: 20 [34000/39785 (1%)]\tLoss: 314.776611\n",
      "Train Epoch: 20 [35000/39785 (1%)]\tLoss: 580.365295\n",
      "Train Epoch: 20 [36000/39785 (1%)]\tLoss: 362.400574\n",
      "Train Epoch: 20 [37000/39785 (1%)]\tLoss: 370.177094\n",
      "Train Epoch: 20 [38000/39785 (1%)]\tLoss: 440.155029\n",
      "Train Epoch: 20 [39000/39785 (1%)]\tLoss: 446.862640\n",
      "39685\n",
      "39785\n",
      "39785\n",
      "39785\n",
      "Train Epoch: 22 [1000/39785 (0%)]\tLoss: 233.560532\n",
      "Train Epoch: 22 [2000/39785 (0%)]\tLoss: 314.883789\n",
      "Train Epoch: 22 [3000/39785 (0%)]\tLoss: 292.048645\n",
      "Train Epoch: 22 [4000/39785 (0%)]\tLoss: 329.069061\n",
      "Train Epoch: 22 [5000/39785 (0%)]\tLoss: 260.688477\n",
      "Train Epoch: 22 [6000/39785 (0%)]\tLoss: 250.417740\n",
      "Train Epoch: 22 [7000/39785 (0%)]\tLoss: 304.046692\n",
      "Train Epoch: 22 [8000/39785 (0%)]\tLoss: 232.882782\n",
      "Train Epoch: 22 [9000/39785 (0%)]\tLoss: 245.301285\n",
      "Train Epoch: 22 [10000/39785 (0%)]\tLoss: 251.094650\n",
      "Train Epoch: 22 [11000/39785 (0%)]\tLoss: 240.409149\n",
      "Train Epoch: 22 [12000/39785 (0%)]\tLoss: 276.884216\n",
      "Train Epoch: 22 [13000/39785 (0%)]\tLoss: 308.958893\n",
      "Train Epoch: 22 [14000/39785 (0%)]\tLoss: 232.672974\n",
      "Train Epoch: 22 [15000/39785 (0%)]\tLoss: 237.052887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [16000/39785 (0%)]\tLoss: 279.963654\n",
      "Train Epoch: 22 [17000/39785 (0%)]\tLoss: 2179.580811\n",
      "Train Epoch: 22 [18000/39785 (0%)]\tLoss: 7381.197754\n",
      "Train Epoch: 22 [19000/39785 (0%)]\tLoss: 1068.999756\n",
      "Train Epoch: 22 [20000/39785 (1%)]\tLoss: 551.577698\n",
      "Train Epoch: 22 [21000/39785 (1%)]\tLoss: 496.914124\n",
      "Train Epoch: 22 [22000/39785 (1%)]\tLoss: 410.606445\n",
      "Train Epoch: 22 [23000/39785 (1%)]\tLoss: 404.816223\n",
      "Train Epoch: 22 [24000/39785 (1%)]\tLoss: 410.224945\n",
      "Train Epoch: 22 [25000/39785 (1%)]\tLoss: 302.351227\n",
      "Train Epoch: 22 [26000/39785 (1%)]\tLoss: 307.191986\n",
      "Train Epoch: 22 [27000/39785 (1%)]\tLoss: 299.496155\n",
      "Train Epoch: 22 [28000/39785 (1%)]\tLoss: 324.316345\n",
      "Train Epoch: 22 [29000/39785 (1%)]\tLoss: 305.786896\n",
      "Train Epoch: 22 [30000/39785 (1%)]\tLoss: 255.715149\n",
      "Train Epoch: 22 [31000/39785 (1%)]\tLoss: 267.314819\n",
      "Train Epoch: 22 [32000/39785 (1%)]\tLoss: 259.120636\n",
      "Train Epoch: 22 [33000/39785 (1%)]\tLoss: 278.312378\n",
      "Train Epoch: 22 [34000/39785 (1%)]\tLoss: 367.373291\n",
      "Train Epoch: 22 [35000/39785 (1%)]\tLoss: 235.951096\n",
      "Train Epoch: 22 [36000/39785 (1%)]\tLoss: 291.570129\n",
      "Train Epoch: 22 [37000/39785 (1%)]\tLoss: 250.316162\n",
      "Train Epoch: 22 [38000/39785 (1%)]\tLoss: 285.249786\n",
      "Train Epoch: 22 [39000/39785 (1%)]\tLoss: 250.265656\n",
      "39700\n",
      "39785\n",
      "Train Epoch: 23 [1000/39785 (0%)]\tLoss: 270.667206\n",
      "Train Epoch: 23 [2000/39785 (0%)]\tLoss: 297.322937\n",
      "Train Epoch: 23 [3000/39785 (0%)]\tLoss: 291.404449\n",
      "Train Epoch: 23 [4000/39785 (0%)]\tLoss: 236.384308\n",
      "Train Epoch: 23 [5000/39785 (0%)]\tLoss: 246.456085\n",
      "Train Epoch: 23 [6000/39785 (0%)]\tLoss: 195.733719\n",
      "Train Epoch: 23 [7000/39785 (0%)]\tLoss: 181.209625\n",
      "Train Epoch: 23 [8000/39785 (0%)]\tLoss: 212.368317\n",
      "Train Epoch: 23 [9000/39785 (0%)]\tLoss: 315.489532\n",
      "Train Epoch: 23 [10000/39785 (0%)]\tLoss: 664.526062\n",
      "Train Epoch: 23 [11000/39785 (0%)]\tLoss: 369.963348\n",
      "Train Epoch: 23 [12000/39785 (0%)]\tLoss: 342.985596\n",
      "Train Epoch: 23 [13000/39785 (0%)]\tLoss: 303.610138\n",
      "Train Epoch: 23 [14000/39785 (0%)]\tLoss: 248.856842\n",
      "Train Epoch: 23 [15000/39785 (0%)]\tLoss: 228.648697\n",
      "Train Epoch: 23 [16000/39785 (0%)]\tLoss: 196.081772\n",
      "Train Epoch: 23 [17000/39785 (0%)]\tLoss: 249.406143\n",
      "Train Epoch: 23 [18000/39785 (0%)]\tLoss: 204.727585\n",
      "Train Epoch: 23 [19000/39785 (0%)]\tLoss: 265.704926\n",
      "Train Epoch: 23 [20000/39785 (1%)]\tLoss: 205.689529\n",
      "Train Epoch: 23 [21000/39785 (1%)]\tLoss: 255.250900\n",
      "Train Epoch: 23 [22000/39785 (1%)]\tLoss: 275.887695\n",
      "Train Epoch: 23 [23000/39785 (1%)]\tLoss: 259.441864\n",
      "Train Epoch: 23 [24000/39785 (1%)]\tLoss: 233.946548\n",
      "Train Epoch: 23 [25000/39785 (1%)]\tLoss: 215.396667\n",
      "Train Epoch: 23 [26000/39785 (1%)]\tLoss: 224.860886\n",
      "Train Epoch: 23 [27000/39785 (1%)]\tLoss: 162.766891\n",
      "Train Epoch: 23 [28000/39785 (1%)]\tLoss: 174.592422\n",
      "Train Epoch: 23 [29000/39785 (1%)]\tLoss: 222.495865\n",
      "Train Epoch: 23 [30000/39785 (1%)]\tLoss: 186.320236\n",
      "Train Epoch: 23 [31000/39785 (1%)]\tLoss: 214.917801\n",
      "Train Epoch: 23 [32000/39785 (1%)]\tLoss: 222.125778\n",
      "Train Epoch: 23 [33000/39785 (1%)]\tLoss: 247.167114\n",
      "Train Epoch: 23 [34000/39785 (1%)]\tLoss: 192.748062\n",
      "Train Epoch: 23 [35000/39785 (1%)]\tLoss: 195.616028\n",
      "Train Epoch: 23 [36000/39785 (1%)]\tLoss: 195.657257\n",
      "Train Epoch: 23 [37000/39785 (1%)]\tLoss: 241.853745\n",
      "Train Epoch: 23 [38000/39785 (1%)]\tLoss: 212.705261\n",
      "Train Epoch: 23 [39000/39785 (1%)]\tLoss: 188.172989\n",
      "39715\n",
      "39785\n",
      "Train Epoch: 24 [1000/39785 (0%)]\tLoss: 200.149063\n",
      "Train Epoch: 24 [2000/39785 (0%)]\tLoss: 185.599808\n",
      "Train Epoch: 24 [3000/39785 (0%)]\tLoss: 164.362930\n",
      "Train Epoch: 24 [4000/39785 (0%)]\tLoss: 210.895020\n",
      "Train Epoch: 24 [5000/39785 (0%)]\tLoss: 168.043777\n",
      "Train Epoch: 24 [6000/39785 (0%)]\tLoss: 228.630081\n",
      "Train Epoch: 24 [7000/39785 (0%)]\tLoss: 203.066849\n",
      "Train Epoch: 24 [8000/39785 (0%)]\tLoss: 279.496643\n",
      "Train Epoch: 24 [9000/39785 (0%)]\tLoss: 186.672119\n",
      "Train Epoch: 24 [10000/39785 (0%)]\tLoss: 167.313553\n",
      "Train Epoch: 24 [11000/39785 (0%)]\tLoss: 159.468643\n",
      "Train Epoch: 24 [12000/39785 (0%)]\tLoss: 152.378632\n",
      "Train Epoch: 24 [13000/39785 (0%)]\tLoss: 171.051147\n",
      "Train Epoch: 24 [14000/39785 (0%)]\tLoss: 266.293060\n",
      "Train Epoch: 24 [15000/39785 (0%)]\tLoss: 273.549774\n",
      "Train Epoch: 24 [16000/39785 (0%)]\tLoss: 244.179810\n",
      "Train Epoch: 24 [17000/39785 (0%)]\tLoss: 287.377380\n",
      "Train Epoch: 24 [18000/39785 (0%)]\tLoss: 195.469574\n",
      "Train Epoch: 24 [19000/39785 (0%)]\tLoss: 239.151566\n",
      "Train Epoch: 24 [20000/39785 (1%)]\tLoss: 202.194382\n",
      "Train Epoch: 24 [21000/39785 (1%)]\tLoss: 185.196472\n",
      "Train Epoch: 24 [22000/39785 (1%)]\tLoss: 218.149078\n",
      "Train Epoch: 24 [23000/39785 (1%)]\tLoss: 242.869370\n",
      "Train Epoch: 24 [24000/39785 (1%)]\tLoss: 254.489380\n",
      "Train Epoch: 24 [25000/39785 (1%)]\tLoss: 218.149765\n",
      "Train Epoch: 24 [26000/39785 (1%)]\tLoss: 218.715149\n",
      "Train Epoch: 24 [27000/39785 (1%)]\tLoss: 293.461670\n",
      "Train Epoch: 24 [28000/39785 (1%)]\tLoss: 179.078186\n",
      "Train Epoch: 24 [29000/39785 (1%)]\tLoss: 189.055710\n",
      "Train Epoch: 24 [30000/39785 (1%)]\tLoss: 187.542511\n",
      "Train Epoch: 24 [31000/39785 (1%)]\tLoss: 292.992340\n",
      "Train Epoch: 24 [32000/39785 (1%)]\tLoss: 178.487396\n",
      "Train Epoch: 24 [33000/39785 (1%)]\tLoss: 238.465179\n",
      "Train Epoch: 24 [34000/39785 (1%)]\tLoss: 238.917191\n",
      "Train Epoch: 24 [35000/39785 (1%)]\tLoss: 193.768448\n",
      "Train Epoch: 24 [36000/39785 (1%)]\tLoss: 210.708359\n",
      "Train Epoch: 24 [37000/39785 (1%)]\tLoss: 207.281403\n",
      "Train Epoch: 24 [38000/39785 (1%)]\tLoss: 211.250443\n",
      "Train Epoch: 24 [39000/39785 (1%)]\tLoss: 197.210495\n",
      "39730\n",
      "39785\n",
      "Train Epoch: 25 [1000/39785 (0%)]\tLoss: 158.905655\n",
      "Train Epoch: 25 [2000/39785 (0%)]\tLoss: 195.837982\n",
      "Train Epoch: 25 [3000/39785 (0%)]\tLoss: 152.740021\n",
      "Train Epoch: 25 [4000/39785 (0%)]\tLoss: 178.126648\n",
      "Train Epoch: 25 [5000/39785 (0%)]\tLoss: 211.969620\n",
      "Train Epoch: 25 [6000/39785 (0%)]\tLoss: 213.297638\n",
      "Train Epoch: 25 [7000/39785 (0%)]\tLoss: 197.268677\n",
      "Train Epoch: 25 [8000/39785 (0%)]\tLoss: 225.345032\n",
      "Train Epoch: 25 [9000/39785 (0%)]\tLoss: 275.343750\n",
      "Train Epoch: 25 [10000/39785 (0%)]\tLoss: 204.995804\n",
      "Train Epoch: 25 [11000/39785 (0%)]\tLoss: 152.908417\n",
      "Train Epoch: 25 [12000/39785 (0%)]\tLoss: 269.848511\n",
      "Train Epoch: 25 [13000/39785 (0%)]\tLoss: 173.663467\n",
      "Train Epoch: 25 [14000/39785 (0%)]\tLoss: 233.260437\n",
      "Train Epoch: 25 [15000/39785 (0%)]\tLoss: 193.393387\n",
      "Train Epoch: 25 [16000/39785 (0%)]\tLoss: 211.661911\n",
      "Train Epoch: 25 [17000/39785 (0%)]\tLoss: 201.483047\n",
      "Train Epoch: 25 [18000/39785 (0%)]\tLoss: 172.853287\n",
      "Train Epoch: 25 [19000/39785 (0%)]\tLoss: 191.285110\n",
      "Train Epoch: 25 [20000/39785 (1%)]\tLoss: 231.746964\n",
      "Train Epoch: 25 [21000/39785 (1%)]\tLoss: 288.033264\n",
      "Train Epoch: 25 [22000/39785 (1%)]\tLoss: 185.255936\n",
      "Train Epoch: 25 [23000/39785 (1%)]\tLoss: 171.148285\n",
      "Train Epoch: 25 [24000/39785 (1%)]\tLoss: 187.691010\n",
      "Train Epoch: 25 [25000/39785 (1%)]\tLoss: 163.146179\n",
      "Train Epoch: 25 [26000/39785 (1%)]\tLoss: 191.037048\n",
      "Train Epoch: 25 [27000/39785 (1%)]\tLoss: 140.848587\n",
      "Train Epoch: 25 [28000/39785 (1%)]\tLoss: 165.568634\n",
      "Train Epoch: 25 [29000/39785 (1%)]\tLoss: 237.683273\n",
      "Train Epoch: 25 [30000/39785 (1%)]\tLoss: 238.248306\n",
      "Train Epoch: 25 [31000/39785 (1%)]\tLoss: 184.434738\n",
      "Train Epoch: 25 [32000/39785 (1%)]\tLoss: 187.577499\n",
      "Train Epoch: 25 [33000/39785 (1%)]\tLoss: 193.063812\n",
      "Train Epoch: 25 [34000/39785 (1%)]\tLoss: 216.101532\n",
      "Train Epoch: 25 [35000/39785 (1%)]\tLoss: 139.657486\n",
      "Train Epoch: 25 [36000/39785 (1%)]\tLoss: 199.945068\n",
      "Train Epoch: 25 [37000/39785 (1%)]\tLoss: 145.533417\n",
      "Train Epoch: 25 [38000/39785 (1%)]\tLoss: 192.923111\n",
      "Train Epoch: 25 [39000/39785 (1%)]\tLoss: 143.459259\n",
      "39745\n",
      "39785\n",
      "Train Epoch: 26 [1000/39785 (0%)]\tLoss: 175.587204\n",
      "Train Epoch: 26 [2000/39785 (0%)]\tLoss: 189.712296\n",
      "Train Epoch: 26 [3000/39785 (0%)]\tLoss: 204.961349\n",
      "Train Epoch: 26 [4000/39785 (0%)]\tLoss: 194.694412\n",
      "Train Epoch: 26 [5000/39785 (0%)]\tLoss: 135.972748\n",
      "Train Epoch: 26 [6000/39785 (0%)]\tLoss: 134.598053\n",
      "Train Epoch: 26 [7000/39785 (0%)]\tLoss: 194.555344\n",
      "Train Epoch: 26 [8000/39785 (0%)]\tLoss: 164.119125\n",
      "Train Epoch: 26 [9000/39785 (0%)]\tLoss: 164.532578\n",
      "Train Epoch: 26 [10000/39785 (0%)]\tLoss: 172.028595\n",
      "Train Epoch: 26 [11000/39785 (0%)]\tLoss: 149.249130\n",
      "Train Epoch: 26 [12000/39785 (0%)]\tLoss: 156.804535\n",
      "Train Epoch: 26 [13000/39785 (0%)]\tLoss: 185.547104\n",
      "Train Epoch: 26 [14000/39785 (0%)]\tLoss: 177.159286\n",
      "Train Epoch: 26 [15000/39785 (0%)]\tLoss: 187.008698\n",
      "Train Epoch: 26 [16000/39785 (0%)]\tLoss: 145.200165\n",
      "Train Epoch: 26 [17000/39785 (0%)]\tLoss: 188.755127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 [18000/39785 (0%)]\tLoss: 204.682831\n",
      "Train Epoch: 26 [19000/39785 (0%)]\tLoss: 158.754074\n",
      "Train Epoch: 26 [20000/39785 (1%)]\tLoss: 122.989746\n",
      "Train Epoch: 26 [21000/39785 (1%)]\tLoss: 166.034042\n",
      "Train Epoch: 26 [22000/39785 (1%)]\tLoss: 202.003830\n",
      "Train Epoch: 26 [23000/39785 (1%)]\tLoss: 167.957031\n",
      "Train Epoch: 26 [24000/39785 (1%)]\tLoss: 156.162399\n",
      "Train Epoch: 26 [25000/39785 (1%)]\tLoss: 209.467346\n",
      "Train Epoch: 26 [26000/39785 (1%)]\tLoss: 167.713791\n",
      "Train Epoch: 26 [27000/39785 (1%)]\tLoss: 211.907700\n",
      "Train Epoch: 26 [28000/39785 (1%)]\tLoss: 206.505707\n",
      "Train Epoch: 26 [29000/39785 (1%)]\tLoss: 168.556961\n",
      "Train Epoch: 26 [30000/39785 (1%)]\tLoss: 195.849121\n",
      "Train Epoch: 26 [31000/39785 (1%)]\tLoss: 210.711945\n",
      "Train Epoch: 26 [32000/39785 (1%)]\tLoss: 207.860504\n",
      "Train Epoch: 26 [33000/39785 (1%)]\tLoss: 227.628281\n",
      "Train Epoch: 26 [34000/39785 (1%)]\tLoss: 176.535400\n",
      "Train Epoch: 26 [35000/39785 (1%)]\tLoss: 188.408142\n",
      "Train Epoch: 26 [36000/39785 (1%)]\tLoss: 197.222870\n",
      "Train Epoch: 26 [37000/39785 (1%)]\tLoss: 192.551086\n",
      "Train Epoch: 26 [38000/39785 (1%)]\tLoss: 167.612183\n",
      "Train Epoch: 26 [39000/39785 (1%)]\tLoss: 220.320786\n",
      "39760\n",
      "39785\n",
      "Train Epoch: 27 [1000/39785 (0%)]\tLoss: 145.073517\n",
      "Train Epoch: 27 [2000/39785 (0%)]\tLoss: 124.464920\n",
      "Train Epoch: 27 [3000/39785 (0%)]\tLoss: 172.851868\n",
      "Train Epoch: 27 [4000/39785 (0%)]\tLoss: 205.253265\n",
      "Train Epoch: 27 [5000/39785 (0%)]\tLoss: 195.868195\n",
      "Train Epoch: 27 [6000/39785 (0%)]\tLoss: 143.945450\n",
      "Train Epoch: 27 [7000/39785 (0%)]\tLoss: 170.719116\n",
      "Train Epoch: 27 [8000/39785 (0%)]\tLoss: 152.333527\n",
      "Train Epoch: 27 [9000/39785 (0%)]\tLoss: 191.029968\n",
      "Train Epoch: 27 [10000/39785 (0%)]\tLoss: 136.879959\n",
      "Train Epoch: 27 [11000/39785 (0%)]\tLoss: 166.397766\n",
      "Train Epoch: 27 [12000/39785 (0%)]\tLoss: 143.850342\n",
      "Train Epoch: 27 [13000/39785 (0%)]\tLoss: 166.385513\n",
      "Train Epoch: 27 [14000/39785 (0%)]\tLoss: 157.899536\n",
      "Train Epoch: 27 [15000/39785 (0%)]\tLoss: 195.134857\n",
      "Train Epoch: 27 [16000/39785 (0%)]\tLoss: 146.341522\n",
      "Train Epoch: 27 [17000/39785 (0%)]\tLoss: 170.245071\n",
      "Train Epoch: 27 [18000/39785 (0%)]\tLoss: 179.081528\n",
      "Train Epoch: 27 [19000/39785 (0%)]\tLoss: 175.347519\n",
      "Train Epoch: 27 [20000/39785 (1%)]\tLoss: 168.048584\n",
      "Train Epoch: 27 [21000/39785 (1%)]\tLoss: 138.609879\n",
      "Train Epoch: 27 [22000/39785 (1%)]\tLoss: 165.731232\n",
      "Train Epoch: 27 [23000/39785 (1%)]\tLoss: 148.000641\n",
      "Train Epoch: 27 [24000/39785 (1%)]\tLoss: 173.937454\n",
      "Train Epoch: 27 [25000/39785 (1%)]\tLoss: 128.895294\n",
      "Train Epoch: 27 [26000/39785 (1%)]\tLoss: 185.090317\n",
      "Train Epoch: 27 [27000/39785 (1%)]\tLoss: 132.803360\n",
      "Train Epoch: 27 [28000/39785 (1%)]\tLoss: 190.369736\n",
      "Train Epoch: 27 [29000/39785 (1%)]\tLoss: 136.357086\n",
      "Train Epoch: 27 [30000/39785 (1%)]\tLoss: 170.119354\n",
      "Train Epoch: 27 [31000/39785 (1%)]\tLoss: 121.718246\n",
      "Train Epoch: 27 [32000/39785 (1%)]\tLoss: 141.859863\n",
      "Train Epoch: 27 [33000/39785 (1%)]\tLoss: 179.890900\n",
      "Train Epoch: 27 [34000/39785 (1%)]\tLoss: 219.383087\n",
      "Train Epoch: 27 [35000/39785 (1%)]\tLoss: 150.992966\n",
      "Train Epoch: 27 [36000/39785 (1%)]\tLoss: 120.752289\n",
      "Train Epoch: 27 [37000/39785 (1%)]\tLoss: 183.103760\n",
      "Train Epoch: 27 [38000/39785 (1%)]\tLoss: 143.745895\n",
      "Train Epoch: 27 [39000/39785 (1%)]\tLoss: 211.105560\n",
      "39775\n",
      "39785\n",
      "Train Epoch: 28 [1000/39785 (0%)]\tLoss: 169.526428\n",
      "Train Epoch: 28 [2000/39785 (0%)]\tLoss: 152.293564\n",
      "Train Epoch: 28 [3000/39785 (0%)]\tLoss: 138.667206\n",
      "Train Epoch: 28 [4000/39785 (0%)]\tLoss: 170.785904\n",
      "Train Epoch: 28 [5000/39785 (0%)]\tLoss: 128.972000\n",
      "Train Epoch: 28 [6000/39785 (0%)]\tLoss: 140.324051\n",
      "Train Epoch: 28 [7000/39785 (0%)]\tLoss: 128.931900\n",
      "Train Epoch: 28 [8000/39785 (0%)]\tLoss: 114.886444\n",
      "Train Epoch: 28 [9000/39785 (0%)]\tLoss: 152.448608\n",
      "Train Epoch: 28 [10000/39785 (0%)]\tLoss: 123.761055\n",
      "Train Epoch: 28 [11000/39785 (0%)]\tLoss: 114.167343\n",
      "Train Epoch: 28 [12000/39785 (0%)]\tLoss: 160.678040\n",
      "Train Epoch: 28 [13000/39785 (0%)]\tLoss: 173.227005\n",
      "Train Epoch: 28 [14000/39785 (0%)]\tLoss: 149.236832\n",
      "Train Epoch: 28 [15000/39785 (0%)]\tLoss: 155.784592\n",
      "Train Epoch: 28 [16000/39785 (0%)]\tLoss: 112.220833\n",
      "Train Epoch: 28 [17000/39785 (0%)]\tLoss: 172.985306\n",
      "Train Epoch: 28 [18000/39785 (0%)]\tLoss: 207.583908\n",
      "Train Epoch: 28 [19000/39785 (0%)]\tLoss: 161.964371\n",
      "Train Epoch: 28 [20000/39785 (1%)]\tLoss: 109.006805\n",
      "Train Epoch: 28 [21000/39785 (1%)]\tLoss: 153.043762\n",
      "Train Epoch: 28 [22000/39785 (1%)]\tLoss: 122.943001\n",
      "Train Epoch: 28 [23000/39785 (1%)]\tLoss: 114.348824\n",
      "Train Epoch: 28 [24000/39785 (1%)]\tLoss: 130.652420\n",
      "Train Epoch: 28 [25000/39785 (1%)]\tLoss: 186.326782\n",
      "Train Epoch: 28 [26000/39785 (1%)]\tLoss: 155.410904\n",
      "Train Epoch: 28 [27000/39785 (1%)]\tLoss: 144.142792\n",
      "Train Epoch: 28 [28000/39785 (1%)]\tLoss: 165.233276\n",
      "Train Epoch: 28 [29000/39785 (1%)]\tLoss: 131.612015\n",
      "Train Epoch: 28 [30000/39785 (1%)]\tLoss: 169.273956\n",
      "Train Epoch: 28 [31000/39785 (1%)]\tLoss: 199.579483\n",
      "Train Epoch: 28 [32000/39785 (1%)]\tLoss: 152.695465\n",
      "Train Epoch: 28 [33000/39785 (1%)]\tLoss: 125.024574\n",
      "Train Epoch: 28 [34000/39785 (1%)]\tLoss: 163.826080\n",
      "Train Epoch: 28 [35000/39785 (1%)]\tLoss: 175.638687\n",
      "Train Epoch: 28 [36000/39785 (1%)]\tLoss: 117.435486\n",
      "Train Epoch: 28 [37000/39785 (1%)]\tLoss: 152.498672\n",
      "Train Epoch: 28 [38000/39785 (1%)]\tLoss: 158.441544\n",
      "Train Epoch: 28 [39000/39785 (1%)]\tLoss: 132.367279\n",
      "39690\n",
      "39785\n",
      "Train Epoch: 29 [1000/39785 (0%)]\tLoss: 101.619385\n",
      "Train Epoch: 29 [2000/39785 (0%)]\tLoss: 190.027939\n",
      "Train Epoch: 29 [3000/39785 (0%)]\tLoss: 154.706421\n",
      "Train Epoch: 29 [4000/39785 (0%)]\tLoss: 99.598656\n",
      "Train Epoch: 29 [5000/39785 (0%)]\tLoss: 136.121887\n",
      "Train Epoch: 29 [6000/39785 (0%)]\tLoss: 195.049316\n",
      "Train Epoch: 29 [7000/39785 (0%)]\tLoss: 119.857513\n",
      "Train Epoch: 29 [8000/39785 (0%)]\tLoss: 174.321350\n",
      "Train Epoch: 29 [9000/39785 (0%)]\tLoss: 129.630188\n",
      "Train Epoch: 29 [10000/39785 (0%)]\tLoss: 131.939514\n",
      "Train Epoch: 29 [11000/39785 (0%)]\tLoss: 170.785522\n",
      "Train Epoch: 29 [12000/39785 (0%)]\tLoss: 180.079239\n",
      "Train Epoch: 29 [13000/39785 (0%)]\tLoss: 153.443069\n",
      "Train Epoch: 29 [14000/39785 (0%)]\tLoss: 153.477951\n",
      "Train Epoch: 29 [15000/39785 (0%)]\tLoss: 179.622299\n",
      "Train Epoch: 29 [16000/39785 (0%)]\tLoss: 140.727386\n",
      "Train Epoch: 29 [17000/39785 (0%)]\tLoss: 172.388489\n",
      "Train Epoch: 29 [18000/39785 (0%)]\tLoss: 184.772980\n",
      "Train Epoch: 29 [19000/39785 (0%)]\tLoss: 130.615402\n",
      "Train Epoch: 29 [20000/39785 (1%)]\tLoss: 132.645554\n",
      "Train Epoch: 29 [21000/39785 (1%)]\tLoss: 127.505150\n",
      "Train Epoch: 29 [22000/39785 (1%)]\tLoss: 131.143173\n",
      "Train Epoch: 29 [23000/39785 (1%)]\tLoss: 122.043777\n",
      "Train Epoch: 29 [24000/39785 (1%)]\tLoss: 134.715134\n",
      "Train Epoch: 29 [25000/39785 (1%)]\tLoss: 122.075470\n",
      "Train Epoch: 29 [26000/39785 (1%)]\tLoss: 175.905212\n",
      "Train Epoch: 29 [27000/39785 (1%)]\tLoss: 105.379372\n",
      "Train Epoch: 29 [28000/39785 (1%)]\tLoss: 117.022911\n",
      "Train Epoch: 29 [29000/39785 (1%)]\tLoss: 119.769501\n",
      "Train Epoch: 29 [30000/39785 (1%)]\tLoss: 141.633789\n",
      "Train Epoch: 29 [31000/39785 (1%)]\tLoss: 148.432220\n",
      "Train Epoch: 29 [32000/39785 (1%)]\tLoss: 146.627014\n",
      "Train Epoch: 29 [33000/39785 (1%)]\tLoss: 165.188644\n",
      "Train Epoch: 29 [34000/39785 (1%)]\tLoss: 118.452728\n",
      "Train Epoch: 29 [35000/39785 (1%)]\tLoss: 168.719711\n",
      "Train Epoch: 29 [36000/39785 (1%)]\tLoss: 181.727921\n",
      "Train Epoch: 29 [37000/39785 (1%)]\tLoss: 138.416611\n",
      "Train Epoch: 29 [38000/39785 (1%)]\tLoss: 187.096512\n",
      "Train Epoch: 29 [39000/39785 (1%)]\tLoss: 161.688461\n",
      "39705\n",
      "39785\n",
      "Train Epoch: 30 [1000/39785 (0%)]\tLoss: 99.363693\n",
      "Train Epoch: 30 [2000/39785 (0%)]\tLoss: 115.478294\n",
      "Train Epoch: 30 [3000/39785 (0%)]\tLoss: 146.050262\n",
      "Train Epoch: 30 [4000/39785 (0%)]\tLoss: 122.103256\n",
      "Train Epoch: 30 [5000/39785 (0%)]\tLoss: 120.181404\n",
      "Train Epoch: 30 [6000/39785 (0%)]\tLoss: 111.867134\n",
      "Train Epoch: 30 [7000/39785 (0%)]\tLoss: 126.549255\n",
      "Train Epoch: 30 [8000/39785 (0%)]\tLoss: 114.304543\n",
      "Train Epoch: 30 [9000/39785 (0%)]\tLoss: 143.778458\n",
      "Train Epoch: 30 [10000/39785 (0%)]\tLoss: 127.934776\n",
      "Train Epoch: 30 [11000/39785 (0%)]\tLoss: 128.581146\n",
      "Train Epoch: 30 [12000/39785 (0%)]\tLoss: 119.419182\n",
      "Train Epoch: 30 [13000/39785 (0%)]\tLoss: 120.790207\n",
      "Train Epoch: 30 [14000/39785 (0%)]\tLoss: 133.408981\n",
      "Train Epoch: 30 [15000/39785 (0%)]\tLoss: 165.288055\n",
      "Train Epoch: 30 [16000/39785 (0%)]\tLoss: 107.020889\n",
      "Train Epoch: 30 [17000/39785 (0%)]\tLoss: 151.228394\n",
      "Train Epoch: 30 [18000/39785 (0%)]\tLoss: 115.301651\n",
      "Train Epoch: 30 [19000/39785 (0%)]\tLoss: 157.793396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30 [20000/39785 (1%)]\tLoss: 102.993111\n",
      "Train Epoch: 30 [21000/39785 (1%)]\tLoss: 156.144836\n",
      "Train Epoch: 30 [22000/39785 (1%)]\tLoss: 135.597580\n",
      "Train Epoch: 30 [23000/39785 (1%)]\tLoss: 119.716614\n",
      "Train Epoch: 30 [24000/39785 (1%)]\tLoss: 202.235580\n",
      "Train Epoch: 30 [25000/39785 (1%)]\tLoss: 121.147942\n",
      "Train Epoch: 30 [26000/39785 (1%)]\tLoss: 143.485031\n",
      "Train Epoch: 30 [27000/39785 (1%)]\tLoss: 127.660789\n",
      "Train Epoch: 30 [28000/39785 (1%)]\tLoss: 143.791718\n",
      "Train Epoch: 30 [29000/39785 (1%)]\tLoss: 139.654984\n",
      "Train Epoch: 30 [30000/39785 (1%)]\tLoss: 168.066574\n",
      "Train Epoch: 30 [31000/39785 (1%)]\tLoss: 109.261139\n",
      "Train Epoch: 30 [32000/39785 (1%)]\tLoss: 106.828537\n",
      "Train Epoch: 30 [33000/39785 (1%)]\tLoss: 199.258713\n",
      "Train Epoch: 30 [34000/39785 (1%)]\tLoss: 133.750885\n",
      "Train Epoch: 30 [35000/39785 (1%)]\tLoss: 146.484116\n",
      "Train Epoch: 30 [36000/39785 (1%)]\tLoss: 156.100174\n",
      "Train Epoch: 30 [37000/39785 (1%)]\tLoss: 145.571762\n",
      "Train Epoch: 30 [38000/39785 (1%)]\tLoss: 134.673340\n",
      "Train Epoch: 30 [39000/39785 (1%)]\tLoss: 170.987335\n",
      "39720\n",
      "39785\n",
      "Train Epoch: 31 [1000/39785 (0%)]\tLoss: 104.812363\n",
      "Train Epoch: 31 [2000/39785 (0%)]\tLoss: 152.447449\n",
      "Train Epoch: 31 [3000/39785 (0%)]\tLoss: 124.876717\n",
      "Train Epoch: 31 [4000/39785 (0%)]\tLoss: 121.485268\n",
      "Train Epoch: 31 [5000/39785 (0%)]\tLoss: 111.069069\n",
      "Train Epoch: 31 [6000/39785 (0%)]\tLoss: 156.951263\n",
      "Train Epoch: 31 [7000/39785 (0%)]\tLoss: 125.998085\n",
      "Train Epoch: 31 [8000/39785 (0%)]\tLoss: 118.367180\n",
      "Train Epoch: 31 [9000/39785 (0%)]\tLoss: 114.340614\n",
      "Train Epoch: 31 [10000/39785 (0%)]\tLoss: 132.762299\n",
      "Train Epoch: 31 [11000/39785 (0%)]\tLoss: 98.642403\n",
      "Train Epoch: 31 [12000/39785 (0%)]\tLoss: 134.670441\n",
      "Train Epoch: 31 [13000/39785 (0%)]\tLoss: 132.395340\n",
      "Train Epoch: 31 [14000/39785 (0%)]\tLoss: 106.660271\n",
      "Train Epoch: 31 [15000/39785 (0%)]\tLoss: 120.516853\n",
      "Train Epoch: 31 [16000/39785 (0%)]\tLoss: 118.319550\n",
      "Train Epoch: 31 [17000/39785 (0%)]\tLoss: 156.601898\n",
      "Train Epoch: 31 [18000/39785 (0%)]\tLoss: 120.756500\n",
      "Train Epoch: 31 [19000/39785 (0%)]\tLoss: 178.689926\n",
      "Train Epoch: 31 [20000/39785 (1%)]\tLoss: 121.254295\n",
      "Train Epoch: 31 [21000/39785 (1%)]\tLoss: 116.954742\n",
      "Train Epoch: 31 [22000/39785 (1%)]\tLoss: 149.601349\n",
      "Train Epoch: 31 [23000/39785 (1%)]\tLoss: 156.529694\n",
      "Train Epoch: 31 [24000/39785 (1%)]\tLoss: 134.478928\n",
      "Train Epoch: 31 [25000/39785 (1%)]\tLoss: 149.235443\n",
      "Train Epoch: 31 [26000/39785 (1%)]\tLoss: 145.609741\n",
      "Train Epoch: 31 [27000/39785 (1%)]\tLoss: 123.616196\n",
      "Train Epoch: 31 [28000/39785 (1%)]\tLoss: 109.403008\n",
      "Train Epoch: 31 [29000/39785 (1%)]\tLoss: 113.960648\n",
      "Train Epoch: 31 [30000/39785 (1%)]\tLoss: 97.170052\n",
      "Train Epoch: 31 [31000/39785 (1%)]\tLoss: 162.850143\n",
      "Train Epoch: 31 [32000/39785 (1%)]\tLoss: 151.977448\n",
      "Train Epoch: 31 [33000/39785 (1%)]\tLoss: 140.813797\n",
      "Train Epoch: 31 [34000/39785 (1%)]\tLoss: 106.886932\n",
      "Train Epoch: 31 [35000/39785 (1%)]\tLoss: 150.696503\n",
      "Train Epoch: 31 [36000/39785 (1%)]\tLoss: 140.269669\n",
      "Train Epoch: 31 [37000/39785 (1%)]\tLoss: 139.885513\n",
      "Train Epoch: 31 [38000/39785 (1%)]\tLoss: 94.320351\n",
      "Train Epoch: 31 [39000/39785 (1%)]\tLoss: 180.753403\n",
      "39735\n",
      "39785\n",
      "Train Epoch: 32 [1000/39785 (0%)]\tLoss: 118.414040\n",
      "Train Epoch: 32 [2000/39785 (0%)]\tLoss: 94.978874\n",
      "Train Epoch: 32 [3000/39785 (0%)]\tLoss: 127.252419\n",
      "Train Epoch: 32 [4000/39785 (0%)]\tLoss: 91.112648\n",
      "Train Epoch: 32 [5000/39785 (0%)]\tLoss: 97.979912\n",
      "Train Epoch: 32 [6000/39785 (0%)]\tLoss: 109.662605\n",
      "Train Epoch: 32 [7000/39785 (0%)]\tLoss: 121.920372\n",
      "Train Epoch: 32 [8000/39785 (0%)]\tLoss: 118.302994\n",
      "Train Epoch: 32 [9000/39785 (0%)]\tLoss: 109.731201\n",
      "Train Epoch: 32 [10000/39785 (0%)]\tLoss: 133.592102\n",
      "Train Epoch: 32 [11000/39785 (0%)]\tLoss: 132.355988\n",
      "Train Epoch: 32 [12000/39785 (0%)]\tLoss: 125.017876\n",
      "Train Epoch: 32 [13000/39785 (0%)]\tLoss: 145.688263\n",
      "Train Epoch: 32 [14000/39785 (0%)]\tLoss: 114.127060\n",
      "Train Epoch: 32 [15000/39785 (0%)]\tLoss: 93.708595\n",
      "Train Epoch: 32 [16000/39785 (0%)]\tLoss: 123.668121\n",
      "Train Epoch: 32 [17000/39785 (0%)]\tLoss: 88.708099\n",
      "Train Epoch: 32 [18000/39785 (0%)]\tLoss: 85.080070\n",
      "Train Epoch: 32 [19000/39785 (0%)]\tLoss: 135.257370\n",
      "Train Epoch: 32 [20000/39785 (1%)]\tLoss: 127.903412\n",
      "Train Epoch: 32 [21000/39785 (1%)]\tLoss: 89.145775\n",
      "Train Epoch: 32 [22000/39785 (1%)]\tLoss: 1053.205322\n",
      "Train Epoch: 32 [23000/39785 (1%)]\tLoss: 142.150284\n",
      "Train Epoch: 32 [24000/39785 (1%)]\tLoss: 127.219078\n",
      "Train Epoch: 32 [25000/39785 (1%)]\tLoss: 97.082382\n",
      "Train Epoch: 32 [26000/39785 (1%)]\tLoss: 147.470932\n",
      "Train Epoch: 32 [27000/39785 (1%)]\tLoss: 140.442459\n",
      "Train Epoch: 32 [28000/39785 (1%)]\tLoss: 97.548355\n",
      "Train Epoch: 32 [29000/39785 (1%)]\tLoss: 108.479706\n",
      "Train Epoch: 32 [30000/39785 (1%)]\tLoss: 163.473404\n",
      "Train Epoch: 32 [31000/39785 (1%)]\tLoss: 161.619019\n",
      "Train Epoch: 32 [32000/39785 (1%)]\tLoss: 209.421509\n",
      "Train Epoch: 32 [33000/39785 (1%)]\tLoss: 143.120743\n",
      "Train Epoch: 32 [34000/39785 (1%)]\tLoss: 94.995872\n",
      "Train Epoch: 32 [35000/39785 (1%)]\tLoss: 127.955551\n",
      "Train Epoch: 32 [36000/39785 (1%)]\tLoss: 96.321465\n",
      "Train Epoch: 32 [37000/39785 (1%)]\tLoss: 125.834633\n",
      "Train Epoch: 32 [38000/39785 (1%)]\tLoss: 98.846489\n",
      "Train Epoch: 32 [39000/39785 (1%)]\tLoss: 141.007675\n",
      "39750\n",
      "39785\n",
      "Train Epoch: 33 [1000/39785 (0%)]\tLoss: 104.548454\n",
      "Train Epoch: 33 [2000/39785 (0%)]\tLoss: 140.354797\n",
      "Train Epoch: 33 [3000/39785 (0%)]\tLoss: 82.794235\n",
      "Train Epoch: 33 [4000/39785 (0%)]\tLoss: 142.074203\n",
      "Train Epoch: 33 [5000/39785 (0%)]\tLoss: 111.299461\n",
      "Train Epoch: 33 [6000/39785 (0%)]\tLoss: 100.099220\n",
      "Train Epoch: 33 [7000/39785 (0%)]\tLoss: 100.876656\n",
      "Train Epoch: 33 [8000/39785 (0%)]\tLoss: 102.612778\n",
      "Train Epoch: 33 [9000/39785 (0%)]\tLoss: 116.528992\n",
      "Train Epoch: 33 [10000/39785 (0%)]\tLoss: 101.262184\n",
      "Train Epoch: 33 [11000/39785 (0%)]\tLoss: 128.602020\n",
      "Train Epoch: 33 [12000/39785 (0%)]\tLoss: 76.986191\n",
      "Train Epoch: 33 [13000/39785 (0%)]\tLoss: 114.477997\n",
      "Train Epoch: 33 [14000/39785 (0%)]\tLoss: 118.134499\n",
      "Train Epoch: 33 [15000/39785 (0%)]\tLoss: 111.870384\n",
      "Train Epoch: 33 [16000/39785 (0%)]\tLoss: 110.196625\n",
      "Train Epoch: 33 [17000/39785 (0%)]\tLoss: 111.057152\n",
      "Train Epoch: 33 [18000/39785 (0%)]\tLoss: 75.301353\n",
      "Train Epoch: 33 [19000/39785 (0%)]\tLoss: 118.471008\n",
      "Train Epoch: 33 [20000/39785 (1%)]\tLoss: 81.343262\n",
      "Train Epoch: 33 [21000/39785 (1%)]\tLoss: 102.327164\n",
      "Train Epoch: 33 [22000/39785 (1%)]\tLoss: 116.295563\n",
      "Train Epoch: 33 [23000/39785 (1%)]\tLoss: 90.645836\n",
      "Train Epoch: 33 [24000/39785 (1%)]\tLoss: 93.488258\n",
      "Train Epoch: 33 [25000/39785 (1%)]\tLoss: 132.819382\n",
      "Train Epoch: 33 [26000/39785 (1%)]\tLoss: 106.994331\n",
      "Train Epoch: 33 [27000/39785 (1%)]\tLoss: 123.000259\n",
      "Train Epoch: 33 [28000/39785 (1%)]\tLoss: 86.492638\n",
      "Train Epoch: 33 [29000/39785 (1%)]\tLoss: 84.171211\n",
      "Train Epoch: 33 [30000/39785 (1%)]\tLoss: 138.654984\n",
      "Train Epoch: 33 [31000/39785 (1%)]\tLoss: 161.472382\n",
      "Train Epoch: 33 [32000/39785 (1%)]\tLoss: 90.241386\n",
      "Train Epoch: 33 [33000/39785 (1%)]\tLoss: 141.864090\n",
      "Train Epoch: 33 [34000/39785 (1%)]\tLoss: 174.379883\n",
      "Train Epoch: 33 [35000/39785 (1%)]\tLoss: 104.570656\n",
      "Train Epoch: 33 [36000/39785 (1%)]\tLoss: 119.100624\n",
      "Train Epoch: 33 [37000/39785 (1%)]\tLoss: 103.117615\n",
      "Train Epoch: 33 [38000/39785 (1%)]\tLoss: 92.025734\n",
      "Train Epoch: 33 [39000/39785 (1%)]\tLoss: 120.729477\n",
      "39765\n",
      "39785\n",
      "Train Epoch: 34 [1000/39785 (0%)]\tLoss: 72.308113\n",
      "Train Epoch: 34 [2000/39785 (0%)]\tLoss: 92.013794\n",
      "Train Epoch: 34 [3000/39785 (0%)]\tLoss: 102.804588\n",
      "Train Epoch: 34 [4000/39785 (0%)]\tLoss: 102.022797\n",
      "Train Epoch: 34 [5000/39785 (0%)]\tLoss: 94.254036\n",
      "Train Epoch: 34 [6000/39785 (0%)]\tLoss: 102.303963\n",
      "Train Epoch: 34 [7000/39785 (0%)]\tLoss: 79.998413\n",
      "Train Epoch: 34 [8000/39785 (0%)]\tLoss: 147.471512\n",
      "Train Epoch: 34 [9000/39785 (0%)]\tLoss: 98.151611\n",
      "Train Epoch: 34 [10000/39785 (0%)]\tLoss: 92.270271\n",
      "Train Epoch: 34 [11000/39785 (0%)]\tLoss: 113.692642\n",
      "Train Epoch: 34 [12000/39785 (0%)]\tLoss: 115.824440\n",
      "Train Epoch: 34 [13000/39785 (0%)]\tLoss: 130.641785\n",
      "Train Epoch: 34 [14000/39785 (0%)]\tLoss: 107.483871\n",
      "Train Epoch: 34 [15000/39785 (0%)]\tLoss: 97.802750\n",
      "Train Epoch: 34 [16000/39785 (0%)]\tLoss: 92.882919\n",
      "Train Epoch: 34 [17000/39785 (0%)]\tLoss: 90.876289\n",
      "Train Epoch: 34 [18000/39785 (0%)]\tLoss: 84.039810\n",
      "Train Epoch: 34 [19000/39785 (0%)]\tLoss: 101.164276\n",
      "Train Epoch: 34 [20000/39785 (1%)]\tLoss: 93.884941\n",
      "Train Epoch: 34 [21000/39785 (1%)]\tLoss: 99.433746\n",
      "Train Epoch: 34 [22000/39785 (1%)]\tLoss: 86.524658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34 [23000/39785 (1%)]\tLoss: 84.283195\n",
      "Train Epoch: 34 [24000/39785 (1%)]\tLoss: 101.605988\n",
      "Train Epoch: 34 [25000/39785 (1%)]\tLoss: 98.696114\n",
      "Train Epoch: 34 [26000/39785 (1%)]\tLoss: 97.509071\n",
      "Train Epoch: 34 [27000/39785 (1%)]\tLoss: 131.259415\n",
      "Train Epoch: 34 [28000/39785 (1%)]\tLoss: 150.176559\n",
      "Train Epoch: 34 [29000/39785 (1%)]\tLoss: 125.832466\n",
      "Train Epoch: 34 [30000/39785 (1%)]\tLoss: 120.225510\n",
      "Train Epoch: 34 [31000/39785 (1%)]\tLoss: 119.179420\n",
      "Train Epoch: 34 [32000/39785 (1%)]\tLoss: 83.392609\n",
      "Train Epoch: 34 [33000/39785 (1%)]\tLoss: 103.816917\n",
      "Train Epoch: 34 [34000/39785 (1%)]\tLoss: 113.577629\n",
      "Train Epoch: 34 [35000/39785 (1%)]\tLoss: 111.218735\n",
      "Train Epoch: 34 [36000/39785 (1%)]\tLoss: 103.738350\n",
      "Train Epoch: 34 [37000/39785 (1%)]\tLoss: 109.434402\n",
      "Train Epoch: 34 [38000/39785 (1%)]\tLoss: 135.677673\n",
      "Train Epoch: 34 [39000/39785 (1%)]\tLoss: 102.696358\n",
      "39780\n",
      "39785\n",
      "Train Epoch: 35 [1000/39785 (0%)]\tLoss: 70.871025\n",
      "Train Epoch: 35 [2000/39785 (0%)]\tLoss: 106.460487\n",
      "Train Epoch: 35 [3000/39785 (0%)]\tLoss: 63.737278\n",
      "Train Epoch: 35 [4000/39785 (0%)]\tLoss: 62.624893\n",
      "Train Epoch: 35 [5000/39785 (0%)]\tLoss: 88.571274\n",
      "Train Epoch: 35 [6000/39785 (0%)]\tLoss: 96.224121\n",
      "Train Epoch: 35 [7000/39785 (0%)]\tLoss: 96.964653\n",
      "Train Epoch: 35 [8000/39785 (0%)]\tLoss: 121.257164\n",
      "Train Epoch: 35 [9000/39785 (0%)]\tLoss: 109.345871\n",
      "Train Epoch: 35 [10000/39785 (0%)]\tLoss: 131.536224\n",
      "Train Epoch: 35 [11000/39785 (0%)]\tLoss: 92.433998\n",
      "Train Epoch: 35 [12000/39785 (0%)]\tLoss: 115.997864\n",
      "Train Epoch: 35 [13000/39785 (0%)]\tLoss: 97.487175\n",
      "Train Epoch: 35 [14000/39785 (0%)]\tLoss: 85.773331\n",
      "Train Epoch: 35 [15000/39785 (0%)]\tLoss: 105.466270\n",
      "Train Epoch: 35 [16000/39785 (0%)]\tLoss: 63.891888\n",
      "Train Epoch: 35 [17000/39785 (0%)]\tLoss: 79.653297\n",
      "Train Epoch: 35 [18000/39785 (0%)]\tLoss: 95.618141\n",
      "Train Epoch: 35 [19000/39785 (0%)]\tLoss: 72.050613\n",
      "Train Epoch: 35 [20000/39785 (1%)]\tLoss: 105.021492\n",
      "Train Epoch: 35 [21000/39785 (1%)]\tLoss: 59.069252\n",
      "Train Epoch: 35 [22000/39785 (1%)]\tLoss: 83.856209\n",
      "Train Epoch: 35 [23000/39785 (1%)]\tLoss: 81.968086\n",
      "Train Epoch: 35 [24000/39785 (1%)]\tLoss: 88.942490\n",
      "Train Epoch: 35 [25000/39785 (1%)]\tLoss: 68.316391\n",
      "Train Epoch: 35 [26000/39785 (1%)]\tLoss: 91.209358\n",
      "Train Epoch: 35 [27000/39785 (1%)]\tLoss: 94.160606\n",
      "Train Epoch: 35 [28000/39785 (1%)]\tLoss: 84.148621\n",
      "Train Epoch: 35 [29000/39785 (1%)]\tLoss: 136.703842\n",
      "Train Epoch: 35 [30000/39785 (1%)]\tLoss: 84.484825\n",
      "Train Epoch: 35 [31000/39785 (1%)]\tLoss: 78.744873\n",
      "Train Epoch: 35 [32000/39785 (1%)]\tLoss: 103.351387\n",
      "Train Epoch: 35 [33000/39785 (1%)]\tLoss: 97.085800\n",
      "Train Epoch: 35 [34000/39785 (1%)]\tLoss: 113.347610\n",
      "Train Epoch: 35 [35000/39785 (1%)]\tLoss: 119.158768\n",
      "Train Epoch: 35 [36000/39785 (1%)]\tLoss: 105.587708\n",
      "Train Epoch: 35 [37000/39785 (1%)]\tLoss: 78.376198\n",
      "Train Epoch: 35 [38000/39785 (1%)]\tLoss: 104.914948\n",
      "Train Epoch: 35 [39000/39785 (1%)]\tLoss: 106.820274\n",
      "39695\n",
      "39785\n",
      "Train Epoch: 36 [1000/39785 (0%)]\tLoss: 59.052696\n",
      "Train Epoch: 36 [2000/39785 (0%)]\tLoss: 72.777962\n",
      "Train Epoch: 36 [3000/39785 (0%)]\tLoss: 81.077263\n",
      "Train Epoch: 36 [4000/39785 (0%)]\tLoss: 83.692467\n",
      "Train Epoch: 36 [5000/39785 (0%)]\tLoss: 70.343788\n",
      "Train Epoch: 36 [6000/39785 (0%)]\tLoss: 73.957718\n",
      "Train Epoch: 36 [7000/39785 (0%)]\tLoss: 83.853806\n",
      "Train Epoch: 36 [8000/39785 (0%)]\tLoss: 73.800011\n",
      "Train Epoch: 36 [9000/39785 (0%)]\tLoss: 77.316711\n",
      "Train Epoch: 36 [10000/39785 (0%)]\tLoss: 66.480339\n",
      "Train Epoch: 36 [11000/39785 (0%)]\tLoss: 68.640564\n",
      "Train Epoch: 36 [12000/39785 (0%)]\tLoss: 105.688820\n",
      "Train Epoch: 36 [13000/39785 (0%)]\tLoss: 102.103180\n",
      "Train Epoch: 36 [14000/39785 (0%)]\tLoss: 92.358345\n",
      "Train Epoch: 36 [15000/39785 (0%)]\tLoss: 104.125549\n",
      "Train Epoch: 36 [16000/39785 (0%)]\tLoss: 73.248749\n",
      "Train Epoch: 36 [17000/39785 (0%)]\tLoss: 79.278030\n",
      "Train Epoch: 36 [18000/39785 (0%)]\tLoss: 92.128082\n",
      "Train Epoch: 36 [19000/39785 (0%)]\tLoss: 82.978371\n",
      "Train Epoch: 36 [20000/39785 (1%)]\tLoss: 98.539543\n",
      "Train Epoch: 36 [21000/39785 (1%)]\tLoss: 71.631935\n",
      "Train Epoch: 36 [22000/39785 (1%)]\tLoss: 57.490501\n",
      "Train Epoch: 36 [23000/39785 (1%)]\tLoss: 77.658852\n",
      "Train Epoch: 36 [24000/39785 (1%)]\tLoss: 69.261772\n",
      "Train Epoch: 36 [25000/39785 (1%)]\tLoss: 98.379372\n",
      "Train Epoch: 36 [26000/39785 (1%)]\tLoss: 82.950287\n",
      "Train Epoch: 36 [27000/39785 (1%)]\tLoss: 119.284576\n",
      "Train Epoch: 36 [28000/39785 (1%)]\tLoss: 113.310799\n",
      "Train Epoch: 36 [29000/39785 (1%)]\tLoss: 127.429825\n",
      "Train Epoch: 36 [30000/39785 (1%)]\tLoss: 95.527733\n",
      "Train Epoch: 36 [31000/39785 (1%)]\tLoss: 80.362297\n",
      "Train Epoch: 36 [32000/39785 (1%)]\tLoss: 93.968834\n",
      "Train Epoch: 36 [33000/39785 (1%)]\tLoss: 125.219749\n",
      "Train Epoch: 36 [34000/39785 (1%)]\tLoss: 86.242516\n",
      "Train Epoch: 36 [35000/39785 (1%)]\tLoss: 77.154900\n",
      "Train Epoch: 36 [36000/39785 (1%)]\tLoss: 69.423309\n",
      "Train Epoch: 36 [37000/39785 (1%)]\tLoss: 77.486221\n",
      "Train Epoch: 36 [38000/39785 (1%)]\tLoss: 103.549553\n",
      "Train Epoch: 36 [39000/39785 (1%)]\tLoss: 76.902336\n",
      "39710\n",
      "39785\n",
      "Train Epoch: 37 [1000/39785 (0%)]\tLoss: 64.141571\n",
      "Train Epoch: 37 [2000/39785 (0%)]\tLoss: 66.969994\n",
      "Train Epoch: 37 [3000/39785 (0%)]\tLoss: 71.829971\n",
      "Train Epoch: 37 [4000/39785 (0%)]\tLoss: 95.093010\n",
      "Train Epoch: 37 [5000/39785 (0%)]\tLoss: 91.167236\n",
      "Train Epoch: 37 [6000/39785 (0%)]\tLoss: 63.402874\n",
      "Train Epoch: 37 [7000/39785 (0%)]\tLoss: 81.741753\n",
      "Train Epoch: 37 [8000/39785 (0%)]\tLoss: 82.039742\n",
      "Train Epoch: 37 [9000/39785 (0%)]\tLoss: 75.464493\n",
      "Train Epoch: 37 [10000/39785 (0%)]\tLoss: 64.114449\n",
      "Train Epoch: 37 [11000/39785 (0%)]\tLoss: 94.897011\n",
      "Train Epoch: 37 [12000/39785 (0%)]\tLoss: 76.829277\n",
      "Train Epoch: 37 [13000/39785 (0%)]\tLoss: 89.729828\n",
      "Train Epoch: 37 [14000/39785 (0%)]\tLoss: 88.106621\n",
      "Train Epoch: 37 [15000/39785 (0%)]\tLoss: 94.483719\n",
      "Train Epoch: 37 [16000/39785 (0%)]\tLoss: 108.060394\n",
      "Train Epoch: 37 [17000/39785 (0%)]\tLoss: 103.210587\n",
      "Train Epoch: 37 [18000/39785 (0%)]\tLoss: 78.821754\n",
      "Train Epoch: 37 [19000/39785 (0%)]\tLoss: 46.594875\n",
      "Train Epoch: 37 [20000/39785 (1%)]\tLoss: 73.217514\n",
      "Train Epoch: 37 [21000/39785 (1%)]\tLoss: 85.088982\n",
      "Train Epoch: 37 [22000/39785 (1%)]\tLoss: 70.056168\n",
      "Train Epoch: 37 [23000/39785 (1%)]\tLoss: 81.553902\n",
      "Train Epoch: 37 [24000/39785 (1%)]\tLoss: 89.774529\n",
      "Train Epoch: 37 [25000/39785 (1%)]\tLoss: 69.925613\n",
      "Train Epoch: 37 [26000/39785 (1%)]\tLoss: 72.259468\n",
      "Train Epoch: 37 [27000/39785 (1%)]\tLoss: 93.230370\n",
      "Train Epoch: 37 [28000/39785 (1%)]\tLoss: 77.074280\n",
      "Train Epoch: 37 [29000/39785 (1%)]\tLoss: 83.753822\n",
      "Train Epoch: 37 [30000/39785 (1%)]\tLoss: 76.561455\n",
      "Train Epoch: 37 [31000/39785 (1%)]\tLoss: 103.631119\n",
      "Train Epoch: 37 [32000/39785 (1%)]\tLoss: 117.319489\n",
      "Train Epoch: 37 [33000/39785 (1%)]\tLoss: 76.286583\n",
      "Train Epoch: 37 [34000/39785 (1%)]\tLoss: 64.555237\n",
      "Train Epoch: 37 [35000/39785 (1%)]\tLoss: 66.709381\n",
      "Train Epoch: 37 [36000/39785 (1%)]\tLoss: 74.987465\n",
      "Train Epoch: 37 [37000/39785 (1%)]\tLoss: 92.858269\n",
      "Train Epoch: 37 [38000/39785 (1%)]\tLoss: 75.722000\n",
      "Train Epoch: 37 [39000/39785 (1%)]\tLoss: 73.093842\n",
      "39725\n",
      "39785\n",
      "Train Epoch: 38 [1000/39785 (0%)]\tLoss: 90.153404\n",
      "Train Epoch: 38 [2000/39785 (0%)]\tLoss: 82.391861\n",
      "Train Epoch: 38 [3000/39785 (0%)]\tLoss: 60.655243\n",
      "Train Epoch: 38 [4000/39785 (0%)]\tLoss: 54.661743\n",
      "Train Epoch: 38 [5000/39785 (0%)]\tLoss: 74.727303\n",
      "Train Epoch: 38 [6000/39785 (0%)]\tLoss: 62.099884\n",
      "Train Epoch: 38 [7000/39785 (0%)]\tLoss: 51.786114\n",
      "Train Epoch: 38 [8000/39785 (0%)]\tLoss: 50.515331\n",
      "Train Epoch: 38 [9000/39785 (0%)]\tLoss: 53.604137\n",
      "Train Epoch: 38 [10000/39785 (0%)]\tLoss: 59.594589\n",
      "Train Epoch: 38 [11000/39785 (0%)]\tLoss: 74.540741\n",
      "Train Epoch: 38 [12000/39785 (0%)]\tLoss: 65.114899\n",
      "Train Epoch: 38 [13000/39785 (0%)]\tLoss: 73.000740\n",
      "Train Epoch: 38 [14000/39785 (0%)]\tLoss: 64.580795\n",
      "Train Epoch: 38 [15000/39785 (0%)]\tLoss: 83.946213\n",
      "Train Epoch: 38 [16000/39785 (0%)]\tLoss: 71.868904\n",
      "Train Epoch: 38 [17000/39785 (0%)]\tLoss: 98.861488\n",
      "Train Epoch: 38 [18000/39785 (0%)]\tLoss: 57.977352\n",
      "Train Epoch: 38 [19000/39785 (0%)]\tLoss: 82.856766\n",
      "Train Epoch: 38 [20000/39785 (1%)]\tLoss: 68.882874\n",
      "Train Epoch: 38 [21000/39785 (1%)]\tLoss: 72.247276\n",
      "Train Epoch: 38 [22000/39785 (1%)]\tLoss: 69.271057\n",
      "Train Epoch: 38 [23000/39785 (1%)]\tLoss: 66.508797\n",
      "Train Epoch: 38 [24000/39785 (1%)]\tLoss: 70.610535\n",
      "Train Epoch: 38 [25000/39785 (1%)]\tLoss: 90.883202\n",
      "Train Epoch: 38 [26000/39785 (1%)]\tLoss: 92.648247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [27000/39785 (1%)]\tLoss: 85.271873\n",
      "Train Epoch: 38 [28000/39785 (1%)]\tLoss: 71.789284\n",
      "Train Epoch: 38 [29000/39785 (1%)]\tLoss: 54.209515\n",
      "Train Epoch: 38 [30000/39785 (1%)]\tLoss: 51.324833\n",
      "Train Epoch: 38 [31000/39785 (1%)]\tLoss: 73.448151\n",
      "Train Epoch: 38 [32000/39785 (1%)]\tLoss: 81.495018\n",
      "Train Epoch: 38 [33000/39785 (1%)]\tLoss: 65.185158\n",
      "Train Epoch: 38 [34000/39785 (1%)]\tLoss: 73.700813\n",
      "Train Epoch: 38 [35000/39785 (1%)]\tLoss: 57.396877\n",
      "Train Epoch: 38 [36000/39785 (1%)]\tLoss: 73.465363\n",
      "Train Epoch: 38 [37000/39785 (1%)]\tLoss: 75.900993\n",
      "Train Epoch: 38 [38000/39785 (1%)]\tLoss: 106.960281\n",
      "Train Epoch: 38 [39000/39785 (1%)]\tLoss: 82.596451\n",
      "39740\n",
      "39785\n",
      "Train Epoch: 39 [1000/39785 (0%)]\tLoss: 58.526257\n",
      "Train Epoch: 39 [2000/39785 (0%)]\tLoss: 65.158775\n",
      "Train Epoch: 39 [3000/39785 (0%)]\tLoss: 58.407074\n",
      "Train Epoch: 39 [4000/39785 (0%)]\tLoss: 101.377762\n",
      "Train Epoch: 39 [5000/39785 (0%)]\tLoss: 55.757027\n",
      "Train Epoch: 39 [6000/39785 (0%)]\tLoss: 61.581757\n",
      "Train Epoch: 39 [7000/39785 (0%)]\tLoss: 52.279469\n",
      "Train Epoch: 39 [8000/39785 (0%)]\tLoss: 93.421761\n",
      "Train Epoch: 39 [9000/39785 (0%)]\tLoss: 64.619171\n",
      "Train Epoch: 39 [10000/39785 (0%)]\tLoss: 67.072685\n",
      "Train Epoch: 39 [11000/39785 (0%)]\tLoss: 48.098312\n",
      "Train Epoch: 39 [12000/39785 (0%)]\tLoss: 61.543034\n",
      "Train Epoch: 39 [13000/39785 (0%)]\tLoss: 63.154152\n",
      "Train Epoch: 39 [14000/39785 (0%)]\tLoss: 54.840221\n",
      "Train Epoch: 39 [15000/39785 (0%)]\tLoss: 59.998188\n",
      "Train Epoch: 39 [16000/39785 (0%)]\tLoss: 67.717979\n",
      "Train Epoch: 39 [17000/39785 (0%)]\tLoss: 78.773247\n",
      "Train Epoch: 39 [18000/39785 (0%)]\tLoss: 95.864952\n",
      "Train Epoch: 39 [19000/39785 (0%)]\tLoss: 47.718975\n",
      "Train Epoch: 39 [20000/39785 (1%)]\tLoss: 65.622757\n",
      "Train Epoch: 39 [21000/39785 (1%)]\tLoss: 82.036438\n",
      "Train Epoch: 39 [22000/39785 (1%)]\tLoss: 89.753082\n",
      "Train Epoch: 39 [23000/39785 (1%)]\tLoss: 77.483856\n",
      "Train Epoch: 39 [24000/39785 (1%)]\tLoss: 64.538284\n",
      "Train Epoch: 39 [25000/39785 (1%)]\tLoss: 66.379021\n",
      "Train Epoch: 39 [26000/39785 (1%)]\tLoss: 109.453705\n",
      "Train Epoch: 39 [27000/39785 (1%)]\tLoss: 81.275513\n",
      "Train Epoch: 39 [28000/39785 (1%)]\tLoss: 70.403770\n",
      "Train Epoch: 39 [29000/39785 (1%)]\tLoss: 61.666286\n",
      "Train Epoch: 39 [30000/39785 (1%)]\tLoss: 79.533348\n",
      "Train Epoch: 39 [31000/39785 (1%)]\tLoss: 53.818199\n",
      "Train Epoch: 39 [32000/39785 (1%)]\tLoss: 67.048775\n",
      "Train Epoch: 39 [33000/39785 (1%)]\tLoss: 54.670311\n",
      "Train Epoch: 39 [34000/39785 (1%)]\tLoss: 366.570221\n",
      "Train Epoch: 39 [35000/39785 (1%)]\tLoss: 78.257034\n",
      "Train Epoch: 39 [36000/39785 (1%)]\tLoss: 85.804672\n",
      "Train Epoch: 39 [37000/39785 (1%)]\tLoss: 56.628220\n",
      "Train Epoch: 39 [38000/39785 (1%)]\tLoss: 60.639545\n",
      "Train Epoch: 39 [39000/39785 (1%)]\tLoss: 75.166161\n",
      "39755\n",
      "39785\n",
      "Train Epoch: 40 [1000/39785 (0%)]\tLoss: 43.197937\n",
      "Train Epoch: 40 [2000/39785 (0%)]\tLoss: 44.675285\n",
      "Train Epoch: 40 [3000/39785 (0%)]\tLoss: 76.200882\n",
      "Train Epoch: 40 [4000/39785 (0%)]\tLoss: 69.412064\n",
      "Train Epoch: 40 [5000/39785 (0%)]\tLoss: 59.622143\n",
      "Train Epoch: 40 [6000/39785 (0%)]\tLoss: 62.884712\n",
      "Train Epoch: 40 [7000/39785 (0%)]\tLoss: 54.532925\n",
      "Train Epoch: 40 [8000/39785 (0%)]\tLoss: 54.342236\n",
      "Train Epoch: 40 [9000/39785 (0%)]\tLoss: 56.083023\n",
      "Train Epoch: 40 [10000/39785 (0%)]\tLoss: 74.787971\n",
      "Train Epoch: 40 [11000/39785 (0%)]\tLoss: 50.459862\n",
      "Train Epoch: 40 [12000/39785 (0%)]\tLoss: 44.516125\n",
      "Train Epoch: 40 [13000/39785 (0%)]\tLoss: 67.550377\n",
      "Train Epoch: 40 [14000/39785 (0%)]\tLoss: 54.442886\n",
      "Train Epoch: 40 [15000/39785 (0%)]\tLoss: 58.434544\n",
      "Train Epoch: 40 [16000/39785 (0%)]\tLoss: 72.115585\n",
      "Train Epoch: 40 [17000/39785 (0%)]\tLoss: 48.161747\n",
      "Train Epoch: 40 [18000/39785 (0%)]\tLoss: 52.411892\n",
      "Train Epoch: 40 [19000/39785 (0%)]\tLoss: 63.506042\n",
      "Train Epoch: 40 [20000/39785 (1%)]\tLoss: 52.481804\n",
      "Train Epoch: 40 [21000/39785 (1%)]\tLoss: 1624.329834\n",
      "Train Epoch: 40 [22000/39785 (1%)]\tLoss: 62.383503\n",
      "Train Epoch: 40 [23000/39785 (1%)]\tLoss: 50.878250\n",
      "Train Epoch: 40 [24000/39785 (1%)]\tLoss: 62.913033\n",
      "Train Epoch: 40 [25000/39785 (1%)]\tLoss: 86.516350\n",
      "Train Epoch: 40 [26000/39785 (1%)]\tLoss: 59.480156\n",
      "Train Epoch: 40 [27000/39785 (1%)]\tLoss: 65.790894\n",
      "Train Epoch: 40 [28000/39785 (1%)]\tLoss: 60.697803\n",
      "Train Epoch: 40 [29000/39785 (1%)]\tLoss: 72.601662\n",
      "Train Epoch: 40 [30000/39785 (1%)]\tLoss: 58.634300\n",
      "Train Epoch: 40 [31000/39785 (1%)]\tLoss: 58.313313\n",
      "Train Epoch: 40 [32000/39785 (1%)]\tLoss: 63.654823\n",
      "Train Epoch: 40 [33000/39785 (1%)]\tLoss: 65.516693\n",
      "Train Epoch: 40 [34000/39785 (1%)]\tLoss: 50.459278\n",
      "Train Epoch: 40 [35000/39785 (1%)]\tLoss: 67.703812\n",
      "Train Epoch: 40 [36000/39785 (1%)]\tLoss: 62.152527\n",
      "Train Epoch: 40 [37000/39785 (1%)]\tLoss: 59.934059\n",
      "Train Epoch: 40 [38000/39785 (1%)]\tLoss: 67.376038\n",
      "Train Epoch: 40 [39000/39785 (1%)]\tLoss: 67.415756\n",
      "39770\n",
      "39785\n",
      "Train Epoch: 41 [1000/39785 (0%)]\tLoss: 45.916145\n",
      "Train Epoch: 41 [2000/39785 (0%)]\tLoss: 64.630112\n",
      "Train Epoch: 41 [3000/39785 (0%)]\tLoss: 54.017296\n",
      "Train Epoch: 41 [4000/39785 (0%)]\tLoss: 71.268021\n",
      "Train Epoch: 41 [5000/39785 (0%)]\tLoss: 54.435131\n",
      "Train Epoch: 41 [6000/39785 (0%)]\tLoss: 49.171032\n",
      "Train Epoch: 41 [7000/39785 (0%)]\tLoss: 49.818535\n",
      "Train Epoch: 41 [8000/39785 (0%)]\tLoss: 43.417336\n",
      "Train Epoch: 41 [9000/39785 (0%)]\tLoss: 50.524529\n",
      "Train Epoch: 41 [10000/39785 (0%)]\tLoss: 43.965199\n",
      "Train Epoch: 41 [11000/39785 (0%)]\tLoss: 55.511379\n",
      "Train Epoch: 41 [12000/39785 (0%)]\tLoss: 44.020672\n",
      "Train Epoch: 41 [13000/39785 (0%)]\tLoss: 59.424641\n",
      "Train Epoch: 41 [14000/39785 (0%)]\tLoss: 60.635639\n",
      "Train Epoch: 41 [15000/39785 (0%)]\tLoss: 63.009403\n",
      "Train Epoch: 41 [16000/39785 (0%)]\tLoss: 70.333488\n",
      "Train Epoch: 41 [17000/39785 (0%)]\tLoss: 49.025528\n",
      "Train Epoch: 41 [18000/39785 (0%)]\tLoss: 57.634998\n",
      "Train Epoch: 41 [19000/39785 (0%)]\tLoss: 68.875481\n",
      "Train Epoch: 41 [20000/39785 (1%)]\tLoss: 52.529320\n",
      "Train Epoch: 41 [21000/39785 (1%)]\tLoss: 87.498474\n",
      "Train Epoch: 41 [22000/39785 (1%)]\tLoss: 52.123566\n",
      "Train Epoch: 41 [23000/39785 (1%)]\tLoss: 63.170139\n",
      "Train Epoch: 41 [24000/39785 (1%)]\tLoss: 73.910286\n",
      "Train Epoch: 41 [25000/39785 (1%)]\tLoss: 49.590679\n",
      "Train Epoch: 41 [26000/39785 (1%)]\tLoss: 46.420498\n",
      "Train Epoch: 41 [27000/39785 (1%)]\tLoss: 66.518005\n",
      "Train Epoch: 41 [28000/39785 (1%)]\tLoss: 59.453674\n",
      "Train Epoch: 41 [29000/39785 (1%)]\tLoss: 49.630363\n",
      "Train Epoch: 41 [30000/39785 (1%)]\tLoss: 48.785591\n",
      "Train Epoch: 41 [31000/39785 (1%)]\tLoss: 43.418777\n",
      "Train Epoch: 41 [32000/39785 (1%)]\tLoss: 47.126904\n",
      "Train Epoch: 41 [33000/39785 (1%)]\tLoss: 53.909519\n",
      "Train Epoch: 41 [34000/39785 (1%)]\tLoss: 57.609978\n",
      "Train Epoch: 41 [35000/39785 (1%)]\tLoss: 48.730545\n",
      "Train Epoch: 41 [36000/39785 (1%)]\tLoss: 53.526314\n",
      "Train Epoch: 41 [37000/39785 (1%)]\tLoss: 43.455875\n",
      "Train Epoch: 41 [38000/39785 (1%)]\tLoss: 66.053825\n",
      "Train Epoch: 41 [39000/39785 (1%)]\tLoss: 76.013817\n",
      "39685\n",
      "39785\n",
      "39785\n",
      "39785\n",
      "Train Epoch: 43 [1000/39785 (0%)]\tLoss: 63.353733\n",
      "Train Epoch: 43 [2000/39785 (0%)]\tLoss: 56.566124\n",
      "Train Epoch: 43 [3000/39785 (0%)]\tLoss: 64.655334\n",
      "Train Epoch: 43 [4000/39785 (0%)]\tLoss: 57.724461\n",
      "Train Epoch: 43 [5000/39785 (0%)]\tLoss: 46.065746\n",
      "Train Epoch: 43 [6000/39785 (0%)]\tLoss: 62.375385\n",
      "Train Epoch: 43 [7000/39785 (0%)]\tLoss: 55.432869\n",
      "Train Epoch: 43 [8000/39785 (0%)]\tLoss: 50.437859\n",
      "Train Epoch: 43 [9000/39785 (0%)]\tLoss: 38.669666\n",
      "Train Epoch: 43 [10000/39785 (0%)]\tLoss: 53.368500\n",
      "Train Epoch: 43 [11000/39785 (0%)]\tLoss: 47.543221\n",
      "Train Epoch: 43 [12000/39785 (0%)]\tLoss: 38.873547\n",
      "Train Epoch: 43 [13000/39785 (0%)]\tLoss: 68.286270\n",
      "Train Epoch: 43 [14000/39785 (0%)]\tLoss: 51.099560\n",
      "Train Epoch: 43 [15000/39785 (0%)]\tLoss: 51.490124\n",
      "Train Epoch: 43 [16000/39785 (0%)]\tLoss: 42.264969\n",
      "Train Epoch: 43 [17000/39785 (0%)]\tLoss: 51.701256\n",
      "Train Epoch: 43 [18000/39785 (0%)]\tLoss: 108.607040\n",
      "Train Epoch: 43 [19000/39785 (0%)]\tLoss: 148.018890\n",
      "Train Epoch: 43 [20000/39785 (1%)]\tLoss: 106.394135\n",
      "Train Epoch: 43 [21000/39785 (1%)]\tLoss: 118.933380\n",
      "Train Epoch: 43 [22000/39785 (1%)]\tLoss: 67.872864\n",
      "Train Epoch: 43 [23000/39785 (1%)]\tLoss: 68.548180\n",
      "Train Epoch: 43 [24000/39785 (1%)]\tLoss: 59.223492\n",
      "Train Epoch: 43 [25000/39785 (1%)]\tLoss: 76.876289\n",
      "Train Epoch: 43 [26000/39785 (1%)]\tLoss: 51.175823\n",
      "Train Epoch: 43 [27000/39785 (1%)]\tLoss: 80.689331\n",
      "Train Epoch: 43 [28000/39785 (1%)]\tLoss: 63.167339\n",
      "Train Epoch: 43 [29000/39785 (1%)]\tLoss: 72.332382\n",
      "Train Epoch: 43 [30000/39785 (1%)]\tLoss: 82.880798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 [31000/39785 (1%)]\tLoss: 55.441082\n",
      "Train Epoch: 43 [32000/39785 (1%)]\tLoss: 70.763359\n",
      "Train Epoch: 43 [33000/39785 (1%)]\tLoss: 83.316055\n",
      "Train Epoch: 43 [34000/39785 (1%)]\tLoss: 50.247536\n",
      "Train Epoch: 43 [35000/39785 (1%)]\tLoss: 51.767487\n",
      "Train Epoch: 43 [36000/39785 (1%)]\tLoss: 62.485100\n",
      "Train Epoch: 43 [37000/39785 (1%)]\tLoss: 44.350361\n",
      "Train Epoch: 43 [38000/39785 (1%)]\tLoss: 54.388588\n",
      "Train Epoch: 43 [39000/39785 (1%)]\tLoss: 68.870529\n",
      "39700\n",
      "39785\n",
      "Train Epoch: 44 [1000/39785 (0%)]\tLoss: 67.387611\n",
      "Train Epoch: 44 [2000/39785 (0%)]\tLoss: 54.107941\n",
      "Train Epoch: 44 [3000/39785 (0%)]\tLoss: 48.686325\n",
      "Train Epoch: 44 [4000/39785 (0%)]\tLoss: 49.457703\n",
      "Train Epoch: 44 [5000/39785 (0%)]\tLoss: 43.195225\n",
      "Train Epoch: 44 [6000/39785 (0%)]\tLoss: 59.877464\n",
      "Train Epoch: 44 [7000/39785 (0%)]\tLoss: 48.908813\n",
      "Train Epoch: 44 [8000/39785 (0%)]\tLoss: 54.660458\n",
      "Train Epoch: 44 [9000/39785 (0%)]\tLoss: 45.513191\n",
      "Train Epoch: 44 [10000/39785 (0%)]\tLoss: 60.584431\n",
      "Train Epoch: 44 [11000/39785 (0%)]\tLoss: 61.676350\n",
      "Train Epoch: 44 [12000/39785 (0%)]\tLoss: 37.718468\n",
      "Train Epoch: 44 [13000/39785 (0%)]\tLoss: 49.824238\n",
      "Train Epoch: 44 [14000/39785 (0%)]\tLoss: 49.195469\n",
      "Train Epoch: 44 [15000/39785 (0%)]\tLoss: 40.975368\n",
      "Train Epoch: 44 [16000/39785 (0%)]\tLoss: 53.165745\n",
      "Train Epoch: 44 [17000/39785 (0%)]\tLoss: 54.453075\n",
      "Train Epoch: 44 [18000/39785 (0%)]\tLoss: 47.598373\n",
      "Train Epoch: 44 [19000/39785 (0%)]\tLoss: 44.021275\n",
      "Train Epoch: 44 [20000/39785 (1%)]\tLoss: 93.396225\n",
      "Train Epoch: 44 [21000/39785 (1%)]\tLoss: 49.460804\n",
      "Train Epoch: 44 [22000/39785 (1%)]\tLoss: 49.784904\n",
      "Train Epoch: 44 [23000/39785 (1%)]\tLoss: 46.278404\n",
      "Train Epoch: 44 [24000/39785 (1%)]\tLoss: 56.485935\n",
      "Train Epoch: 44 [25000/39785 (1%)]\tLoss: 47.631706\n",
      "Train Epoch: 44 [26000/39785 (1%)]\tLoss: 57.888641\n",
      "Train Epoch: 44 [27000/39785 (1%)]\tLoss: 58.455570\n",
      "Train Epoch: 44 [28000/39785 (1%)]\tLoss: 43.839035\n",
      "Train Epoch: 44 [29000/39785 (1%)]\tLoss: 58.646652\n",
      "Train Epoch: 44 [30000/39785 (1%)]\tLoss: 42.223591\n",
      "Train Epoch: 44 [31000/39785 (1%)]\tLoss: 69.323509\n",
      "Train Epoch: 44 [32000/39785 (1%)]\tLoss: 72.824013\n",
      "Train Epoch: 44 [33000/39785 (1%)]\tLoss: 54.976685\n",
      "Train Epoch: 44 [34000/39785 (1%)]\tLoss: 63.094120\n",
      "Train Epoch: 44 [35000/39785 (1%)]\tLoss: 43.392735\n",
      "Train Epoch: 44 [36000/39785 (1%)]\tLoss: 52.768093\n",
      "Train Epoch: 44 [37000/39785 (1%)]\tLoss: 51.901779\n",
      "Train Epoch: 44 [38000/39785 (1%)]\tLoss: 53.524025\n",
      "Train Epoch: 44 [39000/39785 (1%)]\tLoss: 52.430370\n",
      "39715\n",
      "39785\n",
      "Train Epoch: 45 [1000/39785 (0%)]\tLoss: 32.226761\n",
      "Train Epoch: 45 [2000/39785 (0%)]\tLoss: 45.177631\n",
      "Train Epoch: 45 [3000/39785 (0%)]\tLoss: 154.612167\n",
      "Train Epoch: 45 [4000/39785 (0%)]\tLoss: 40.969181\n",
      "Train Epoch: 45 [5000/39785 (0%)]\tLoss: 43.697292\n",
      "Train Epoch: 45 [6000/39785 (0%)]\tLoss: 36.353142\n",
      "Train Epoch: 45 [7000/39785 (0%)]\tLoss: 45.630173\n",
      "Train Epoch: 45 [8000/39785 (0%)]\tLoss: 65.631523\n",
      "Train Epoch: 45 [9000/39785 (0%)]\tLoss: 44.056694\n",
      "Train Epoch: 45 [10000/39785 (0%)]\tLoss: 56.817398\n",
      "Train Epoch: 45 [11000/39785 (0%)]\tLoss: 42.040192\n",
      "Train Epoch: 45 [12000/39785 (0%)]\tLoss: 38.078297\n",
      "Train Epoch: 45 [13000/39785 (0%)]\tLoss: 42.393993\n",
      "Train Epoch: 45 [14000/39785 (0%)]\tLoss: 43.246132\n",
      "Train Epoch: 45 [15000/39785 (0%)]\tLoss: 51.074703\n",
      "Train Epoch: 45 [16000/39785 (0%)]\tLoss: 39.478683\n",
      "Train Epoch: 45 [17000/39785 (0%)]\tLoss: 53.656624\n",
      "Train Epoch: 45 [18000/39785 (0%)]\tLoss: 52.875145\n",
      "Train Epoch: 45 [19000/39785 (0%)]\tLoss: 49.591774\n",
      "Train Epoch: 45 [20000/39785 (1%)]\tLoss: 36.931171\n",
      "Train Epoch: 45 [21000/39785 (1%)]\tLoss: 45.325180\n",
      "Train Epoch: 45 [22000/39785 (1%)]\tLoss: 52.447845\n",
      "Train Epoch: 45 [23000/39785 (1%)]\tLoss: 65.351318\n",
      "Train Epoch: 45 [24000/39785 (1%)]\tLoss: 38.949097\n",
      "Train Epoch: 45 [25000/39785 (1%)]\tLoss: 35.725700\n",
      "Train Epoch: 45 [26000/39785 (1%)]\tLoss: 59.110641\n",
      "Train Epoch: 45 [27000/39785 (1%)]\tLoss: 57.175705\n",
      "Train Epoch: 45 [28000/39785 (1%)]\tLoss: 37.545856\n",
      "Train Epoch: 45 [29000/39785 (1%)]\tLoss: 43.992176\n",
      "Train Epoch: 45 [30000/39785 (1%)]\tLoss: 40.896053\n",
      "Train Epoch: 45 [31000/39785 (1%)]\tLoss: 56.125126\n",
      "Train Epoch: 45 [32000/39785 (1%)]\tLoss: 73.046593\n",
      "Train Epoch: 45 [33000/39785 (1%)]\tLoss: 50.167278\n",
      "Train Epoch: 45 [34000/39785 (1%)]\tLoss: 46.517334\n",
      "Train Epoch: 45 [35000/39785 (1%)]\tLoss: 36.526043\n",
      "Train Epoch: 45 [36000/39785 (1%)]\tLoss: 53.556324\n",
      "Train Epoch: 45 [37000/39785 (1%)]\tLoss: 43.856251\n",
      "Train Epoch: 45 [38000/39785 (1%)]\tLoss: 46.056458\n",
      "Train Epoch: 45 [39000/39785 (1%)]\tLoss: 55.807758\n",
      "39730\n",
      "39785\n",
      "Train Epoch: 46 [1000/39785 (0%)]\tLoss: 33.830353\n",
      "Train Epoch: 46 [2000/39785 (0%)]\tLoss: 47.916229\n",
      "Train Epoch: 46 [3000/39785 (0%)]\tLoss: 45.679466\n",
      "Train Epoch: 46 [4000/39785 (0%)]\tLoss: 35.704659\n",
      "Train Epoch: 46 [5000/39785 (0%)]\tLoss: 57.351299\n",
      "Train Epoch: 46 [6000/39785 (0%)]\tLoss: 59.360588\n",
      "Train Epoch: 46 [7000/39785 (0%)]\tLoss: 65.493599\n",
      "Train Epoch: 46 [8000/39785 (0%)]\tLoss: 54.986290\n",
      "Train Epoch: 46 [9000/39785 (0%)]\tLoss: 37.317699\n",
      "Train Epoch: 46 [10000/39785 (0%)]\tLoss: 53.621277\n",
      "Train Epoch: 46 [11000/39785 (0%)]\tLoss: 45.137192\n",
      "Train Epoch: 46 [12000/39785 (0%)]\tLoss: 32.546619\n",
      "Train Epoch: 46 [13000/39785 (0%)]\tLoss: 29.682827\n",
      "Train Epoch: 46 [14000/39785 (0%)]\tLoss: 32.119045\n",
      "Train Epoch: 46 [15000/39785 (0%)]\tLoss: 39.642773\n",
      "Train Epoch: 46 [16000/39785 (0%)]\tLoss: 49.415176\n",
      "Train Epoch: 46 [17000/39785 (0%)]\tLoss: 69.062393\n",
      "Train Epoch: 46 [18000/39785 (0%)]\tLoss: 39.404732\n",
      "Train Epoch: 46 [19000/39785 (0%)]\tLoss: 36.642536\n",
      "Train Epoch: 46 [20000/39785 (1%)]\tLoss: 35.863045\n",
      "Train Epoch: 46 [21000/39785 (1%)]\tLoss: 37.685932\n",
      "Train Epoch: 46 [22000/39785 (1%)]\tLoss: 56.451500\n",
      "Train Epoch: 46 [23000/39785 (1%)]\tLoss: 36.600605\n",
      "Train Epoch: 46 [24000/39785 (1%)]\tLoss: 48.123878\n",
      "Train Epoch: 46 [25000/39785 (1%)]\tLoss: 44.264114\n",
      "Train Epoch: 46 [26000/39785 (1%)]\tLoss: 37.208199\n",
      "Train Epoch: 46 [27000/39785 (1%)]\tLoss: 44.183056\n",
      "Train Epoch: 46 [28000/39785 (1%)]\tLoss: 40.153690\n",
      "Train Epoch: 46 [29000/39785 (1%)]\tLoss: 40.518429\n",
      "Train Epoch: 46 [30000/39785 (1%)]\tLoss: 42.166214\n",
      "Train Epoch: 46 [31000/39785 (1%)]\tLoss: 32.706474\n",
      "Train Epoch: 46 [32000/39785 (1%)]\tLoss: 61.093277\n",
      "Train Epoch: 46 [33000/39785 (1%)]\tLoss: 50.658424\n",
      "Train Epoch: 46 [34000/39785 (1%)]\tLoss: 42.915958\n",
      "Train Epoch: 46 [35000/39785 (1%)]\tLoss: 55.003128\n",
      "Train Epoch: 46 [36000/39785 (1%)]\tLoss: 68.927559\n",
      "Train Epoch: 46 [37000/39785 (1%)]\tLoss: 59.499130\n",
      "Train Epoch: 46 [38000/39785 (1%)]\tLoss: 56.043823\n",
      "Train Epoch: 46 [39000/39785 (1%)]\tLoss: 59.135803\n",
      "39745\n",
      "39785\n",
      "Train Epoch: 47 [1000/39785 (0%)]\tLoss: 38.273945\n",
      "Train Epoch: 47 [2000/39785 (0%)]\tLoss: 44.156754\n",
      "Train Epoch: 47 [3000/39785 (0%)]\tLoss: 34.081215\n",
      "Train Epoch: 47 [4000/39785 (0%)]\tLoss: 41.093117\n",
      "Train Epoch: 47 [5000/39785 (0%)]\tLoss: 38.693356\n",
      "Train Epoch: 47 [6000/39785 (0%)]\tLoss: 77.536934\n",
      "Train Epoch: 47 [7000/39785 (0%)]\tLoss: 49.231236\n",
      "Train Epoch: 47 [8000/39785 (0%)]\tLoss: 54.418312\n",
      "Train Epoch: 47 [9000/39785 (0%)]\tLoss: 60.898521\n",
      "Train Epoch: 47 [10000/39785 (0%)]\tLoss: 76.592033\n",
      "Train Epoch: 47 [11000/39785 (0%)]\tLoss: 38.678669\n",
      "Train Epoch: 47 [12000/39785 (0%)]\tLoss: 48.367302\n",
      "Train Epoch: 47 [13000/39785 (0%)]\tLoss: 37.965309\n",
      "Train Epoch: 47 [14000/39785 (0%)]\tLoss: 29.015501\n",
      "Train Epoch: 47 [15000/39785 (0%)]\tLoss: 39.508450\n",
      "Train Epoch: 47 [16000/39785 (0%)]\tLoss: 30.674826\n",
      "Train Epoch: 47 [17000/39785 (0%)]\tLoss: 42.339069\n",
      "Train Epoch: 47 [18000/39785 (0%)]\tLoss: 36.600098\n",
      "Train Epoch: 47 [19000/39785 (0%)]\tLoss: 35.577835\n",
      "Train Epoch: 47 [20000/39785 (1%)]\tLoss: 33.689800\n",
      "Train Epoch: 47 [21000/39785 (1%)]\tLoss: 44.646004\n",
      "Train Epoch: 47 [22000/39785 (1%)]\tLoss: 42.284756\n",
      "Train Epoch: 47 [23000/39785 (1%)]\tLoss: 35.723282\n",
      "Train Epoch: 47 [24000/39785 (1%)]\tLoss: 41.603405\n",
      "Train Epoch: 47 [25000/39785 (1%)]\tLoss: 38.990055\n",
      "Train Epoch: 47 [26000/39785 (1%)]\tLoss: 52.563660\n",
      "Train Epoch: 47 [27000/39785 (1%)]\tLoss: 44.193180\n",
      "Train Epoch: 47 [28000/39785 (1%)]\tLoss: 36.433094\n",
      "Train Epoch: 47 [29000/39785 (1%)]\tLoss: 36.470634\n",
      "Train Epoch: 47 [30000/39785 (1%)]\tLoss: 35.267509\n",
      "Train Epoch: 47 [31000/39785 (1%)]\tLoss: 28.320393\n",
      "Train Epoch: 47 [32000/39785 (1%)]\tLoss: 34.673290\n",
      "Train Epoch: 47 [33000/39785 (1%)]\tLoss: 38.984219\n",
      "Train Epoch: 47 [34000/39785 (1%)]\tLoss: 46.547840\n",
      "Train Epoch: 47 [35000/39785 (1%)]\tLoss: 37.786087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 47 [36000/39785 (1%)]\tLoss: 40.898792\n",
      "Train Epoch: 47 [37000/39785 (1%)]\tLoss: 45.971962\n",
      "Train Epoch: 47 [38000/39785 (1%)]\tLoss: 34.702728\n",
      "Train Epoch: 47 [39000/39785 (1%)]\tLoss: 42.223938\n",
      "39760\n",
      "39785\n",
      "Train Epoch: 48 [1000/39785 (0%)]\tLoss: 43.219185\n",
      "Train Epoch: 48 [2000/39785 (0%)]\tLoss: 34.502762\n",
      "Train Epoch: 48 [3000/39785 (0%)]\tLoss: 41.055058\n",
      "Train Epoch: 48 [4000/39785 (0%)]\tLoss: 31.658493\n",
      "Train Epoch: 48 [5000/39785 (0%)]\tLoss: 39.151028\n",
      "Train Epoch: 48 [6000/39785 (0%)]\tLoss: 229.345078\n",
      "Train Epoch: 48 [7000/39785 (0%)]\tLoss: 40.306435\n",
      "Train Epoch: 48 [8000/39785 (0%)]\tLoss: 37.408676\n",
      "Train Epoch: 48 [9000/39785 (0%)]\tLoss: 33.568874\n",
      "Train Epoch: 48 [10000/39785 (0%)]\tLoss: 33.257336\n",
      "Train Epoch: 48 [11000/39785 (0%)]\tLoss: 61.300510\n",
      "Train Epoch: 48 [12000/39785 (0%)]\tLoss: 41.643398\n",
      "Train Epoch: 48 [13000/39785 (0%)]\tLoss: 45.624577\n",
      "Train Epoch: 48 [14000/39785 (0%)]\tLoss: 42.983139\n",
      "Train Epoch: 48 [15000/39785 (0%)]\tLoss: 29.735014\n",
      "Train Epoch: 48 [16000/39785 (0%)]\tLoss: 29.292336\n",
      "Train Epoch: 48 [17000/39785 (0%)]\tLoss: 44.688263\n",
      "Train Epoch: 48 [18000/39785 (0%)]\tLoss: 37.933117\n",
      "Train Epoch: 48 [19000/39785 (0%)]\tLoss: 36.823757\n",
      "Train Epoch: 48 [20000/39785 (1%)]\tLoss: 32.800579\n",
      "Train Epoch: 48 [21000/39785 (1%)]\tLoss: 42.404678\n",
      "Train Epoch: 48 [22000/39785 (1%)]\tLoss: 37.176785\n",
      "Train Epoch: 48 [23000/39785 (1%)]\tLoss: 31.177540\n",
      "Train Epoch: 48 [24000/39785 (1%)]\tLoss: 35.962811\n",
      "Train Epoch: 48 [25000/39785 (1%)]\tLoss: 38.848255\n",
      "Train Epoch: 48 [26000/39785 (1%)]\tLoss: 30.355211\n",
      "Train Epoch: 48 [27000/39785 (1%)]\tLoss: 47.688782\n",
      "Train Epoch: 48 [28000/39785 (1%)]\tLoss: 47.730148\n",
      "Train Epoch: 48 [29000/39785 (1%)]\tLoss: 30.224129\n",
      "Train Epoch: 48 [30000/39785 (1%)]\tLoss: 36.537914\n",
      "Train Epoch: 48 [31000/39785 (1%)]\tLoss: 36.589523\n",
      "Train Epoch: 48 [32000/39785 (1%)]\tLoss: 46.498512\n",
      "Train Epoch: 48 [33000/39785 (1%)]\tLoss: 52.448154\n",
      "Train Epoch: 48 [34000/39785 (1%)]\tLoss: 49.657841\n",
      "Train Epoch: 48 [35000/39785 (1%)]\tLoss: 38.028809\n",
      "Train Epoch: 48 [36000/39785 (1%)]\tLoss: 30.928091\n",
      "Train Epoch: 48 [37000/39785 (1%)]\tLoss: 38.580570\n",
      "Train Epoch: 48 [38000/39785 (1%)]\tLoss: 51.409645\n",
      "Train Epoch: 48 [39000/39785 (1%)]\tLoss: 41.439598\n",
      "39775\n",
      "39785\n",
      "Train Epoch: 49 [1000/39785 (0%)]\tLoss: 41.330036\n",
      "Train Epoch: 49 [2000/39785 (0%)]\tLoss: 28.672546\n",
      "Train Epoch: 49 [3000/39785 (0%)]\tLoss: 36.604824\n",
      "Train Epoch: 49 [4000/39785 (0%)]\tLoss: 46.451191\n",
      "Train Epoch: 49 [5000/39785 (0%)]\tLoss: 24.270449\n",
      "Train Epoch: 49 [6000/39785 (0%)]\tLoss: 34.116055\n",
      "Train Epoch: 49 [7000/39785 (0%)]\tLoss: 42.423832\n",
      "Train Epoch: 49 [8000/39785 (0%)]\tLoss: 53.714394\n",
      "Train Epoch: 49 [9000/39785 (0%)]\tLoss: 151.943665\n",
      "Train Epoch: 49 [10000/39785 (0%)]\tLoss: 37.217930\n",
      "Train Epoch: 49 [11000/39785 (0%)]\tLoss: 38.401695\n",
      "Train Epoch: 49 [12000/39785 (0%)]\tLoss: 47.644871\n",
      "Train Epoch: 49 [13000/39785 (0%)]\tLoss: 37.205799\n",
      "Train Epoch: 49 [14000/39785 (0%)]\tLoss: 50.916710\n",
      "Train Epoch: 49 [15000/39785 (0%)]\tLoss: 34.733078\n",
      "Train Epoch: 49 [16000/39785 (0%)]\tLoss: 36.692932\n",
      "Train Epoch: 49 [17000/39785 (0%)]\tLoss: 32.362244\n",
      "Train Epoch: 49 [18000/39785 (0%)]\tLoss: 41.576344\n",
      "Train Epoch: 49 [19000/39785 (0%)]\tLoss: 58.252323\n",
      "Train Epoch: 49 [20000/39785 (1%)]\tLoss: 36.430908\n",
      "Train Epoch: 49 [21000/39785 (1%)]\tLoss: 45.689995\n",
      "Train Epoch: 49 [22000/39785 (1%)]\tLoss: 34.166611\n",
      "Train Epoch: 49 [23000/39785 (1%)]\tLoss: 43.354519\n",
      "Train Epoch: 49 [24000/39785 (1%)]\tLoss: 42.727013\n",
      "Train Epoch: 49 [25000/39785 (1%)]\tLoss: 29.807272\n",
      "Train Epoch: 49 [26000/39785 (1%)]\tLoss: 29.761736\n",
      "Train Epoch: 49 [27000/39785 (1%)]\tLoss: 41.376820\n",
      "Train Epoch: 49 [28000/39785 (1%)]\tLoss: 38.638870\n",
      "Train Epoch: 49 [29000/39785 (1%)]\tLoss: 58.362591\n",
      "Train Epoch: 49 [30000/39785 (1%)]\tLoss: 34.290485\n",
      "Train Epoch: 49 [31000/39785 (1%)]\tLoss: 27.904562\n",
      "Train Epoch: 49 [32000/39785 (1%)]\tLoss: 39.646061\n",
      "Train Epoch: 49 [33000/39785 (1%)]\tLoss: 48.696342\n",
      "Train Epoch: 49 [34000/39785 (1%)]\tLoss: 37.045948\n",
      "Train Epoch: 49 [35000/39785 (1%)]\tLoss: 37.352562\n",
      "Train Epoch: 49 [36000/39785 (1%)]\tLoss: 57.402382\n",
      "Train Epoch: 49 [37000/39785 (1%)]\tLoss: 53.309990\n",
      "Train Epoch: 49 [38000/39785 (1%)]\tLoss: 44.400478\n",
      "Train Epoch: 49 [39000/39785 (1%)]\tLoss: 53.712257\n",
      "39690\n",
      "39785\n",
      "Train Epoch: 50 [1000/39785 (0%)]\tLoss: 39.030766\n",
      "Train Epoch: 50 [2000/39785 (0%)]\tLoss: 35.629250\n",
      "Train Epoch: 50 [3000/39785 (0%)]\tLoss: 44.028057\n",
      "Train Epoch: 50 [4000/39785 (0%)]\tLoss: 50.482384\n",
      "Train Epoch: 50 [5000/39785 (0%)]\tLoss: 36.782291\n",
      "Train Epoch: 50 [6000/39785 (0%)]\tLoss: 60.279572\n",
      "Train Epoch: 50 [7000/39785 (0%)]\tLoss: 35.341881\n",
      "Train Epoch: 50 [8000/39785 (0%)]\tLoss: 33.121078\n",
      "Train Epoch: 50 [9000/39785 (0%)]\tLoss: 38.046322\n",
      "Train Epoch: 50 [10000/39785 (0%)]\tLoss: 53.047001\n",
      "Train Epoch: 50 [11000/39785 (0%)]\tLoss: 31.434372\n",
      "Train Epoch: 50 [12000/39785 (0%)]\tLoss: 43.813564\n",
      "Train Epoch: 50 [13000/39785 (0%)]\tLoss: 36.264107\n",
      "Train Epoch: 50 [14000/39785 (0%)]\tLoss: 33.790997\n",
      "Train Epoch: 50 [15000/39785 (0%)]\tLoss: 34.298363\n",
      "Train Epoch: 50 [16000/39785 (0%)]\tLoss: 47.195850\n",
      "Train Epoch: 50 [17000/39785 (0%)]\tLoss: 24.638361\n",
      "Train Epoch: 50 [18000/39785 (0%)]\tLoss: 40.137726\n",
      "Train Epoch: 50 [19000/39785 (0%)]\tLoss: 31.360723\n",
      "Train Epoch: 50 [20000/39785 (1%)]\tLoss: 31.348629\n",
      "Train Epoch: 50 [21000/39785 (1%)]\tLoss: 37.492744\n",
      "Train Epoch: 50 [22000/39785 (1%)]\tLoss: 46.502548\n",
      "Train Epoch: 50 [23000/39785 (1%)]\tLoss: 40.792576\n",
      "Train Epoch: 50 [24000/39785 (1%)]\tLoss: 31.882435\n",
      "Train Epoch: 50 [25000/39785 (1%)]\tLoss: 38.682629\n",
      "Train Epoch: 50 [26000/39785 (1%)]\tLoss: 30.587196\n",
      "Train Epoch: 50 [27000/39785 (1%)]\tLoss: 43.772877\n",
      "Train Epoch: 50 [28000/39785 (1%)]\tLoss: 34.527546\n",
      "Train Epoch: 50 [29000/39785 (1%)]\tLoss: 35.693237\n",
      "Train Epoch: 50 [30000/39785 (1%)]\tLoss: 27.667229\n",
      "Train Epoch: 50 [31000/39785 (1%)]\tLoss: 35.313511\n",
      "Train Epoch: 50 [32000/39785 (1%)]\tLoss: 44.024723\n",
      "Train Epoch: 50 [33000/39785 (1%)]\tLoss: 48.034748\n",
      "Train Epoch: 50 [34000/39785 (1%)]\tLoss: 54.968147\n",
      "Train Epoch: 50 [35000/39785 (1%)]\tLoss: 49.436531\n",
      "Train Epoch: 50 [36000/39785 (1%)]\tLoss: 49.317997\n",
      "Train Epoch: 50 [37000/39785 (1%)]\tLoss: 63.273865\n",
      "Train Epoch: 50 [38000/39785 (1%)]\tLoss: 61.601475\n",
      "Train Epoch: 50 [39000/39785 (1%)]\tLoss: 40.346458\n",
      "39705\n",
      "39785\n",
      "Train Epoch: 51 [1000/39785 (0%)]\tLoss: 245.633362\n",
      "Train Epoch: 51 [2000/39785 (0%)]\tLoss: 1290.638184\n",
      "Train Epoch: 51 [3000/39785 (0%)]\tLoss: 975.441162\n",
      "Train Epoch: 51 [4000/39785 (0%)]\tLoss: 370.157867\n",
      "Train Epoch: 51 [5000/39785 (0%)]\tLoss: 212.847961\n",
      "Train Epoch: 51 [6000/39785 (0%)]\tLoss: 211.512665\n",
      "Train Epoch: 51 [7000/39785 (0%)]\tLoss: 165.600113\n",
      "Train Epoch: 51 [8000/39785 (0%)]\tLoss: 118.147331\n",
      "Train Epoch: 51 [9000/39785 (0%)]\tLoss: 102.913536\n",
      "Train Epoch: 51 [10000/39785 (0%)]\tLoss: 83.549240\n",
      "Train Epoch: 51 [11000/39785 (0%)]\tLoss: 79.583832\n",
      "Train Epoch: 51 [12000/39785 (0%)]\tLoss: 81.242493\n",
      "Train Epoch: 51 [13000/39785 (0%)]\tLoss: 56.132122\n",
      "Train Epoch: 51 [14000/39785 (0%)]\tLoss: 88.589600\n",
      "Train Epoch: 51 [15000/39785 (0%)]\tLoss: 62.752037\n",
      "Train Epoch: 51 [16000/39785 (0%)]\tLoss: 51.518368\n",
      "Train Epoch: 51 [17000/39785 (0%)]\tLoss: 56.783573\n",
      "Train Epoch: 51 [18000/39785 (0%)]\tLoss: 63.921070\n",
      "Train Epoch: 51 [19000/39785 (0%)]\tLoss: 79.421753\n",
      "Train Epoch: 51 [20000/39785 (1%)]\tLoss: 57.413986\n",
      "Train Epoch: 51 [21000/39785 (1%)]\tLoss: 60.585175\n",
      "Train Epoch: 51 [22000/39785 (1%)]\tLoss: 58.157043\n",
      "Train Epoch: 51 [23000/39785 (1%)]\tLoss: 49.365593\n",
      "Train Epoch: 51 [24000/39785 (1%)]\tLoss: 40.158810\n",
      "Train Epoch: 51 [25000/39785 (1%)]\tLoss: 49.990444\n",
      "Train Epoch: 51 [26000/39785 (1%)]\tLoss: 38.120300\n",
      "Train Epoch: 51 [27000/39785 (1%)]\tLoss: 45.917286\n",
      "Train Epoch: 51 [28000/39785 (1%)]\tLoss: 47.426804\n",
      "Train Epoch: 51 [29000/39785 (1%)]\tLoss: 44.105030\n",
      "Train Epoch: 51 [30000/39785 (1%)]\tLoss: 37.507378\n",
      "Train Epoch: 51 [31000/39785 (1%)]\tLoss: 36.557926\n",
      "Train Epoch: 51 [32000/39785 (1%)]\tLoss: 32.688835\n",
      "Train Epoch: 51 [33000/39785 (1%)]\tLoss: 33.413982\n",
      "Train Epoch: 51 [34000/39785 (1%)]\tLoss: 47.129299\n",
      "Train Epoch: 51 [35000/39785 (1%)]\tLoss: 35.773319\n",
      "Train Epoch: 51 [36000/39785 (1%)]\tLoss: 40.590256\n",
      "Train Epoch: 51 [37000/39785 (1%)]\tLoss: 50.250336\n",
      "Train Epoch: 51 [38000/39785 (1%)]\tLoss: 52.172821\n",
      "Train Epoch: 51 [39000/39785 (1%)]\tLoss: 37.146942\n",
      "39720\n",
      "39785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 52 [1000/39785 (0%)]\tLoss: 38.039146\n",
      "Train Epoch: 52 [2000/39785 (0%)]\tLoss: 31.030167\n",
      "Train Epoch: 52 [3000/39785 (0%)]\tLoss: 39.226330\n",
      "Train Epoch: 52 [4000/39785 (0%)]\tLoss: 36.567795\n",
      "Train Epoch: 52 [5000/39785 (0%)]\tLoss: 33.601250\n",
      "Train Epoch: 52 [6000/39785 (0%)]\tLoss: 28.641104\n",
      "Train Epoch: 52 [7000/39785 (0%)]\tLoss: 27.337687\n",
      "Train Epoch: 52 [8000/39785 (0%)]\tLoss: 43.180580\n",
      "Train Epoch: 52 [9000/39785 (0%)]\tLoss: 45.932602\n",
      "Train Epoch: 52 [10000/39785 (0%)]\tLoss: 40.116055\n",
      "Train Epoch: 52 [11000/39785 (0%)]\tLoss: 36.361622\n",
      "Train Epoch: 52 [12000/39785 (0%)]\tLoss: 38.304241\n",
      "Train Epoch: 52 [13000/39785 (0%)]\tLoss: 29.187811\n",
      "Train Epoch: 52 [14000/39785 (0%)]\tLoss: 33.373589\n",
      "Train Epoch: 52 [15000/39785 (0%)]\tLoss: 27.518009\n",
      "Train Epoch: 52 [16000/39785 (0%)]\tLoss: 33.967640\n",
      "Train Epoch: 52 [17000/39785 (0%)]\tLoss: 41.698776\n",
      "Train Epoch: 52 [18000/39785 (0%)]\tLoss: 47.840401\n",
      "Train Epoch: 52 [19000/39785 (0%)]\tLoss: 43.202614\n",
      "Train Epoch: 52 [20000/39785 (1%)]\tLoss: 33.501270\n",
      "Train Epoch: 52 [21000/39785 (1%)]\tLoss: 38.126930\n",
      "Train Epoch: 52 [22000/39785 (1%)]\tLoss: 35.162750\n",
      "Train Epoch: 52 [23000/39785 (1%)]\tLoss: 52.933216\n",
      "Train Epoch: 52 [24000/39785 (1%)]\tLoss: 39.443275\n",
      "Train Epoch: 52 [25000/39785 (1%)]\tLoss: 45.812271\n",
      "Train Epoch: 52 [26000/39785 (1%)]\tLoss: 33.513096\n",
      "Train Epoch: 52 [27000/39785 (1%)]\tLoss: 30.105570\n",
      "Train Epoch: 52 [28000/39785 (1%)]\tLoss: 115.162903\n",
      "Train Epoch: 52 [29000/39785 (1%)]\tLoss: 36.799877\n",
      "Train Epoch: 52 [30000/39785 (1%)]\tLoss: 79.641243\n",
      "Train Epoch: 52 [31000/39785 (1%)]\tLoss: 44.683342\n",
      "Train Epoch: 52 [32000/39785 (1%)]\tLoss: 41.861828\n",
      "Train Epoch: 52 [33000/39785 (1%)]\tLoss: 36.386410\n",
      "Train Epoch: 52 [34000/39785 (1%)]\tLoss: 25.169800\n",
      "Train Epoch: 52 [35000/39785 (1%)]\tLoss: 40.090363\n",
      "Train Epoch: 52 [36000/39785 (1%)]\tLoss: 42.937912\n",
      "Train Epoch: 52 [37000/39785 (1%)]\tLoss: 33.451618\n",
      "Train Epoch: 52 [38000/39785 (1%)]\tLoss: 42.912094\n",
      "Train Epoch: 52 [39000/39785 (1%)]\tLoss: 38.099072\n",
      "39735\n",
      "39785\n",
      "Train Epoch: 53 [1000/39785 (0%)]\tLoss: 30.935684\n",
      "Train Epoch: 53 [2000/39785 (0%)]\tLoss: 26.749617\n",
      "Train Epoch: 53 [3000/39785 (0%)]\tLoss: 25.850412\n",
      "Train Epoch: 53 [4000/39785 (0%)]\tLoss: 27.773577\n",
      "Train Epoch: 53 [5000/39785 (0%)]\tLoss: 32.169285\n",
      "Train Epoch: 53 [6000/39785 (0%)]\tLoss: 26.720512\n",
      "Train Epoch: 53 [7000/39785 (0%)]\tLoss: 33.131790\n",
      "Train Epoch: 53 [8000/39785 (0%)]\tLoss: 32.300785\n",
      "Train Epoch: 53 [9000/39785 (0%)]\tLoss: 26.212700\n",
      "Train Epoch: 53 [10000/39785 (0%)]\tLoss: 31.032681\n",
      "Train Epoch: 53 [11000/39785 (0%)]\tLoss: 26.894966\n",
      "Train Epoch: 53 [12000/39785 (0%)]\tLoss: 18.933193\n",
      "Train Epoch: 53 [13000/39785 (0%)]\tLoss: 35.782722\n",
      "Train Epoch: 53 [14000/39785 (0%)]\tLoss: 27.082575\n",
      "Train Epoch: 53 [15000/39785 (0%)]\tLoss: 27.282667\n",
      "Train Epoch: 53 [16000/39785 (0%)]\tLoss: 30.920380\n",
      "Train Epoch: 53 [17000/39785 (0%)]\tLoss: 36.591450\n",
      "Train Epoch: 53 [18000/39785 (0%)]\tLoss: 50.717117\n",
      "Train Epoch: 53 [19000/39785 (0%)]\tLoss: 32.265739\n",
      "Train Epoch: 53 [20000/39785 (1%)]\tLoss: 30.021923\n",
      "Train Epoch: 53 [21000/39785 (1%)]\tLoss: 25.626738\n",
      "Train Epoch: 53 [22000/39785 (1%)]\tLoss: 22.417484\n",
      "Train Epoch: 53 [23000/39785 (1%)]\tLoss: 22.724390\n",
      "Train Epoch: 53 [24000/39785 (1%)]\tLoss: 23.477896\n",
      "Train Epoch: 53 [25000/39785 (1%)]\tLoss: 26.282034\n",
      "Train Epoch: 53 [26000/39785 (1%)]\tLoss: 30.383244\n",
      "Train Epoch: 53 [27000/39785 (1%)]\tLoss: 24.868771\n",
      "Train Epoch: 53 [28000/39785 (1%)]\tLoss: 64.492424\n",
      "Train Epoch: 53 [29000/39785 (1%)]\tLoss: 92.715958\n",
      "Train Epoch: 53 [30000/39785 (1%)]\tLoss: 35.353230\n",
      "Train Epoch: 53 [31000/39785 (1%)]\tLoss: 26.451946\n",
      "Train Epoch: 53 [32000/39785 (1%)]\tLoss: 29.269083\n",
      "Train Epoch: 53 [33000/39785 (1%)]\tLoss: 21.387524\n",
      "Train Epoch: 53 [34000/39785 (1%)]\tLoss: 21.906258\n",
      "Train Epoch: 53 [35000/39785 (1%)]\tLoss: 32.077908\n",
      "Train Epoch: 53 [36000/39785 (1%)]\tLoss: 25.747593\n",
      "Train Epoch: 53 [37000/39785 (1%)]\tLoss: 24.909128\n",
      "Train Epoch: 53 [38000/39785 (1%)]\tLoss: 28.247156\n",
      "Train Epoch: 53 [39000/39785 (1%)]\tLoss: 35.585445\n",
      "39750\n",
      "39785\n",
      "Train Epoch: 54 [1000/39785 (0%)]\tLoss: 38.301025\n",
      "Train Epoch: 54 [2000/39785 (0%)]\tLoss: 29.294937\n",
      "Train Epoch: 54 [3000/39785 (0%)]\tLoss: 29.747690\n",
      "Train Epoch: 54 [4000/39785 (0%)]\tLoss: 25.025486\n",
      "Train Epoch: 54 [5000/39785 (0%)]\tLoss: 27.431581\n",
      "Train Epoch: 54 [6000/39785 (0%)]\tLoss: 22.694452\n",
      "Train Epoch: 54 [7000/39785 (0%)]\tLoss: 21.327778\n",
      "Train Epoch: 54 [8000/39785 (0%)]\tLoss: 41.254696\n",
      "Train Epoch: 54 [9000/39785 (0%)]\tLoss: 22.047335\n",
      "Train Epoch: 54 [10000/39785 (0%)]\tLoss: 26.420328\n",
      "Train Epoch: 54 [11000/39785 (0%)]\tLoss: 28.410940\n",
      "Train Epoch: 54 [12000/39785 (0%)]\tLoss: 22.802069\n",
      "Train Epoch: 54 [13000/39785 (0%)]\tLoss: 31.644939\n",
      "Train Epoch: 54 [14000/39785 (0%)]\tLoss: 23.006321\n",
      "Train Epoch: 54 [15000/39785 (0%)]\tLoss: 26.353680\n",
      "Train Epoch: 54 [16000/39785 (0%)]\tLoss: 26.631203\n",
      "Train Epoch: 54 [17000/39785 (0%)]\tLoss: 23.190664\n",
      "Train Epoch: 54 [18000/39785 (0%)]\tLoss: 26.910025\n",
      "Train Epoch: 54 [19000/39785 (0%)]\tLoss: 25.698818\n",
      "Train Epoch: 54 [20000/39785 (1%)]\tLoss: 23.420612\n",
      "Train Epoch: 54 [21000/39785 (1%)]\tLoss: 23.000835\n",
      "Train Epoch: 54 [22000/39785 (1%)]\tLoss: 29.026093\n",
      "Train Epoch: 54 [23000/39785 (1%)]\tLoss: 1100.053955\n",
      "Train Epoch: 54 [24000/39785 (1%)]\tLoss: 46.140652\n",
      "Train Epoch: 54 [25000/39785 (1%)]\tLoss: 37.831635\n",
      "Train Epoch: 54 [26000/39785 (1%)]\tLoss: 27.915199\n",
      "Train Epoch: 54 [27000/39785 (1%)]\tLoss: 34.284264\n",
      "Train Epoch: 54 [28000/39785 (1%)]\tLoss: 33.783222\n",
      "Train Epoch: 54 [29000/39785 (1%)]\tLoss: 31.164474\n",
      "Train Epoch: 54 [30000/39785 (1%)]\tLoss: 25.536428\n",
      "Train Epoch: 54 [31000/39785 (1%)]\tLoss: 31.094143\n",
      "Train Epoch: 54 [32000/39785 (1%)]\tLoss: 35.221264\n",
      "Train Epoch: 54 [33000/39785 (1%)]\tLoss: 48.122154\n",
      "Train Epoch: 54 [34000/39785 (1%)]\tLoss: 30.693888\n",
      "Train Epoch: 54 [35000/39785 (1%)]\tLoss: 31.075033\n",
      "Train Epoch: 54 [36000/39785 (1%)]\tLoss: 28.720274\n",
      "Train Epoch: 54 [37000/39785 (1%)]\tLoss: 34.185329\n",
      "Train Epoch: 54 [38000/39785 (1%)]\tLoss: 27.552822\n",
      "Train Epoch: 54 [39000/39785 (1%)]\tLoss: 24.004080\n",
      "39765\n",
      "39785\n",
      "Train Epoch: 55 [1000/39785 (0%)]\tLoss: 26.820412\n",
      "Train Epoch: 55 [2000/39785 (0%)]\tLoss: 22.456963\n",
      "Train Epoch: 55 [3000/39785 (0%)]\tLoss: 20.800056\n",
      "Train Epoch: 55 [4000/39785 (0%)]\tLoss: 20.737953\n",
      "Train Epoch: 55 [5000/39785 (0%)]\tLoss: 38.617222\n",
      "Train Epoch: 55 [6000/39785 (0%)]\tLoss: 30.537565\n",
      "Train Epoch: 55 [7000/39785 (0%)]\tLoss: 21.307657\n",
      "Train Epoch: 55 [8000/39785 (0%)]\tLoss: 24.560526\n",
      "Train Epoch: 55 [9000/39785 (0%)]\tLoss: 21.507814\n",
      "Train Epoch: 55 [10000/39785 (0%)]\tLoss: 19.101578\n",
      "Train Epoch: 55 [11000/39785 (0%)]\tLoss: 30.676962\n",
      "Train Epoch: 55 [12000/39785 (0%)]\tLoss: 20.019526\n",
      "Train Epoch: 55 [13000/39785 (0%)]\tLoss: 30.597519\n",
      "Train Epoch: 55 [14000/39785 (0%)]\tLoss: 27.169111\n",
      "Train Epoch: 55 [15000/39785 (0%)]\tLoss: 38.400932\n",
      "Train Epoch: 55 [16000/39785 (0%)]\tLoss: 21.111471\n",
      "Train Epoch: 55 [17000/39785 (0%)]\tLoss: 26.386221\n",
      "Train Epoch: 55 [18000/39785 (0%)]\tLoss: 22.191681\n",
      "Train Epoch: 55 [19000/39785 (0%)]\tLoss: 23.658970\n",
      "Train Epoch: 55 [20000/39785 (1%)]\tLoss: 27.168459\n",
      "Train Epoch: 55 [21000/39785 (1%)]\tLoss: 32.701488\n",
      "Train Epoch: 55 [22000/39785 (1%)]\tLoss: 44.660763\n",
      "Train Epoch: 55 [23000/39785 (1%)]\tLoss: 18.578144\n",
      "Train Epoch: 55 [24000/39785 (1%)]\tLoss: 26.849394\n",
      "Train Epoch: 55 [25000/39785 (1%)]\tLoss: 26.129923\n",
      "Train Epoch: 55 [26000/39785 (1%)]\tLoss: 24.893652\n",
      "Train Epoch: 55 [27000/39785 (1%)]\tLoss: 29.704638\n",
      "Train Epoch: 55 [28000/39785 (1%)]\tLoss: 21.593313\n",
      "Train Epoch: 55 [29000/39785 (1%)]\tLoss: 23.262680\n",
      "Train Epoch: 55 [30000/39785 (1%)]\tLoss: 24.529600\n",
      "Train Epoch: 55 [31000/39785 (1%)]\tLoss: 22.473238\n",
      "Train Epoch: 55 [32000/39785 (1%)]\tLoss: 35.434097\n",
      "Train Epoch: 55 [33000/39785 (1%)]\tLoss: 28.401802\n",
      "Train Epoch: 55 [34000/39785 (1%)]\tLoss: 34.122269\n",
      "Train Epoch: 55 [35000/39785 (1%)]\tLoss: 23.281935\n",
      "Train Epoch: 55 [36000/39785 (1%)]\tLoss: 37.065605\n",
      "Train Epoch: 55 [37000/39785 (1%)]\tLoss: 28.325369\n",
      "Train Epoch: 55 [38000/39785 (1%)]\tLoss: 30.771664\n",
      "Train Epoch: 55 [39000/39785 (1%)]\tLoss: 25.156414\n",
      "39780\n",
      "39785\n",
      "Train Epoch: 56 [1000/39785 (0%)]\tLoss: 40.346943\n",
      "Train Epoch: 56 [2000/39785 (0%)]\tLoss: 23.813725\n",
      "Train Epoch: 56 [3000/39785 (0%)]\tLoss: 19.729685\n",
      "Train Epoch: 56 [4000/39785 (0%)]\tLoss: 18.700098\n",
      "Train Epoch: 56 [5000/39785 (0%)]\tLoss: 19.951433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 56 [6000/39785 (0%)]\tLoss: 29.782087\n",
      "Train Epoch: 56 [7000/39785 (0%)]\tLoss: 24.443213\n",
      "Train Epoch: 56 [8000/39785 (0%)]\tLoss: 22.717445\n",
      "Train Epoch: 56 [9000/39785 (0%)]\tLoss: 25.146513\n",
      "Train Epoch: 56 [10000/39785 (0%)]\tLoss: 23.430019\n",
      "Train Epoch: 56 [11000/39785 (0%)]\tLoss: 25.108603\n",
      "Train Epoch: 56 [12000/39785 (0%)]\tLoss: 348.366119\n",
      "Train Epoch: 56 [13000/39785 (0%)]\tLoss: 25.848816\n",
      "Train Epoch: 56 [14000/39785 (0%)]\tLoss: 18.311773\n",
      "Train Epoch: 56 [15000/39785 (0%)]\tLoss: 24.141392\n",
      "Train Epoch: 56 [16000/39785 (0%)]\tLoss: 27.882996\n",
      "Train Epoch: 56 [17000/39785 (0%)]\tLoss: 25.426882\n",
      "Train Epoch: 56 [18000/39785 (0%)]\tLoss: 21.784637\n",
      "Train Epoch: 56 [19000/39785 (0%)]\tLoss: 23.197939\n",
      "Train Epoch: 56 [20000/39785 (1%)]\tLoss: 18.033220\n",
      "Train Epoch: 56 [21000/39785 (1%)]\tLoss: 19.812561\n",
      "Train Epoch: 56 [22000/39785 (1%)]\tLoss: 22.534891\n",
      "Train Epoch: 56 [23000/39785 (1%)]\tLoss: 21.964024\n",
      "Train Epoch: 56 [24000/39785 (1%)]\tLoss: 18.788759\n",
      "Train Epoch: 56 [25000/39785 (1%)]\tLoss: 23.283951\n",
      "Train Epoch: 56 [26000/39785 (1%)]\tLoss: 22.836489\n",
      "Train Epoch: 56 [27000/39785 (1%)]\tLoss: 23.572117\n",
      "Train Epoch: 56 [28000/39785 (1%)]\tLoss: 18.990105\n",
      "Train Epoch: 56 [29000/39785 (1%)]\tLoss: 29.902483\n",
      "Train Epoch: 56 [30000/39785 (1%)]\tLoss: 16.541397\n",
      "Train Epoch: 56 [31000/39785 (1%)]\tLoss: 23.624159\n",
      "Train Epoch: 56 [32000/39785 (1%)]\tLoss: 18.775612\n",
      "Train Epoch: 56 [33000/39785 (1%)]\tLoss: 23.158756\n",
      "Train Epoch: 56 [34000/39785 (1%)]\tLoss: 28.654356\n",
      "Train Epoch: 56 [35000/39785 (1%)]\tLoss: 33.441929\n",
      "Train Epoch: 56 [36000/39785 (1%)]\tLoss: 27.516497\n",
      "Train Epoch: 56 [37000/39785 (1%)]\tLoss: 33.032768\n",
      "Train Epoch: 56 [38000/39785 (1%)]\tLoss: 23.497335\n",
      "Train Epoch: 56 [39000/39785 (1%)]\tLoss: 22.804968\n",
      "39695\n",
      "39785\n",
      "Train Epoch: 57 [1000/39785 (0%)]\tLoss: 25.039886\n",
      "Train Epoch: 57 [2000/39785 (0%)]\tLoss: 25.011707\n",
      "Train Epoch: 57 [3000/39785 (0%)]\tLoss: 32.049129\n",
      "Train Epoch: 57 [4000/39785 (0%)]\tLoss: 24.985491\n",
      "Train Epoch: 57 [5000/39785 (0%)]\tLoss: 25.667234\n",
      "Train Epoch: 57 [6000/39785 (0%)]\tLoss: 19.750296\n",
      "Train Epoch: 57 [7000/39785 (0%)]\tLoss: 33.184429\n",
      "Train Epoch: 57 [8000/39785 (0%)]\tLoss: 21.804970\n",
      "Train Epoch: 57 [9000/39785 (0%)]\tLoss: 25.020594\n",
      "Train Epoch: 57 [10000/39785 (0%)]\tLoss: 26.220009\n",
      "Train Epoch: 57 [11000/39785 (0%)]\tLoss: 37.190399\n",
      "Train Epoch: 57 [12000/39785 (0%)]\tLoss: 20.889578\n",
      "Train Epoch: 57 [13000/39785 (0%)]\tLoss: 27.368891\n",
      "Train Epoch: 57 [14000/39785 (0%)]\tLoss: 26.183420\n",
      "Train Epoch: 57 [15000/39785 (0%)]\tLoss: 24.276604\n",
      "Train Epoch: 57 [16000/39785 (0%)]\tLoss: 33.221066\n",
      "Train Epoch: 57 [17000/39785 (0%)]\tLoss: 28.273907\n",
      "Train Epoch: 57 [18000/39785 (0%)]\tLoss: 17.077488\n",
      "Train Epoch: 57 [19000/39785 (0%)]\tLoss: 22.683292\n",
      "Train Epoch: 57 [20000/39785 (1%)]\tLoss: 22.721943\n",
      "Train Epoch: 57 [21000/39785 (1%)]\tLoss: 26.080614\n",
      "Train Epoch: 57 [22000/39785 (1%)]\tLoss: 21.812300\n",
      "Train Epoch: 57 [23000/39785 (1%)]\tLoss: 37.637207\n",
      "Train Epoch: 57 [24000/39785 (1%)]\tLoss: 21.816526\n",
      "Train Epoch: 57 [25000/39785 (1%)]\tLoss: 20.450565\n",
      "Train Epoch: 57 [26000/39785 (1%)]\tLoss: 25.512480\n",
      "Train Epoch: 57 [27000/39785 (1%)]\tLoss: 21.828575\n",
      "Train Epoch: 57 [28000/39785 (1%)]\tLoss: 20.260138\n",
      "Train Epoch: 57 [29000/39785 (1%)]\tLoss: 32.379028\n",
      "Train Epoch: 57 [30000/39785 (1%)]\tLoss: 25.099968\n",
      "Train Epoch: 57 [31000/39785 (1%)]\tLoss: 27.966480\n",
      "Train Epoch: 57 [32000/39785 (1%)]\tLoss: 25.878149\n",
      "Train Epoch: 57 [33000/39785 (1%)]\tLoss: 23.647371\n",
      "Train Epoch: 57 [34000/39785 (1%)]\tLoss: 24.067379\n",
      "Train Epoch: 57 [35000/39785 (1%)]\tLoss: 21.702301\n",
      "Train Epoch: 57 [36000/39785 (1%)]\tLoss: 28.761503\n",
      "Train Epoch: 57 [37000/39785 (1%)]\tLoss: 36.000648\n",
      "Train Epoch: 57 [38000/39785 (1%)]\tLoss: 31.441282\n",
      "Train Epoch: 57 [39000/39785 (1%)]\tLoss: 26.025558\n",
      "39710\n",
      "39785\n",
      "Train Epoch: 58 [1000/39785 (0%)]\tLoss: 28.076509\n",
      "Train Epoch: 58 [2000/39785 (0%)]\tLoss: 26.691439\n",
      "Train Epoch: 58 [3000/39785 (0%)]\tLoss: 21.993858\n",
      "Train Epoch: 58 [4000/39785 (0%)]\tLoss: 18.267784\n",
      "Train Epoch: 58 [5000/39785 (0%)]\tLoss: 26.297415\n",
      "Train Epoch: 58 [6000/39785 (0%)]\tLoss: 22.787678\n",
      "Train Epoch: 58 [7000/39785 (0%)]\tLoss: 28.706373\n",
      "Train Epoch: 58 [8000/39785 (0%)]\tLoss: 22.808325\n",
      "Train Epoch: 58 [9000/39785 (0%)]\tLoss: 36.795284\n",
      "Train Epoch: 58 [10000/39785 (0%)]\tLoss: 28.987705\n",
      "Train Epoch: 58 [11000/39785 (0%)]\tLoss: 27.497620\n",
      "Train Epoch: 58 [12000/39785 (0%)]\tLoss: 38.966774\n",
      "Train Epoch: 58 [13000/39785 (0%)]\tLoss: 28.732668\n",
      "Train Epoch: 58 [14000/39785 (0%)]\tLoss: 25.281929\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-7791b9d3356e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_hard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecr_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# test(model_hard, device, test_set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-8503584ebb6d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-8503584ebb6d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# x = self.gated(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m#x = self.pool2(self.conv2(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tf.reshape(x,[batchSize,-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/se3cnn-0.0.0-py3.7.egg/se3cnn/convolution.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# matrix_size = 16\n",
    "# train_set = untransformed(50, matrix_size)\n",
    "'''\n",
    "test_set = [(a_i, torch.tensor([1,1,1], dtype=torch.float32)), \n",
    "            (rotation_1(a_i), torch.tensor([-1,1,1], dtype=torch.float32)), \n",
    "            (rotation_1(rotation_1(a_i)), torch.tensor([-1,1,-1], dtype=torch.float32)), \n",
    "            (rotation_1(rotation_1(rotation_1(a_i))), torch.tensor([1,1,-1], dtype=torch.float32))]\n",
    "'''\n",
    "\n",
    "model_hard = EquiNet().to(device)\n",
    "learning_rate = 5e-3\n",
    "optimizer = torch.optim.Adam(model_hard.parameters(), lr=learning_rate)\n",
    "\n",
    "per_epoch = 150\n",
    "decr_rate = 0.99\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model_hard, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate)\n",
    "    # test(model_hard, device, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = model_hard(torch.from_numpy(train_set._images[:100].reshape(batch_size,1,24,24,24)).type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4324,  0.8455,  0.0822,  0.1313, -0.1046, -0.4683,  0.2780],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.86292964,  0.03844497,  0.09862536, -0.08708213,\n",
       "       -0.41256937,  0.25758612], dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set._labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../deepSymmetry/data/fromScripts/dataReady0\n",
      "Extracting ../deepSymmetry/data/fromScripts/dataReady0_label\n",
      "(39785, 13824)\n"
     ]
    }
   ],
   "source": [
    "train_name = '../deepSymmetry/data/fromScripts/dataReady0'\n",
    "train_set = load_data.read_data_set(train_name, dtype=dtypes.float16, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../deepSymmetry/data/densityMaps/density_testf\n",
      "Extracting ../deepSymmetry/data/densityMaps/density_testf_label\n",
      "(120000, 13824)\n"
     ]
    }
   ],
   "source": [
    "test_name = '../deepSymmetry/data/densityMaps/density_testf'\n",
    "test_set = load_data.read_data_set(test_name, dtype=dtypes.float16, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_test = model_hard(torch.from_numpy(test_set._images[:100].reshape(batch_size,1,24,24,24)).type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.681089878082275, 0.8225629329681396, 0.24174951016902924, 0.033087629824876785, 0.010919880121946335, -0.17829450964927673, 0.6451407074928284]\n",
      "[ 7.          0.8140826   0.16944312  0.01647427 -0.07471883 -0.16377677\n",
      "  0.5252441 ]\n",
      "\n",
      "[7.156384468078613, -0.09772703796625137, 0.8188420534133911, 0.08037760853767395, -0.6574083566665649, 0.03126903250813484, -0.26504260301589966]\n",
      "[ 7.          0.01401387  0.8029993   0.18298681 -0.5421038   0.071615\n",
      " -0.15002087]\n",
      "\n",
      "[8.394238471984863, 1.0517383813858032, 0.08680028468370438, 0.1367802619934082, 0.03753487020730972, 0.0565904825925827, -0.18338654935359955]\n",
      "[ 7.0000000e+00  9.5146030e-01  4.8440255e-02  9.9439159e-05\n",
      " -3.1038227e-03  1.3755901e-02 -3.0360824e-01]\n",
      "\n",
      "[7.138195991516113, 0.21090511977672577, 0.5391544103622437, 0.294271856546402, -0.5449842214584351, -0.480374276638031, 0.7109291553497314]\n",
      "[ 7.          0.23470888  0.4653611   0.29993004 -0.5283479  -0.37522325\n",
      "  0.46738502]\n",
      "\n",
      "[8.730587005615234, 0.6358888149261475, 0.33428075909614563, 0.17487573623657227, -0.42174822092056274, 0.6431983709335327, -0.7727349400520325]\n",
      "[ 7.          0.45699063  0.31786323  0.22514616 -0.37832707  0.4536291\n",
      " -0.53900003]\n",
      "\n",
      "[8.575613975524902, 0.2678661346435547, 0.5918046832084656, 0.21760225296020508, 0.8090437650680542, 0.49064743518829346, 0.668545663356781]\n",
      "[7.         0.22514616 0.45699063 0.31786323 0.53900003 0.37832707\n",
      " 0.4536291 ]\n",
      "\n",
      "[6.385571479797363, -0.04580746591091156, 0.9540625810623169, 0.1501503735780716, -0.4468027353286743, 0.10782847553491592, -0.11363757401704788]\n",
      "[ 7.          0.01647427  0.8140826   0.16944312 -0.5252441   0.07471883\n",
      " -0.16377677]\n",
      "\n",
      "[7.198699474334717, 0.14840549230575562, -0.035713471472263336, 0.7983440160751343, 0.34743165969848633, 0.9519135355949402, 0.2301645129919052]\n",
      "[7.         0.18298681 0.01401387 0.8029993  0.15002087 0.5421038\n",
      " 0.071615  ]\n",
      "\n",
      "[8.586642265319824, -0.06985707581043243, 0.9221779704093933, 0.09014852344989777, 0.39408835768699646, -0.0018035918474197388, 0.10627113282680511]\n",
      "[7.0000000e+00 9.9439159e-05 9.5146030e-01 4.8440255e-02 3.0360824e-01\n",
      " 3.1038227e-03 1.3755901e-02]\n",
      "\n",
      "[6.30518913269043, 0.2668163776397705, 0.06963256001472473, 0.39703357219696045, -0.5968856811523438, 0.6275244951248169, -0.49467432498931885]\n",
      "[ 7.          0.29993004  0.23470888  0.4653611  -0.46738502  0.5283479\n",
      " -0.37522325]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(answer_test[i].data.tolist())\n",
    "    print(test_set._labels[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(output, target):\n",
    "    order_out = output[:, 0 : NUM_CLASSES]\n",
    "    order_target = target[:, 0 : 1].type(torch.LongTensor).squeeze_()\n",
    "    axis_out = output[:, NUM_CLASSES : NUM_CLASSES + 6]\n",
    "    axis_target = target[:, 1 : 7]\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()(order_out, order_target) + nn.MSELoss(reduction='sum')(axis_out, axis_target)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = SE3Convolution(repr_in_1, repr_out_1, size=4)\n",
    "        self.pool1 = nn.AvgPool3d(pool_size, pool_stride)\n",
    "        self.conv2 = SE3Convolution(repr_in_2, repr_out_2, size=4)\n",
    "        self.pool2 = nn.AvgPool3d(pool_size, pool_stride)\n",
    "        \n",
    "        self.lin1 = nn.Linear(n_input_1, n_output_1)\n",
    "        self.drop1 = nn.Dropout(prob)\n",
    "        self.lin2 = nn.Linear(n_output_1, n_output_2)\n",
    "        self.drop2 = nn.Dropout(prob)\n",
    "        self.lin3 = nn.Linear(n_output_2, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.gated(x)\n",
    "        x = self.pool1(self.conv1(x))\n",
    "        x = self.pool2(self.conv2(x))\n",
    "        x = x.view(batch_size,-1) # tf.reshape(x,[batchSize,-1])\n",
    "        x = F.leaky_relu(self.lin1(x))\n",
    "        # x = self.drop1(x)\n",
    "        # x = F.relu(self.lin2(x))\n",
    "        # x = self.drop2(x)\n",
    "        return self.lin2(x) #self.lin3(x)\n",
    "    \n",
    "    \n",
    "def train(model, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate):\n",
    "    model.train()\n",
    "    flag = True\n",
    "    new_epoch = True\n",
    "    \n",
    "    if new_epoch:\n",
    "        batch_idx = 1\n",
    "        new_epoch = False\n",
    "        data, target, _ = train_set.next_batch(batch_size)\n",
    "        data = torch.from_numpy(data.reshape(batch_size,1,24,24,24)).type(torch.FloatTensor)\n",
    "        target = torch.from_numpy(target.reshape(batch_size,-1)).type(torch.FloatTensor)\n",
    "        cnt = epoch // per_epoch\n",
    "        if ((epoch+1) // per_epoch > cnt) and flag:\n",
    "            lr = 0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            lr *= decr_rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            flag = False\n",
    "        else:\n",
    "            flag = True\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss_fn = nn.MSELoss(reduction='sum')\n",
    "        # loss = loss_fn(output, target)\n",
    "        loss = custom_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    while (train_set._index_in_epoch + batch_size) < train_set._num_examples:\n",
    "        batch_idx += 1\n",
    "        data, target, _ = train_set.next_batch(batch_size)\n",
    "        data = torch.from_numpy(data.reshape(batch_size,1,24,24,24)).type(torch.FloatTensor)\n",
    "        target = torch.from_numpy(target.reshape(batch_size,-1)).type(torch.FloatTensor)\n",
    "        cnt = epoch // per_epoch\n",
    "        if ((epoch+1) // per_epoch > cnt) and flag:\n",
    "            lr = 0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            lr *= decr_rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            flag = False\n",
    "        else:\n",
    "            flag = True\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss_fn = nn.MSELoss(reduction='sum')\n",
    "        # loss = loss_fn(output, target)\n",
    "        loss = custom_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, train_set._num_examples,\n",
    "                100. * batch_idx / train_set._num_examples, loss.item()))\n",
    "\n",
    "def test(model, device, test_set):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_set:\n",
    "            output = model(data)\n",
    "            loss_fn = nn.MSELoss(reduction='sum')\n",
    "            test_loss += loss_fn(output, target) \n",
    "            # pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += int(torch.argmax(output) == torch.argmax(target))\n",
    "\n",
    "    test_loss /= len(test_set)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_set),\n",
    "        100. * correct / len(test_set)))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_in_1 = [(1,0)]\n",
    "repr_out_1 = [(2,0),(2,1),(2,2),(2,3)]\n",
    "repr_in_2 = [(2,0),(2,1),(2,2),(2,3)]\n",
    "repr_out_2 = [(1,0),(2,1)]\n",
    "size = 4\n",
    "activation = (None, F.leaky_relu)\n",
    "pool_size = 2\n",
    "pool_stride = 2\n",
    "bias = True\n",
    "\n",
    "n_input_1 = 189\n",
    "n_output_1 = 56 \n",
    "n_output_2 = NUM_CLASSES + 6 \n",
    "\n",
    "batch_size = 100\n",
    "prob = 0.5\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../deepSymmetry/data/fromScripts/dataReady0\n",
      "Extracting ../deepSymmetry/data/fromScripts/dataReady0_label\n",
      "(39785, 13824)\n"
     ]
    }
   ],
   "source": [
    "train_name = '../deepSymmetry/data/fromScripts/dataReady0'\n",
    "train_set = load_data.read_data_set(train_name, dtype=dtypes.float16, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1000/39785 (0%)]\tLoss: 46.648594\n",
      "Train Epoch: 1 [2000/39785 (0%)]\tLoss: 41.696766\n",
      "Train Epoch: 1 [3000/39785 (0%)]\tLoss: 35.723019\n",
      "Train Epoch: 1 [4000/39785 (0%)]\tLoss: 32.567127\n",
      "Train Epoch: 1 [5000/39785 (0%)]\tLoss: 26.332949\n",
      "Train Epoch: 1 [6000/39785 (0%)]\tLoss: 33.494045\n",
      "Train Epoch: 1 [7000/39785 (0%)]\tLoss: 27.060057\n",
      "Train Epoch: 1 [8000/39785 (0%)]\tLoss: 19.113297\n",
      "Train Epoch: 1 [9000/39785 (0%)]\tLoss: 22.934341\n",
      "Train Epoch: 1 [10000/39785 (0%)]\tLoss: 24.767778\n",
      "Train Epoch: 1 [11000/39785 (0%)]\tLoss: 24.873268\n",
      "Train Epoch: 1 [12000/39785 (0%)]\tLoss: 21.899326\n",
      "Train Epoch: 1 [13000/39785 (0%)]\tLoss: 20.926369\n",
      "Train Epoch: 1 [14000/39785 (0%)]\tLoss: 22.999231\n",
      "Train Epoch: 1 [15000/39785 (0%)]\tLoss: 20.996355\n",
      "Train Epoch: 1 [16000/39785 (0%)]\tLoss: 21.345695\n",
      "Train Epoch: 1 [17000/39785 (0%)]\tLoss: 24.683270\n",
      "Train Epoch: 1 [18000/39785 (0%)]\tLoss: 19.233530\n",
      "Train Epoch: 1 [19000/39785 (0%)]\tLoss: 22.725492\n",
      "Train Epoch: 1 [20000/39785 (1%)]\tLoss: 22.082321\n",
      "Train Epoch: 1 [21000/39785 (1%)]\tLoss: 20.151461\n",
      "Train Epoch: 1 [22000/39785 (1%)]\tLoss: 17.094738\n",
      "Train Epoch: 1 [23000/39785 (1%)]\tLoss: 17.253321\n",
      "Train Epoch: 1 [24000/39785 (1%)]\tLoss: 18.376595\n",
      "Train Epoch: 1 [25000/39785 (1%)]\tLoss: 16.699930\n",
      "Train Epoch: 1 [26000/39785 (1%)]\tLoss: 18.544584\n",
      "Train Epoch: 1 [27000/39785 (1%)]\tLoss: 16.931784\n",
      "Train Epoch: 1 [28000/39785 (1%)]\tLoss: 20.988781\n",
      "Train Epoch: 1 [29000/39785 (1%)]\tLoss: 17.798824\n",
      "Train Epoch: 1 [30000/39785 (1%)]\tLoss: 18.182367\n",
      "Train Epoch: 1 [31000/39785 (1%)]\tLoss: 18.649237\n",
      "Train Epoch: 1 [32000/39785 (1%)]\tLoss: 15.091253\n",
      "Train Epoch: 1 [33000/39785 (1%)]\tLoss: 18.749844\n",
      "Train Epoch: 1 [34000/39785 (1%)]\tLoss: 17.103748\n",
      "Train Epoch: 1 [35000/39785 (1%)]\tLoss: 23.608999\n",
      "Train Epoch: 1 [36000/39785 (1%)]\tLoss: 19.142250\n",
      "Train Epoch: 1 [37000/39785 (1%)]\tLoss: 17.603039\n",
      "Train Epoch: 1 [38000/39785 (1%)]\tLoss: 21.652309\n",
      "Train Epoch: 1 [39000/39785 (1%)]\tLoss: 15.254982\n",
      "Train Epoch: 2 [1000/39785 (0%)]\tLoss: 14.392473\n",
      "Train Epoch: 2 [2000/39785 (0%)]\tLoss: 19.022451\n",
      "Train Epoch: 2 [3000/39785 (0%)]\tLoss: 19.023384\n",
      "Train Epoch: 2 [4000/39785 (0%)]\tLoss: 17.097355\n",
      "Train Epoch: 2 [5000/39785 (0%)]\tLoss: 14.541278\n",
      "Train Epoch: 2 [6000/39785 (0%)]\tLoss: 13.081747\n",
      "Train Epoch: 2 [7000/39785 (0%)]\tLoss: 16.353849\n",
      "Train Epoch: 2 [8000/39785 (0%)]\tLoss: 15.773908\n",
      "Train Epoch: 2 [9000/39785 (0%)]\tLoss: 14.541514\n",
      "Train Epoch: 2 [10000/39785 (0%)]\tLoss: 18.526669\n",
      "Train Epoch: 2 [11000/39785 (0%)]\tLoss: 14.270598\n",
      "Train Epoch: 2 [12000/39785 (0%)]\tLoss: 20.747025\n",
      "Train Epoch: 2 [13000/39785 (0%)]\tLoss: 16.008623\n",
      "Train Epoch: 2 [14000/39785 (0%)]\tLoss: 16.780245\n",
      "Train Epoch: 2 [15000/39785 (0%)]\tLoss: 14.370271\n",
      "Train Epoch: 2 [16000/39785 (0%)]\tLoss: 21.432610\n",
      "Train Epoch: 2 [17000/39785 (0%)]\tLoss: 16.488350\n",
      "Train Epoch: 2 [18000/39785 (0%)]\tLoss: 16.845051\n",
      "Train Epoch: 2 [19000/39785 (0%)]\tLoss: 17.303951\n",
      "Train Epoch: 2 [20000/39785 (1%)]\tLoss: 17.052078\n",
      "Train Epoch: 2 [21000/39785 (1%)]\tLoss: 20.795570\n",
      "Train Epoch: 2 [22000/39785 (1%)]\tLoss: 15.731544\n",
      "Train Epoch: 2 [23000/39785 (1%)]\tLoss: 16.319593\n",
      "Train Epoch: 2 [24000/39785 (1%)]\tLoss: 14.841831\n",
      "Train Epoch: 2 [25000/39785 (1%)]\tLoss: 16.085632\n",
      "Train Epoch: 2 [26000/39785 (1%)]\tLoss: 19.320137\n",
      "Train Epoch: 2 [27000/39785 (1%)]\tLoss: 16.030794\n",
      "Train Epoch: 2 [28000/39785 (1%)]\tLoss: 12.559588\n",
      "Train Epoch: 2 [29000/39785 (1%)]\tLoss: 15.979687\n",
      "Train Epoch: 2 [30000/39785 (1%)]\tLoss: 19.458399\n",
      "Train Epoch: 2 [31000/39785 (1%)]\tLoss: 16.280684\n",
      "Train Epoch: 2 [32000/39785 (1%)]\tLoss: 17.612442\n",
      "Train Epoch: 2 [33000/39785 (1%)]\tLoss: 15.404036\n",
      "Train Epoch: 2 [34000/39785 (1%)]\tLoss: 14.718454\n",
      "Train Epoch: 2 [35000/39785 (1%)]\tLoss: 15.785028\n",
      "Train Epoch: 2 [36000/39785 (1%)]\tLoss: 18.979116\n",
      "Train Epoch: 2 [37000/39785 (1%)]\tLoss: 17.200811\n",
      "Train Epoch: 2 [38000/39785 (1%)]\tLoss: 16.423422\n",
      "Train Epoch: 2 [39000/39785 (1%)]\tLoss: 14.965608\n",
      "Train Epoch: 3 [1000/39785 (0%)]\tLoss: 14.420113\n",
      "Train Epoch: 3 [2000/39785 (0%)]\tLoss: 18.559332\n",
      "Train Epoch: 3 [3000/39785 (0%)]\tLoss: 14.958141\n",
      "Train Epoch: 3 [4000/39785 (0%)]\tLoss: 18.471382\n",
      "Train Epoch: 3 [5000/39785 (0%)]\tLoss: 13.201229\n",
      "Train Epoch: 3 [6000/39785 (0%)]\tLoss: 19.474936\n",
      "Train Epoch: 3 [7000/39785 (0%)]\tLoss: 19.731550\n",
      "Train Epoch: 3 [8000/39785 (0%)]\tLoss: 16.867197\n",
      "Train Epoch: 3 [9000/39785 (0%)]\tLoss: 13.440257\n",
      "Train Epoch: 3 [10000/39785 (0%)]\tLoss: 15.082128\n",
      "Train Epoch: 3 [11000/39785 (0%)]\tLoss: 17.194744\n",
      "Train Epoch: 3 [12000/39785 (0%)]\tLoss: 12.622370\n",
      "Train Epoch: 3 [13000/39785 (0%)]\tLoss: 14.735040\n",
      "Train Epoch: 3 [14000/39785 (0%)]\tLoss: 11.884960\n",
      "Train Epoch: 3 [15000/39785 (0%)]\tLoss: 14.889650\n",
      "Train Epoch: 3 [16000/39785 (0%)]\tLoss: 17.369781\n",
      "Train Epoch: 3 [17000/39785 (0%)]\tLoss: 15.026018\n",
      "Train Epoch: 3 [18000/39785 (0%)]\tLoss: 16.981609\n",
      "Train Epoch: 3 [19000/39785 (0%)]\tLoss: 19.677750\n",
      "Train Epoch: 3 [20000/39785 (1%)]\tLoss: 11.306179\n",
      "Train Epoch: 3 [21000/39785 (1%)]\tLoss: 13.218935\n",
      "Train Epoch: 3 [22000/39785 (1%)]\tLoss: 14.529720\n",
      "Train Epoch: 3 [23000/39785 (1%)]\tLoss: 18.378477\n",
      "Train Epoch: 3 [24000/39785 (1%)]\tLoss: 17.373751\n",
      "Train Epoch: 3 [25000/39785 (1%)]\tLoss: 15.614205\n",
      "Train Epoch: 3 [26000/39785 (1%)]\tLoss: 18.099188\n",
      "Train Epoch: 3 [27000/39785 (1%)]\tLoss: 12.824747\n",
      "Train Epoch: 3 [28000/39785 (1%)]\tLoss: 16.209396\n",
      "Train Epoch: 3 [29000/39785 (1%)]\tLoss: 15.820563\n",
      "Train Epoch: 3 [30000/39785 (1%)]\tLoss: 15.557301\n",
      "Train Epoch: 3 [31000/39785 (1%)]\tLoss: 16.316458\n",
      "Train Epoch: 3 [32000/39785 (1%)]\tLoss: 15.170198\n",
      "Train Epoch: 3 [33000/39785 (1%)]\tLoss: 16.724833\n",
      "Train Epoch: 3 [34000/39785 (1%)]\tLoss: 15.969538\n",
      "Train Epoch: 3 [35000/39785 (1%)]\tLoss: 13.495256\n",
      "Train Epoch: 3 [36000/39785 (1%)]\tLoss: 15.496180\n",
      "Train Epoch: 3 [37000/39785 (1%)]\tLoss: 13.646740\n",
      "Train Epoch: 3 [38000/39785 (1%)]\tLoss: 14.947067\n",
      "Train Epoch: 3 [39000/39785 (1%)]\tLoss: 16.426155\n",
      "Train Epoch: 4 [1000/39785 (0%)]\tLoss: 15.223183\n",
      "Train Epoch: 4 [2000/39785 (0%)]\tLoss: 15.522886\n",
      "Train Epoch: 4 [3000/39785 (0%)]\tLoss: 13.234108\n",
      "Train Epoch: 4 [4000/39785 (0%)]\tLoss: 13.268106\n",
      "Train Epoch: 4 [5000/39785 (0%)]\tLoss: 14.017321\n",
      "Train Epoch: 4 [6000/39785 (0%)]\tLoss: 11.996151\n",
      "Train Epoch: 4 [7000/39785 (0%)]\tLoss: 15.671361\n",
      "Train Epoch: 4 [8000/39785 (0%)]\tLoss: 14.483809\n",
      "Train Epoch: 4 [9000/39785 (0%)]\tLoss: 14.174938\n",
      "Train Epoch: 4 [10000/39785 (0%)]\tLoss: 15.965101\n",
      "Train Epoch: 4 [11000/39785 (0%)]\tLoss: 19.446220\n",
      "Train Epoch: 4 [12000/39785 (0%)]\tLoss: 14.496213\n",
      "Train Epoch: 4 [13000/39785 (0%)]\tLoss: 14.161602\n",
      "Train Epoch: 4 [14000/39785 (0%)]\tLoss: 19.372890\n",
      "Train Epoch: 4 [15000/39785 (0%)]\tLoss: 12.092718\n",
      "Train Epoch: 4 [16000/39785 (0%)]\tLoss: 17.614155\n",
      "Train Epoch: 4 [17000/39785 (0%)]\tLoss: 16.186682\n",
      "Train Epoch: 4 [18000/39785 (0%)]\tLoss: 16.269224\n",
      "Train Epoch: 4 [19000/39785 (0%)]\tLoss: 12.945483\n",
      "Train Epoch: 4 [20000/39785 (1%)]\tLoss: 13.785563\n",
      "Train Epoch: 4 [21000/39785 (1%)]\tLoss: 17.688423\n",
      "Train Epoch: 4 [22000/39785 (1%)]\tLoss: 15.349367\n",
      "Train Epoch: 4 [23000/39785 (1%)]\tLoss: 15.177896\n",
      "Train Epoch: 4 [24000/39785 (1%)]\tLoss: 13.161343\n",
      "Train Epoch: 4 [25000/39785 (1%)]\tLoss: 17.234045\n",
      "Train Epoch: 4 [26000/39785 (1%)]\tLoss: 16.249908\n",
      "Train Epoch: 4 [27000/39785 (1%)]\tLoss: 15.129722\n",
      "Train Epoch: 4 [28000/39785 (1%)]\tLoss: 15.388290\n",
      "Train Epoch: 4 [29000/39785 (1%)]\tLoss: 17.836746\n",
      "Train Epoch: 4 [30000/39785 (1%)]\tLoss: 16.091156\n",
      "Train Epoch: 4 [31000/39785 (1%)]\tLoss: 17.155502\n",
      "Train Epoch: 4 [32000/39785 (1%)]\tLoss: 14.051780\n",
      "Train Epoch: 4 [33000/39785 (1%)]\tLoss: 13.098690\n",
      "Train Epoch: 4 [34000/39785 (1%)]\tLoss: 14.555031\n",
      "Train Epoch: 4 [35000/39785 (1%)]\tLoss: 18.553556\n",
      "Train Epoch: 4 [36000/39785 (1%)]\tLoss: 15.209823\n",
      "Train Epoch: 4 [37000/39785 (1%)]\tLoss: 14.518982\n",
      "Train Epoch: 4 [38000/39785 (1%)]\tLoss: 12.988264\n",
      "Train Epoch: 4 [39000/39785 (1%)]\tLoss: 16.414457\n",
      "Train Epoch: 5 [1000/39785 (0%)]\tLoss: 12.203529\n",
      "Train Epoch: 5 [2000/39785 (0%)]\tLoss: 11.663002\n",
      "Train Epoch: 5 [3000/39785 (0%)]\tLoss: 14.281474\n",
      "Train Epoch: 5 [4000/39785 (0%)]\tLoss: 12.516015\n",
      "Train Epoch: 5 [5000/39785 (0%)]\tLoss: 12.721657\n",
      "Train Epoch: 5 [6000/39785 (0%)]\tLoss: 13.222950\n",
      "Train Epoch: 5 [7000/39785 (0%)]\tLoss: 16.201130\n",
      "Train Epoch: 5 [8000/39785 (0%)]\tLoss: 11.384894\n",
      "Train Epoch: 5 [9000/39785 (0%)]\tLoss: 14.788321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [10000/39785 (0%)]\tLoss: 12.622517\n",
      "Train Epoch: 5 [11000/39785 (0%)]\tLoss: 14.746858\n",
      "Train Epoch: 5 [12000/39785 (0%)]\tLoss: 10.616294\n",
      "Train Epoch: 5 [13000/39785 (0%)]\tLoss: 17.223125\n",
      "Train Epoch: 5 [14000/39785 (0%)]\tLoss: 15.697552\n",
      "Train Epoch: 5 [15000/39785 (0%)]\tLoss: 12.174756\n",
      "Train Epoch: 5 [16000/39785 (0%)]\tLoss: 14.795235\n",
      "Train Epoch: 5 [17000/39785 (0%)]\tLoss: 17.448853\n",
      "Train Epoch: 5 [18000/39785 (0%)]\tLoss: 15.579608\n",
      "Train Epoch: 5 [19000/39785 (0%)]\tLoss: 14.769566\n",
      "Train Epoch: 5 [20000/39785 (1%)]\tLoss: 11.806815\n",
      "Train Epoch: 5 [21000/39785 (1%)]\tLoss: 12.723416\n",
      "Train Epoch: 5 [22000/39785 (1%)]\tLoss: 13.099526\n",
      "Train Epoch: 5 [23000/39785 (1%)]\tLoss: 14.445068\n",
      "Train Epoch: 5 [24000/39785 (1%)]\tLoss: 13.790761\n",
      "Train Epoch: 5 [25000/39785 (1%)]\tLoss: 14.738664\n",
      "Train Epoch: 5 [26000/39785 (1%)]\tLoss: 14.207312\n",
      "Train Epoch: 5 [27000/39785 (1%)]\tLoss: 13.244943\n",
      "Train Epoch: 5 [28000/39785 (1%)]\tLoss: 15.262305\n",
      "Train Epoch: 5 [29000/39785 (1%)]\tLoss: 15.167724\n",
      "Train Epoch: 5 [30000/39785 (1%)]\tLoss: 14.598586\n",
      "Train Epoch: 5 [31000/39785 (1%)]\tLoss: 12.244933\n",
      "Train Epoch: 5 [32000/39785 (1%)]\tLoss: 17.212420\n",
      "Train Epoch: 5 [33000/39785 (1%)]\tLoss: 16.626919\n",
      "Train Epoch: 5 [34000/39785 (1%)]\tLoss: 14.458749\n",
      "Train Epoch: 5 [35000/39785 (1%)]\tLoss: 13.851945\n",
      "Train Epoch: 5 [36000/39785 (1%)]\tLoss: 14.051882\n",
      "Train Epoch: 5 [37000/39785 (1%)]\tLoss: 16.920105\n",
      "Train Epoch: 5 [38000/39785 (1%)]\tLoss: 19.560202\n",
      "Train Epoch: 5 [39000/39785 (1%)]\tLoss: 12.446718\n",
      "Train Epoch: 6 [1000/39785 (0%)]\tLoss: 15.835559\n",
      "Train Epoch: 6 [2000/39785 (0%)]\tLoss: 15.353899\n",
      "Train Epoch: 6 [3000/39785 (0%)]\tLoss: 12.841435\n",
      "Train Epoch: 6 [4000/39785 (0%)]\tLoss: 11.001176\n",
      "Train Epoch: 6 [5000/39785 (0%)]\tLoss: 15.593334\n",
      "Train Epoch: 6 [6000/39785 (0%)]\tLoss: 15.231699\n",
      "Train Epoch: 6 [7000/39785 (0%)]\tLoss: 12.935976\n",
      "Train Epoch: 6 [8000/39785 (0%)]\tLoss: 16.720615\n",
      "Train Epoch: 6 [9000/39785 (0%)]\tLoss: 9.718110\n",
      "Train Epoch: 6 [10000/39785 (0%)]\tLoss: 16.847273\n",
      "Train Epoch: 6 [11000/39785 (0%)]\tLoss: 15.268799\n",
      "Train Epoch: 6 [12000/39785 (0%)]\tLoss: 13.306770\n",
      "Train Epoch: 6 [13000/39785 (0%)]\tLoss: 18.011257\n",
      "Train Epoch: 6 [14000/39785 (0%)]\tLoss: 14.367399\n",
      "Train Epoch: 6 [15000/39785 (0%)]\tLoss: 12.510711\n",
      "Train Epoch: 6 [16000/39785 (0%)]\tLoss: 10.119536\n",
      "Train Epoch: 6 [17000/39785 (0%)]\tLoss: 14.026826\n",
      "Train Epoch: 6 [18000/39785 (0%)]\tLoss: 14.540644\n",
      "Train Epoch: 6 [19000/39785 (0%)]\tLoss: 12.304935\n",
      "Train Epoch: 6 [20000/39785 (1%)]\tLoss: 10.989320\n",
      "Train Epoch: 6 [21000/39785 (1%)]\tLoss: 16.665066\n",
      "Train Epoch: 6 [22000/39785 (1%)]\tLoss: 13.616570\n",
      "Train Epoch: 6 [23000/39785 (1%)]\tLoss: 13.353625\n",
      "Train Epoch: 6 [24000/39785 (1%)]\tLoss: 15.432121\n",
      "Train Epoch: 6 [25000/39785 (1%)]\tLoss: 17.229481\n",
      "Train Epoch: 6 [26000/39785 (1%)]\tLoss: 19.295189\n",
      "Train Epoch: 6 [27000/39785 (1%)]\tLoss: 12.681051\n",
      "Train Epoch: 6 [28000/39785 (1%)]\tLoss: 14.071852\n",
      "Train Epoch: 6 [29000/39785 (1%)]\tLoss: 16.705770\n",
      "Train Epoch: 6 [30000/39785 (1%)]\tLoss: 13.005205\n",
      "Train Epoch: 6 [31000/39785 (1%)]\tLoss: 18.331121\n",
      "Train Epoch: 6 [32000/39785 (1%)]\tLoss: 12.100721\n",
      "Train Epoch: 6 [33000/39785 (1%)]\tLoss: 14.329897\n",
      "Train Epoch: 6 [34000/39785 (1%)]\tLoss: 16.778618\n",
      "Train Epoch: 6 [35000/39785 (1%)]\tLoss: 9.461662\n",
      "Train Epoch: 6 [36000/39785 (1%)]\tLoss: 11.335801\n",
      "Train Epoch: 6 [37000/39785 (1%)]\tLoss: 13.621498\n",
      "Train Epoch: 6 [38000/39785 (1%)]\tLoss: 15.156757\n",
      "Train Epoch: 6 [39000/39785 (1%)]\tLoss: 15.179867\n",
      "Train Epoch: 7 [1000/39785 (0%)]\tLoss: 12.655602\n",
      "Train Epoch: 7 [2000/39785 (0%)]\tLoss: 16.776655\n",
      "Train Epoch: 7 [3000/39785 (0%)]\tLoss: 12.622066\n",
      "Train Epoch: 7 [4000/39785 (0%)]\tLoss: 14.756187\n",
      "Train Epoch: 7 [5000/39785 (0%)]\tLoss: 14.271869\n",
      "Train Epoch: 7 [6000/39785 (0%)]\tLoss: 17.264362\n",
      "Train Epoch: 7 [7000/39785 (0%)]\tLoss: 13.266056\n",
      "Train Epoch: 7 [8000/39785 (0%)]\tLoss: 12.190612\n",
      "Train Epoch: 7 [9000/39785 (0%)]\tLoss: 15.477742\n",
      "Train Epoch: 7 [10000/39785 (0%)]\tLoss: 18.413822\n",
      "Train Epoch: 7 [11000/39785 (0%)]\tLoss: 14.466212\n",
      "Train Epoch: 7 [12000/39785 (0%)]\tLoss: 18.210445\n",
      "Train Epoch: 7 [13000/39785 (0%)]\tLoss: 18.651680\n",
      "Train Epoch: 7 [14000/39785 (0%)]\tLoss: 13.964024\n",
      "Train Epoch: 7 [15000/39785 (0%)]\tLoss: 13.537242\n",
      "Train Epoch: 7 [16000/39785 (0%)]\tLoss: 15.524117\n",
      "Train Epoch: 7 [17000/39785 (0%)]\tLoss: 13.903307\n",
      "Train Epoch: 7 [18000/39785 (0%)]\tLoss: 16.622229\n",
      "Train Epoch: 7 [19000/39785 (0%)]\tLoss: 17.456589\n",
      "Train Epoch: 7 [20000/39785 (1%)]\tLoss: 11.783066\n",
      "Train Epoch: 7 [21000/39785 (1%)]\tLoss: 18.295742\n",
      "Train Epoch: 7 [22000/39785 (1%)]\tLoss: 12.652191\n",
      "Train Epoch: 7 [23000/39785 (1%)]\tLoss: 12.469884\n",
      "Train Epoch: 7 [24000/39785 (1%)]\tLoss: 12.814722\n",
      "Train Epoch: 7 [25000/39785 (1%)]\tLoss: 16.030443\n",
      "Train Epoch: 7 [26000/39785 (1%)]\tLoss: 15.026452\n",
      "Train Epoch: 7 [27000/39785 (1%)]\tLoss: 12.450592\n",
      "Train Epoch: 7 [28000/39785 (1%)]\tLoss: 14.309042\n",
      "Train Epoch: 7 [29000/39785 (1%)]\tLoss: 12.273232\n",
      "Train Epoch: 7 [30000/39785 (1%)]\tLoss: 14.190998\n",
      "Train Epoch: 7 [31000/39785 (1%)]\tLoss: 15.341270\n",
      "Train Epoch: 7 [32000/39785 (1%)]\tLoss: 15.919843\n",
      "Train Epoch: 7 [33000/39785 (1%)]\tLoss: 13.897202\n",
      "Train Epoch: 7 [34000/39785 (1%)]\tLoss: 11.973472\n",
      "Train Epoch: 7 [35000/39785 (1%)]\tLoss: 14.923554\n",
      "Train Epoch: 7 [36000/39785 (1%)]\tLoss: 16.158224\n",
      "Train Epoch: 7 [37000/39785 (1%)]\tLoss: 14.697132\n",
      "Train Epoch: 7 [38000/39785 (1%)]\tLoss: 13.444776\n",
      "Train Epoch: 7 [39000/39785 (1%)]\tLoss: 13.185665\n",
      "Train Epoch: 8 [1000/39785 (0%)]\tLoss: 12.361449\n",
      "Train Epoch: 8 [2000/39785 (0%)]\tLoss: 17.601721\n",
      "Train Epoch: 8 [3000/39785 (0%)]\tLoss: 16.615788\n",
      "Train Epoch: 8 [4000/39785 (0%)]\tLoss: 13.589708\n",
      "Train Epoch: 8 [5000/39785 (0%)]\tLoss: 12.086192\n",
      "Train Epoch: 8 [6000/39785 (0%)]\tLoss: 13.941935\n",
      "Train Epoch: 8 [7000/39785 (0%)]\tLoss: 16.118095\n",
      "Train Epoch: 8 [8000/39785 (0%)]\tLoss: 15.253626\n",
      "Train Epoch: 8 [9000/39785 (0%)]\tLoss: 11.797248\n",
      "Train Epoch: 8 [10000/39785 (0%)]\tLoss: 12.884396\n",
      "Train Epoch: 8 [11000/39785 (0%)]\tLoss: 14.396442\n",
      "Train Epoch: 8 [12000/39785 (0%)]\tLoss: 15.992992\n",
      "Train Epoch: 8 [13000/39785 (0%)]\tLoss: 13.273999\n",
      "Train Epoch: 8 [14000/39785 (0%)]\tLoss: 12.939930\n",
      "Train Epoch: 8 [15000/39785 (0%)]\tLoss: 13.435564\n",
      "Train Epoch: 8 [16000/39785 (0%)]\tLoss: 16.792706\n",
      "Train Epoch: 8 [17000/39785 (0%)]\tLoss: 13.010406\n",
      "Train Epoch: 8 [18000/39785 (0%)]\tLoss: 15.854604\n",
      "Train Epoch: 8 [19000/39785 (0%)]\tLoss: 12.259108\n",
      "Train Epoch: 8 [20000/39785 (1%)]\tLoss: 13.714024\n",
      "Train Epoch: 8 [21000/39785 (1%)]\tLoss: 15.593569\n",
      "Train Epoch: 8 [22000/39785 (1%)]\tLoss: 15.016075\n",
      "Train Epoch: 8 [23000/39785 (1%)]\tLoss: 15.305475\n",
      "Train Epoch: 8 [24000/39785 (1%)]\tLoss: 14.399623\n",
      "Train Epoch: 8 [25000/39785 (1%)]\tLoss: 15.147871\n",
      "Train Epoch: 8 [26000/39785 (1%)]\tLoss: 14.347964\n",
      "Train Epoch: 8 [27000/39785 (1%)]\tLoss: 16.000984\n",
      "Train Epoch: 8 [28000/39785 (1%)]\tLoss: 14.535807\n",
      "Train Epoch: 8 [29000/39785 (1%)]\tLoss: 13.570965\n",
      "Train Epoch: 8 [30000/39785 (1%)]\tLoss: 13.949508\n",
      "Train Epoch: 8 [31000/39785 (1%)]\tLoss: 13.436601\n",
      "Train Epoch: 8 [32000/39785 (1%)]\tLoss: 13.732843\n",
      "Train Epoch: 8 [33000/39785 (1%)]\tLoss: 17.909767\n",
      "Train Epoch: 8 [34000/39785 (1%)]\tLoss: 12.096725\n",
      "Train Epoch: 8 [35000/39785 (1%)]\tLoss: 10.764375\n",
      "Train Epoch: 8 [36000/39785 (1%)]\tLoss: 13.812962\n",
      "Train Epoch: 8 [37000/39785 (1%)]\tLoss: 14.200357\n",
      "Train Epoch: 8 [38000/39785 (1%)]\tLoss: 15.488766\n",
      "Train Epoch: 8 [39000/39785 (1%)]\tLoss: 12.546168\n",
      "Train Epoch: 9 [1000/39785 (0%)]\tLoss: 13.041523\n",
      "Train Epoch: 9 [2000/39785 (0%)]\tLoss: 15.376580\n",
      "Train Epoch: 9 [3000/39785 (0%)]\tLoss: 18.843422\n",
      "Train Epoch: 9 [4000/39785 (0%)]\tLoss: 14.174841\n",
      "Train Epoch: 9 [5000/39785 (0%)]\tLoss: 15.388170\n",
      "Train Epoch: 9 [6000/39785 (0%)]\tLoss: 12.922604\n",
      "Train Epoch: 9 [7000/39785 (0%)]\tLoss: 19.715549\n",
      "Train Epoch: 9 [8000/39785 (0%)]\tLoss: 16.124306\n",
      "Train Epoch: 9 [9000/39785 (0%)]\tLoss: 16.194433\n",
      "Train Epoch: 9 [10000/39785 (0%)]\tLoss: 15.873548\n",
      "Train Epoch: 9 [11000/39785 (0%)]\tLoss: 10.334439\n",
      "Train Epoch: 9 [12000/39785 (0%)]\tLoss: 10.360147\n",
      "Train Epoch: 9 [13000/39785 (0%)]\tLoss: 12.642071\n",
      "Train Epoch: 9 [14000/39785 (0%)]\tLoss: 15.519398\n",
      "Train Epoch: 9 [15000/39785 (0%)]\tLoss: 15.321121\n",
      "Train Epoch: 9 [16000/39785 (0%)]\tLoss: 12.975093\n",
      "Train Epoch: 9 [17000/39785 (0%)]\tLoss: 13.343981\n",
      "Train Epoch: 9 [18000/39785 (0%)]\tLoss: 14.151637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [19000/39785 (0%)]\tLoss: 18.231171\n",
      "Train Epoch: 9 [20000/39785 (1%)]\tLoss: 14.949144\n",
      "Train Epoch: 9 [21000/39785 (1%)]\tLoss: 12.592390\n",
      "Train Epoch: 9 [22000/39785 (1%)]\tLoss: 12.259623\n",
      "Train Epoch: 9 [23000/39785 (1%)]\tLoss: 14.120815\n",
      "Train Epoch: 9 [24000/39785 (1%)]\tLoss: 15.186064\n",
      "Train Epoch: 9 [25000/39785 (1%)]\tLoss: 16.055338\n",
      "Train Epoch: 9 [26000/39785 (1%)]\tLoss: 16.827185\n",
      "Train Epoch: 9 [27000/39785 (1%)]\tLoss: 13.573219\n",
      "Train Epoch: 9 [28000/39785 (1%)]\tLoss: 16.488340\n",
      "Train Epoch: 9 [29000/39785 (1%)]\tLoss: 15.778923\n",
      "Train Epoch: 9 [30000/39785 (1%)]\tLoss: 13.095004\n",
      "Train Epoch: 9 [31000/39785 (1%)]\tLoss: 15.102017\n",
      "Train Epoch: 9 [32000/39785 (1%)]\tLoss: 10.513493\n",
      "Train Epoch: 9 [33000/39785 (1%)]\tLoss: 14.453828\n",
      "Train Epoch: 9 [34000/39785 (1%)]\tLoss: 14.549540\n",
      "Train Epoch: 9 [35000/39785 (1%)]\tLoss: 10.506563\n",
      "Train Epoch: 9 [36000/39785 (1%)]\tLoss: 14.719914\n",
      "Train Epoch: 9 [37000/39785 (1%)]\tLoss: 14.500222\n",
      "Train Epoch: 9 [38000/39785 (1%)]\tLoss: 17.233698\n",
      "Train Epoch: 9 [39000/39785 (1%)]\tLoss: 14.392132\n",
      "Train Epoch: 10 [1000/39785 (0%)]\tLoss: 16.260294\n",
      "Train Epoch: 10 [2000/39785 (0%)]\tLoss: 15.730937\n",
      "Train Epoch: 10 [3000/39785 (0%)]\tLoss: 14.244031\n",
      "Train Epoch: 10 [4000/39785 (0%)]\tLoss: 12.104609\n",
      "Train Epoch: 10 [5000/39785 (0%)]\tLoss: 12.104283\n",
      "Train Epoch: 10 [6000/39785 (0%)]\tLoss: 14.671097\n",
      "Train Epoch: 10 [7000/39785 (0%)]\tLoss: 14.901624\n",
      "Train Epoch: 10 [8000/39785 (0%)]\tLoss: 12.469190\n",
      "Train Epoch: 10 [9000/39785 (0%)]\tLoss: 13.052786\n",
      "Train Epoch: 10 [10000/39785 (0%)]\tLoss: 14.841044\n",
      "Train Epoch: 10 [11000/39785 (0%)]\tLoss: 15.610231\n",
      "Train Epoch: 10 [12000/39785 (0%)]\tLoss: 15.096153\n",
      "Train Epoch: 10 [13000/39785 (0%)]\tLoss: 15.921475\n",
      "Train Epoch: 10 [14000/39785 (0%)]\tLoss: 11.372703\n",
      "Train Epoch: 10 [15000/39785 (0%)]\tLoss: 11.841337\n",
      "Train Epoch: 10 [16000/39785 (0%)]\tLoss: 17.525928\n",
      "Train Epoch: 10 [17000/39785 (0%)]\tLoss: 16.417643\n",
      "Train Epoch: 10 [18000/39785 (0%)]\tLoss: 14.827677\n",
      "Train Epoch: 10 [19000/39785 (0%)]\tLoss: 11.027825\n",
      "Train Epoch: 10 [20000/39785 (1%)]\tLoss: 14.598247\n",
      "Train Epoch: 10 [21000/39785 (1%)]\tLoss: 12.042222\n",
      "Train Epoch: 10 [22000/39785 (1%)]\tLoss: 13.878569\n",
      "Train Epoch: 10 [23000/39785 (1%)]\tLoss: 9.187972\n",
      "Train Epoch: 10 [24000/39785 (1%)]\tLoss: 13.825470\n",
      "Train Epoch: 10 [25000/39785 (1%)]\tLoss: 15.257442\n",
      "Train Epoch: 10 [26000/39785 (1%)]\tLoss: 12.335738\n",
      "Train Epoch: 10 [27000/39785 (1%)]\tLoss: 10.035468\n",
      "Train Epoch: 10 [28000/39785 (1%)]\tLoss: 15.960896\n",
      "Train Epoch: 10 [29000/39785 (1%)]\tLoss: 15.986391\n",
      "Train Epoch: 10 [30000/39785 (1%)]\tLoss: 12.711502\n",
      "Train Epoch: 10 [31000/39785 (1%)]\tLoss: 10.546138\n",
      "Train Epoch: 10 [32000/39785 (1%)]\tLoss: 9.283975\n",
      "Train Epoch: 10 [33000/39785 (1%)]\tLoss: 12.660578\n",
      "Train Epoch: 10 [34000/39785 (1%)]\tLoss: 13.857285\n",
      "Train Epoch: 10 [35000/39785 (1%)]\tLoss: 15.613366\n",
      "Train Epoch: 10 [36000/39785 (1%)]\tLoss: 17.393536\n",
      "Train Epoch: 10 [37000/39785 (1%)]\tLoss: 12.601315\n",
      "Train Epoch: 10 [38000/39785 (1%)]\tLoss: 13.754744\n",
      "Train Epoch: 10 [39000/39785 (1%)]\tLoss: 13.974849\n",
      "Train Epoch: 11 [1000/39785 (0%)]\tLoss: 11.165071\n",
      "Train Epoch: 11 [2000/39785 (0%)]\tLoss: 14.095676\n",
      "Train Epoch: 11 [3000/39785 (0%)]\tLoss: 16.593082\n",
      "Train Epoch: 11 [4000/39785 (0%)]\tLoss: 14.651260\n",
      "Train Epoch: 11 [5000/39785 (0%)]\tLoss: 12.171808\n",
      "Train Epoch: 11 [6000/39785 (0%)]\tLoss: 11.493851\n",
      "Train Epoch: 11 [7000/39785 (0%)]\tLoss: 9.685312\n",
      "Train Epoch: 11 [8000/39785 (0%)]\tLoss: 19.539934\n",
      "Train Epoch: 11 [9000/39785 (0%)]\tLoss: 14.906654\n",
      "Train Epoch: 11 [10000/39785 (0%)]\tLoss: 14.313768\n",
      "Train Epoch: 11 [11000/39785 (0%)]\tLoss: 14.234531\n",
      "Train Epoch: 11 [12000/39785 (0%)]\tLoss: 15.690907\n",
      "Train Epoch: 11 [13000/39785 (0%)]\tLoss: 16.301731\n",
      "Train Epoch: 11 [14000/39785 (0%)]\tLoss: 11.140510\n",
      "Train Epoch: 11 [15000/39785 (0%)]\tLoss: 14.140900\n",
      "Train Epoch: 11 [16000/39785 (0%)]\tLoss: 14.173136\n",
      "Train Epoch: 11 [17000/39785 (0%)]\tLoss: 11.455419\n",
      "Train Epoch: 11 [18000/39785 (0%)]\tLoss: 14.313333\n",
      "Train Epoch: 11 [19000/39785 (0%)]\tLoss: 15.019500\n",
      "Train Epoch: 11 [20000/39785 (1%)]\tLoss: 15.592553\n",
      "Train Epoch: 11 [21000/39785 (1%)]\tLoss: 14.758921\n",
      "Train Epoch: 11 [22000/39785 (1%)]\tLoss: 16.911852\n",
      "Train Epoch: 11 [23000/39785 (1%)]\tLoss: 15.053848\n",
      "Train Epoch: 11 [24000/39785 (1%)]\tLoss: 12.409365\n",
      "Train Epoch: 11 [25000/39785 (1%)]\tLoss: 11.014286\n",
      "Train Epoch: 11 [26000/39785 (1%)]\tLoss: 11.051078\n",
      "Train Epoch: 11 [27000/39785 (1%)]\tLoss: 15.257326\n",
      "Train Epoch: 11 [28000/39785 (1%)]\tLoss: 11.859606\n",
      "Train Epoch: 11 [29000/39785 (1%)]\tLoss: 15.431557\n",
      "Train Epoch: 11 [30000/39785 (1%)]\tLoss: 16.825169\n",
      "Train Epoch: 11 [31000/39785 (1%)]\tLoss: 13.729938\n",
      "Train Epoch: 11 [32000/39785 (1%)]\tLoss: 17.481682\n",
      "Train Epoch: 11 [33000/39785 (1%)]\tLoss: 13.079377\n",
      "Train Epoch: 11 [34000/39785 (1%)]\tLoss: 12.384336\n",
      "Train Epoch: 11 [35000/39785 (1%)]\tLoss: 15.189636\n",
      "Train Epoch: 11 [36000/39785 (1%)]\tLoss: 14.107777\n",
      "Train Epoch: 11 [37000/39785 (1%)]\tLoss: 11.067270\n",
      "Train Epoch: 11 [38000/39785 (1%)]\tLoss: 10.908035\n",
      "Train Epoch: 11 [39000/39785 (1%)]\tLoss: 15.827671\n",
      "Train Epoch: 12 [1000/39785 (0%)]\tLoss: 15.498766\n",
      "Train Epoch: 12 [2000/39785 (0%)]\tLoss: 13.334682\n",
      "Train Epoch: 12 [3000/39785 (0%)]\tLoss: 12.498572\n",
      "Train Epoch: 12 [4000/39785 (0%)]\tLoss: 18.275654\n",
      "Train Epoch: 12 [5000/39785 (0%)]\tLoss: 16.305925\n",
      "Train Epoch: 12 [6000/39785 (0%)]\tLoss: 12.241607\n",
      "Train Epoch: 12 [7000/39785 (0%)]\tLoss: 16.504307\n",
      "Train Epoch: 12 [8000/39785 (0%)]\tLoss: 12.060072\n",
      "Train Epoch: 12 [9000/39785 (0%)]\tLoss: 11.409802\n",
      "Train Epoch: 12 [10000/39785 (0%)]\tLoss: 18.747850\n",
      "Train Epoch: 12 [11000/39785 (0%)]\tLoss: 12.871771\n",
      "Train Epoch: 12 [12000/39785 (0%)]\tLoss: 11.207544\n",
      "Train Epoch: 12 [13000/39785 (0%)]\tLoss: 12.991502\n",
      "Train Epoch: 12 [14000/39785 (0%)]\tLoss: 11.260860\n",
      "Train Epoch: 12 [15000/39785 (0%)]\tLoss: 16.292183\n",
      "Train Epoch: 12 [16000/39785 (0%)]\tLoss: 9.743952\n",
      "Train Epoch: 12 [17000/39785 (0%)]\tLoss: 12.444361\n",
      "Train Epoch: 12 [18000/39785 (0%)]\tLoss: 15.320498\n",
      "Train Epoch: 12 [19000/39785 (0%)]\tLoss: 15.062119\n",
      "Train Epoch: 12 [20000/39785 (1%)]\tLoss: 14.884838\n",
      "Train Epoch: 12 [21000/39785 (1%)]\tLoss: 13.913725\n",
      "Train Epoch: 12 [22000/39785 (1%)]\tLoss: 17.275723\n",
      "Train Epoch: 12 [23000/39785 (1%)]\tLoss: 12.364784\n",
      "Train Epoch: 12 [24000/39785 (1%)]\tLoss: 14.158688\n",
      "Train Epoch: 12 [25000/39785 (1%)]\tLoss: 12.657735\n",
      "Train Epoch: 12 [26000/39785 (1%)]\tLoss: 12.146708\n",
      "Train Epoch: 12 [27000/39785 (1%)]\tLoss: 12.050462\n",
      "Train Epoch: 12 [28000/39785 (1%)]\tLoss: 14.198854\n",
      "Train Epoch: 12 [29000/39785 (1%)]\tLoss: 11.895554\n",
      "Train Epoch: 12 [30000/39785 (1%)]\tLoss: 12.958696\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-3911606d3a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_custom_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecr_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# test(model_hard, device, test_set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-226-dd355c061d9f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;31m# loss_fn = nn.MSELoss(reduction='sum')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# loss = loss_fn(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-226-dd355c061d9f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# x = self.gated(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tf.reshape(x,[batchSize,-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/se3cnn-0.0.0-py3.7.egg/se3cnn/convolution.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(1)\n",
    "\n",
    "model_custom_loss = EquiNet().to(device)\n",
    "learning_rate = 5e-3\n",
    "optimizer = torch.optim.Adam(model_custom_loss.parameters(), lr=learning_rate)\n",
    "\n",
    "per_epoch = 50\n",
    "decr_rate = 0.99\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model_custom_loss, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate)\n",
    "    # test(model_hard, device, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_test = model_custom_loss(torch.from_numpy(test_set._images[:100].reshape(batch_size,1,24,24,24)).type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) [0.9126054644584656, 0.13815365731716156, 0.0009435713291168213, -0.14054299890995026, -0.22608059644699097, 0.6172221302986145]\n",
      "[ 7.          0.8140826   0.16944312  0.01647427 -0.07471883 -0.16377677\n",
      "  0.5252441 ]\n",
      "\n",
      "tensor(8) [0.045435696840286255, 0.9039760828018188, 0.22042083740234375, -0.5384350419044495, -0.03082834556698799, -0.058054883033037186]\n",
      "[ 7.          0.01401387  0.8029993   0.18298681 -0.5421038   0.071615\n",
      " -0.15002087]\n",
      "\n",
      "tensor(9) [1.028212308883667, 0.037577927112579346, -0.004926323890686035, -0.13047687709331512, 0.028444167226552963, -0.27478092908859253]\n",
      "[ 7.0000000e+00  9.5146030e-01  4.8440255e-02  9.9439159e-05\n",
      " -3.1038227e-03  1.3755901e-02 -3.0360824e-01]\n",
      "\n",
      "tensor(9) [0.20076383650302887, 0.5157843828201294, 0.2729910612106323, -0.6000676155090332, -0.36886218190193176, 0.5529150366783142]\n",
      "[ 7.          0.23470888  0.4653611   0.29993004 -0.5283479  -0.37522325\n",
      "  0.46738502]\n",
      "\n",
      "tensor(7) [0.5473963022232056, 0.37036943435668945, 0.22840455174446106, -0.46846312284469604, 0.4812694489955902, -0.6159973740577698]\n",
      "[ 7.          0.45699063  0.31786323  0.22514616 -0.37832707  0.4536291\n",
      " -0.53900003]\n",
      "\n",
      "tensor(9) [0.24809294939041138, 0.4316691756248474, 0.38817280530929565, 0.5790322422981262, 0.39495840668678284, 0.5602014064788818]\n",
      "[7.         0.22514616 0.45699063 0.31786323 0.53900003 0.37832707\n",
      " 0.4536291 ]\n",
      "\n",
      "tensor(8) [0.025140583515167236, 0.8463009595870972, 0.18931397795677185, -0.5347450971603394, -0.017409298568964005, -0.053691063076257706]\n",
      "[ 7.          0.01647427  0.8140826   0.16944312 -0.5252441   0.07471883\n",
      " -0.16377677]\n",
      "\n",
      "tensor(8) [0.15868476033210754, -0.015958964824676514, 0.8573634624481201, 0.15039555728435516, 0.5300629138946533, 0.04766144976019859]\n",
      "[7.         0.18298681 0.01401387 0.8029993  0.15002087 0.5421038\n",
      " 0.071615  ]\n",
      "\n",
      "tensor(9) [-0.0380614697933197, 0.9714486598968506, 0.04248666763305664, 0.1767701804637909, -0.09470251202583313, 0.029788214713335037]\n",
      "[7.0000000e+00 9.9439159e-05 9.5146030e-01 4.8440255e-02 3.0360824e-01\n",
      " 3.1038227e-03 1.3755901e-02]\n",
      "\n",
      "tensor(9) [0.2331995964050293, 0.18117672204971313, 0.5717426538467407, -0.4957149624824524, 0.5605486035346985, -0.3063337802886963]\n",
      "[ 7.          0.29993004  0.23470888  0.4653611  -0.46738502  0.5283479\n",
      " -0.37522325]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(torch.argmax(answer_test[i][:NUM_CLASSES]), answer_test[i][NUM_CLASSES:].data.tolist())\n",
    "    print(test_set._labels[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_custom_loss(output, target):\n",
    "    order_out = output[:, 0 : NUM_CLASSES]\n",
    "    order_target = target[:, 0 : 1].type(torch.LongTensor).squeeze_()\n",
    "    axis_out = output[:, NUM_CLASSES : NUM_CLASSES + 6]\n",
    "    axis_target = target[:, 1 : 7]\n",
    "\n",
    "    loss = 1 * nn.CrossEntropyLoss()(order_out, order_target) + nn.MSELoss(reduction='sum')(axis_out, axis_target)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = SE3Convolution(repr_in_1, repr_out_1, size=4)\n",
    "        self.pool1 = nn.AvgPool3d(pool_size, pool_stride)\n",
    "        self.conv2 = SE3Convolution(repr_in_2, repr_out_2, size=4)\n",
    "        self.pool2 = nn.AvgPool3d(pool_size, pool_stride)\n",
    "        \n",
    "        self.lin1 = nn.Linear(n_input_1, n_output_1)\n",
    "        self.drop1 = nn.Dropout(prob)\n",
    "        self.lin2 = nn.Linear(n_output_1, n_output_2)\n",
    "        self.drop2 = nn.Dropout(prob)\n",
    "        self.lin3 = nn.Linear(n_output_2, NUM_CLASSES+6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.gated(x)\n",
    "        x = self.pool1(self.conv1(x))\n",
    "        x = self.pool2(self.conv2(x))\n",
    "        x = x.view(batch_size,-1) # tf.reshape(x,[batchSize,-1])\n",
    "        x = F.leaky_relu(self.lin1(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.leaky_relu(self.lin2(x))\n",
    "        x = self.drop2(x)\n",
    "        return self.lin3(x)\n",
    "    \n",
    "    \n",
    "def train(model, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate):\n",
    "    model.train()\n",
    "    flag = True\n",
    "    new_epoch = True\n",
    "    \n",
    "    if new_epoch:\n",
    "        batch_idx = 1\n",
    "        new_epoch = False\n",
    "        data, target, _ = train_set.next_batch(batch_size)\n",
    "        data = torch.from_numpy(data.reshape(batch_size,1,24,24,24)).type(torch.FloatTensor)\n",
    "        target = torch.from_numpy(target.reshape(batch_size,-1)).type(torch.FloatTensor)\n",
    "        cnt = epoch // per_epoch\n",
    "        if ((epoch+1) // per_epoch > cnt) and flag:\n",
    "            lr = 0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            lr *= decr_rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            flag = False\n",
    "        if ((epoch+1) // per_epoch <= cnt):\n",
    "            flag = True\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss_fn = nn.MSELoss(reduction='sum')\n",
    "        # loss = loss_fn(output, target)\n",
    "        loss = custom_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    while (train_set._index_in_epoch + batch_size) < train_set._num_examples:\n",
    "        batch_idx += 1\n",
    "        data, target, _ = train_set.next_batch(batch_size)\n",
    "        data = torch.from_numpy(data.reshape(batch_size,1,24,24,24)).type(torch.FloatTensor)\n",
    "        target = torch.from_numpy(target.reshape(batch_size,-1)).type(torch.FloatTensor)\n",
    "        cnt = epoch // per_epoch\n",
    "        if ((epoch+1) // per_epoch > cnt) and flag:\n",
    "            lr = 0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            lr *= decr_rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            flag = False\n",
    "        if ((epoch+1) // per_epoch <= cnt):\n",
    "            flag = True\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss_fn = nn.MSELoss(reduction='sum')\n",
    "        # loss = loss_fn(output, target)\n",
    "        loss = weighted_custom_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, train_set._num_examples,\n",
    "                100. * batch_idx / train_set._num_examples, loss.item()))\n",
    "\n",
    "def test(model, device, test_set):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_set:\n",
    "            output = model(data)\n",
    "            loss_fn = nn.MSELoss(reduction='sum')\n",
    "            test_loss += loss_fn(output, target) \n",
    "            # pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += int(torch.argmax(output) == torch.argmax(target))\n",
    "\n",
    "    test_loss /= len(test_set)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_set),\n",
    "        100. * correct / len(test_set)))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_in_1 = [(1,0)]\n",
    "repr_out_1 = [(2,0),(2,1),(2,2),(2,3)]\n",
    "repr_in_2 = [(2,0),(2,1),(2,2),(2,3)]\n",
    "repr_out_2 = [(1,0),(2,1)]\n",
    "size = 4\n",
    "activation = (None, F.leaky_relu)\n",
    "pool_size = 2\n",
    "pool_stride = 2\n",
    "bias = True\n",
    "\n",
    "n_input_1 = 189\n",
    "n_output_1 = 74 \n",
    "n_output_2 = 40\n",
    "\n",
    "batch_size = 100\n",
    "prob = 0.5\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../deepSymmetry/data/fromScripts/dataReady0\n",
      "Extracting ../deepSymmetry/data/fromScripts/dataReady0_label\n",
      "(39785, 13824)\n"
     ]
    }
   ],
   "source": [
    "train_name = '../deepSymmetry/data/fromScripts/dataReady0'\n",
    "train_set = load_data.read_data_set(train_name, dtype=dtypes.float16, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1000/39785 (0%)]\tLoss: 67.335251\n",
      "Train Epoch: 1 [2000/39785 (0%)]\tLoss: 58.905796\n",
      "Train Epoch: 1 [3000/39785 (0%)]\tLoss: 56.228504\n",
      "Train Epoch: 1 [4000/39785 (0%)]\tLoss: 50.652225\n",
      "Train Epoch: 1 [5000/39785 (0%)]\tLoss: 51.507225\n",
      "Train Epoch: 1 [6000/39785 (0%)]\tLoss: 50.058414\n",
      "Train Epoch: 1 [7000/39785 (0%)]\tLoss: 49.381378\n",
      "Train Epoch: 1 [8000/39785 (0%)]\tLoss: 41.233288\n",
      "Train Epoch: 1 [9000/39785 (0%)]\tLoss: 45.783123\n",
      "Train Epoch: 1 [10000/39785 (0%)]\tLoss: 42.588291\n",
      "Train Epoch: 1 [11000/39785 (0%)]\tLoss: 39.424538\n",
      "Train Epoch: 1 [12000/39785 (0%)]\tLoss: 40.566345\n",
      "Train Epoch: 1 [13000/39785 (0%)]\tLoss: 39.995770\n",
      "Train Epoch: 1 [14000/39785 (0%)]\tLoss: 37.852776\n",
      "Train Epoch: 1 [15000/39785 (0%)]\tLoss: 36.517467\n",
      "Train Epoch: 1 [16000/39785 (0%)]\tLoss: 39.119663\n",
      "Train Epoch: 1 [17000/39785 (0%)]\tLoss: 39.379356\n",
      "Train Epoch: 1 [18000/39785 (0%)]\tLoss: 32.916790\n",
      "Train Epoch: 1 [19000/39785 (0%)]\tLoss: 40.311321\n",
      "Train Epoch: 1 [20000/39785 (1%)]\tLoss: 39.725632\n",
      "Train Epoch: 1 [21000/39785 (1%)]\tLoss: 35.650158\n",
      "Train Epoch: 1 [22000/39785 (1%)]\tLoss: 33.399887\n",
      "Train Epoch: 1 [23000/39785 (1%)]\tLoss: 33.066597\n",
      "Train Epoch: 1 [24000/39785 (1%)]\tLoss: 33.083504\n",
      "Train Epoch: 1 [25000/39785 (1%)]\tLoss: 31.410814\n",
      "Train Epoch: 1 [26000/39785 (1%)]\tLoss: 32.341930\n",
      "Train Epoch: 1 [27000/39785 (1%)]\tLoss: 32.503139\n",
      "Train Epoch: 1 [28000/39785 (1%)]\tLoss: 34.190285\n",
      "Train Epoch: 1 [29000/39785 (1%)]\tLoss: 31.990652\n",
      "Train Epoch: 1 [30000/39785 (1%)]\tLoss: 30.598526\n",
      "Train Epoch: 1 [31000/39785 (1%)]\tLoss: 34.921463\n",
      "Train Epoch: 1 [32000/39785 (1%)]\tLoss: 30.646019\n",
      "Train Epoch: 1 [33000/39785 (1%)]\tLoss: 34.011139\n",
      "Train Epoch: 1 [34000/39785 (1%)]\tLoss: 31.387623\n",
      "Train Epoch: 1 [35000/39785 (1%)]\tLoss: 35.367462\n",
      "Train Epoch: 1 [36000/39785 (1%)]\tLoss: 34.464493\n",
      "Train Epoch: 1 [37000/39785 (1%)]\tLoss: 32.839622\n",
      "Train Epoch: 1 [38000/39785 (1%)]\tLoss: 39.277081\n",
      "Train Epoch: 1 [39000/39785 (1%)]\tLoss: 29.834898\n",
      "Train Epoch: 2 [1000/39785 (0%)]\tLoss: 29.495989\n",
      "Train Epoch: 2 [2000/39785 (0%)]\tLoss: 33.003925\n",
      "Train Epoch: 2 [3000/39785 (0%)]\tLoss: 33.889282\n",
      "Train Epoch: 2 [4000/39785 (0%)]\tLoss: 29.631685\n",
      "Train Epoch: 2 [5000/39785 (0%)]\tLoss: 28.217241\n",
      "Train Epoch: 2 [6000/39785 (0%)]\tLoss: 29.130333\n",
      "Train Epoch: 2 [7000/39785 (0%)]\tLoss: 32.937473\n",
      "Train Epoch: 2 [8000/39785 (0%)]\tLoss: 32.885040\n",
      "Train Epoch: 2 [9000/39785 (0%)]\tLoss: 24.347298\n",
      "Train Epoch: 2 [10000/39785 (0%)]\tLoss: 34.640392\n",
      "Train Epoch: 2 [11000/39785 (0%)]\tLoss: 31.334976\n",
      "Train Epoch: 2 [12000/39785 (0%)]\tLoss: 32.296341\n",
      "Train Epoch: 2 [13000/39785 (0%)]\tLoss: 31.781015\n",
      "Train Epoch: 2 [14000/39785 (0%)]\tLoss: 31.612144\n",
      "Train Epoch: 2 [15000/39785 (0%)]\tLoss: 28.682602\n",
      "Train Epoch: 2 [16000/39785 (0%)]\tLoss: 31.116940\n",
      "Train Epoch: 2 [17000/39785 (0%)]\tLoss: 32.825535\n",
      "Train Epoch: 2 [18000/39785 (0%)]\tLoss: 31.253153\n",
      "Train Epoch: 2 [19000/39785 (0%)]\tLoss: 31.668375\n",
      "Train Epoch: 2 [20000/39785 (1%)]\tLoss: 32.106770\n",
      "Train Epoch: 2 [21000/39785 (1%)]\tLoss: 32.144489\n",
      "Train Epoch: 2 [22000/39785 (1%)]\tLoss: 31.598276\n",
      "Train Epoch: 2 [23000/39785 (1%)]\tLoss: 29.874712\n",
      "Train Epoch: 2 [24000/39785 (1%)]\tLoss: 27.147894\n",
      "Train Epoch: 2 [25000/39785 (1%)]\tLoss: 31.479633\n",
      "Train Epoch: 2 [26000/39785 (1%)]\tLoss: 32.636429\n",
      "Train Epoch: 2 [27000/39785 (1%)]\tLoss: 31.675995\n",
      "Train Epoch: 2 [28000/39785 (1%)]\tLoss: 26.822758\n",
      "Train Epoch: 2 [29000/39785 (1%)]\tLoss: 27.479586\n",
      "Train Epoch: 2 [30000/39785 (1%)]\tLoss: 33.331356\n",
      "Train Epoch: 2 [31000/39785 (1%)]\tLoss: 31.549021\n",
      "Train Epoch: 2 [32000/39785 (1%)]\tLoss: 32.438217\n",
      "Train Epoch: 2 [33000/39785 (1%)]\tLoss: 33.113972\n",
      "Train Epoch: 2 [34000/39785 (1%)]\tLoss: 30.115068\n",
      "Train Epoch: 2 [35000/39785 (1%)]\tLoss: 31.118019\n",
      "Train Epoch: 2 [36000/39785 (1%)]\tLoss: 31.323378\n",
      "Train Epoch: 2 [37000/39785 (1%)]\tLoss: 31.747713\n",
      "Train Epoch: 2 [38000/39785 (1%)]\tLoss: 31.569786\n",
      "Train Epoch: 2 [39000/39785 (1%)]\tLoss: 28.538841\n",
      "Train Epoch: 3 [1000/39785 (0%)]\tLoss: 26.940214\n",
      "Train Epoch: 3 [2000/39785 (0%)]\tLoss: 30.807922\n",
      "Train Epoch: 3 [3000/39785 (0%)]\tLoss: 27.790318\n",
      "Train Epoch: 3 [4000/39785 (0%)]\tLoss: 30.184612\n",
      "Train Epoch: 3 [5000/39785 (0%)]\tLoss: 26.104483\n",
      "Train Epoch: 3 [6000/39785 (0%)]\tLoss: 33.853767\n",
      "Train Epoch: 3 [7000/39785 (0%)]\tLoss: 31.092161\n",
      "Train Epoch: 3 [8000/39785 (0%)]\tLoss: 29.389145\n",
      "Train Epoch: 3 [9000/39785 (0%)]\tLoss: 26.921608\n",
      "Train Epoch: 3 [10000/39785 (0%)]\tLoss: 27.737476\n",
      "Train Epoch: 3 [11000/39785 (0%)]\tLoss: 27.460348\n",
      "Train Epoch: 3 [12000/39785 (0%)]\tLoss: 27.619888\n",
      "Train Epoch: 3 [13000/39785 (0%)]\tLoss: 26.095278\n",
      "Train Epoch: 3 [14000/39785 (0%)]\tLoss: 22.588270\n",
      "Train Epoch: 3 [15000/39785 (0%)]\tLoss: 27.324518\n",
      "Train Epoch: 3 [16000/39785 (0%)]\tLoss: 30.913235\n",
      "Train Epoch: 3 [17000/39785 (0%)]\tLoss: 26.839909\n",
      "Train Epoch: 3 [18000/39785 (0%)]\tLoss: 28.612616\n",
      "Train Epoch: 3 [19000/39785 (0%)]\tLoss: 34.472065\n",
      "Train Epoch: 3 [20000/39785 (1%)]\tLoss: 28.010384\n",
      "Train Epoch: 3 [21000/39785 (1%)]\tLoss: 28.926401\n",
      "Train Epoch: 3 [22000/39785 (1%)]\tLoss: 30.281244\n",
      "Train Epoch: 3 [23000/39785 (1%)]\tLoss: 29.053961\n",
      "Train Epoch: 3 [24000/39785 (1%)]\tLoss: 30.793158\n",
      "Train Epoch: 3 [25000/39785 (1%)]\tLoss: 29.097439\n",
      "Train Epoch: 3 [26000/39785 (1%)]\tLoss: 31.937403\n",
      "Train Epoch: 3 [27000/39785 (1%)]\tLoss: 23.761789\n",
      "Train Epoch: 3 [28000/39785 (1%)]\tLoss: 30.178951\n",
      "Train Epoch: 3 [29000/39785 (1%)]\tLoss: 28.269918\n",
      "Train Epoch: 3 [30000/39785 (1%)]\tLoss: 27.465298\n",
      "Train Epoch: 3 [31000/39785 (1%)]\tLoss: 31.340445\n",
      "Train Epoch: 3 [32000/39785 (1%)]\tLoss: 27.314148\n",
      "Train Epoch: 3 [33000/39785 (1%)]\tLoss: 31.210339\n",
      "Train Epoch: 3 [34000/39785 (1%)]\tLoss: 27.742279\n",
      "Train Epoch: 3 [35000/39785 (1%)]\tLoss: 25.066736\n",
      "Train Epoch: 3 [36000/39785 (1%)]\tLoss: 29.097637\n",
      "Train Epoch: 3 [37000/39785 (1%)]\tLoss: 27.412930\n",
      "Train Epoch: 3 [38000/39785 (1%)]\tLoss: 29.868645\n",
      "Train Epoch: 3 [39000/39785 (1%)]\tLoss: 28.683598\n",
      "Train Epoch: 4 [1000/39785 (0%)]\tLoss: 27.765062\n",
      "Train Epoch: 4 [2000/39785 (0%)]\tLoss: 29.400383\n",
      "Train Epoch: 4 [3000/39785 (0%)]\tLoss: 27.916245\n",
      "Train Epoch: 4 [4000/39785 (0%)]\tLoss: 27.339745\n",
      "Train Epoch: 4 [5000/39785 (0%)]\tLoss: 23.433807\n",
      "Train Epoch: 4 [6000/39785 (0%)]\tLoss: 25.681576\n",
      "Train Epoch: 4 [7000/39785 (0%)]\tLoss: 28.647926\n",
      "Train Epoch: 4 [8000/39785 (0%)]\tLoss: 30.013298\n",
      "Train Epoch: 4 [9000/39785 (0%)]\tLoss: 30.018051\n",
      "Train Epoch: 4 [10000/39785 (0%)]\tLoss: 27.094219\n",
      "Train Epoch: 4 [11000/39785 (0%)]\tLoss: 31.021715\n",
      "Train Epoch: 4 [12000/39785 (0%)]\tLoss: 26.498507\n",
      "Train Epoch: 4 [13000/39785 (0%)]\tLoss: 27.741995\n",
      "Train Epoch: 4 [14000/39785 (0%)]\tLoss: 28.678263\n",
      "Train Epoch: 4 [15000/39785 (0%)]\tLoss: 26.250246\n",
      "Train Epoch: 4 [16000/39785 (0%)]\tLoss: 28.044956\n",
      "Train Epoch: 4 [17000/39785 (0%)]\tLoss: 29.376854\n",
      "Train Epoch: 4 [18000/39785 (0%)]\tLoss: 27.797188\n",
      "Train Epoch: 4 [19000/39785 (0%)]\tLoss: 26.150274\n",
      "Train Epoch: 4 [20000/39785 (1%)]\tLoss: 33.173698\n",
      "Train Epoch: 4 [21000/39785 (1%)]\tLoss: 26.514502\n",
      "Train Epoch: 4 [22000/39785 (1%)]\tLoss: 27.691359\n",
      "Train Epoch: 4 [23000/39785 (1%)]\tLoss: 27.640966\n",
      "Train Epoch: 4 [24000/39785 (1%)]\tLoss: 25.459145\n",
      "Train Epoch: 4 [25000/39785 (1%)]\tLoss: 26.285572\n",
      "Train Epoch: 4 [26000/39785 (1%)]\tLoss: 28.705353\n",
      "Train Epoch: 4 [27000/39785 (1%)]\tLoss: 28.840969\n",
      "Train Epoch: 4 [28000/39785 (1%)]\tLoss: 32.277893\n",
      "Train Epoch: 4 [29000/39785 (1%)]\tLoss: 32.097755\n",
      "Train Epoch: 4 [30000/39785 (1%)]\tLoss: 28.481161\n",
      "Train Epoch: 4 [31000/39785 (1%)]\tLoss: 30.324457\n",
      "Train Epoch: 4 [32000/39785 (1%)]\tLoss: 29.151323\n",
      "Train Epoch: 4 [33000/39785 (1%)]\tLoss: 27.888700\n",
      "Train Epoch: 4 [34000/39785 (1%)]\tLoss: 27.405523\n",
      "Train Epoch: 4 [35000/39785 (1%)]\tLoss: 31.346369\n",
      "Train Epoch: 4 [36000/39785 (1%)]\tLoss: 28.483740\n",
      "Train Epoch: 4 [37000/39785 (1%)]\tLoss: 28.052982\n",
      "Train Epoch: 4 [38000/39785 (1%)]\tLoss: 23.344616\n",
      "Train Epoch: 4 [39000/39785 (1%)]\tLoss: 26.569923\n",
      "Train Epoch: 5 [1000/39785 (0%)]\tLoss: 23.750599\n",
      "Train Epoch: 5 [2000/39785 (0%)]\tLoss: 25.025530\n",
      "Train Epoch: 5 [3000/39785 (0%)]\tLoss: 28.538008\n",
      "Train Epoch: 5 [4000/39785 (0%)]\tLoss: 24.331743\n",
      "Train Epoch: 5 [5000/39785 (0%)]\tLoss: 25.112627\n",
      "Train Epoch: 5 [6000/39785 (0%)]\tLoss: 25.912418\n",
      "Train Epoch: 5 [7000/39785 (0%)]\tLoss: 29.950384\n",
      "Train Epoch: 5 [8000/39785 (0%)]\tLoss: 27.771917\n",
      "Train Epoch: 5 [9000/39785 (0%)]\tLoss: 27.640688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [10000/39785 (0%)]\tLoss: 27.056166\n",
      "Train Epoch: 5 [11000/39785 (0%)]\tLoss: 25.496437\n",
      "Train Epoch: 5 [12000/39785 (0%)]\tLoss: 21.688648\n",
      "Train Epoch: 5 [13000/39785 (0%)]\tLoss: 28.641411\n",
      "Train Epoch: 5 [14000/39785 (0%)]\tLoss: 29.990101\n",
      "Train Epoch: 5 [15000/39785 (0%)]\tLoss: 24.634541\n",
      "Train Epoch: 5 [16000/39785 (0%)]\tLoss: 27.037546\n",
      "Train Epoch: 5 [17000/39785 (0%)]\tLoss: 29.249025\n",
      "Train Epoch: 5 [18000/39785 (0%)]\tLoss: 27.435038\n",
      "Train Epoch: 5 [19000/39785 (0%)]\tLoss: 27.575462\n",
      "Train Epoch: 5 [20000/39785 (1%)]\tLoss: 23.076130\n",
      "Train Epoch: 5 [21000/39785 (1%)]\tLoss: 25.909668\n",
      "Train Epoch: 5 [22000/39785 (1%)]\tLoss: 25.048637\n",
      "Train Epoch: 5 [23000/39785 (1%)]\tLoss: 27.880983\n",
      "Train Epoch: 5 [24000/39785 (1%)]\tLoss: 30.983496\n",
      "Train Epoch: 5 [25000/39785 (1%)]\tLoss: 24.562962\n",
      "Train Epoch: 5 [26000/39785 (1%)]\tLoss: 29.923880\n",
      "Train Epoch: 5 [27000/39785 (1%)]\tLoss: 26.116508\n",
      "Train Epoch: 5 [28000/39785 (1%)]\tLoss: 31.898441\n",
      "Train Epoch: 5 [29000/39785 (1%)]\tLoss: 27.364183\n",
      "Train Epoch: 5 [30000/39785 (1%)]\tLoss: 27.410194\n",
      "Train Epoch: 5 [31000/39785 (1%)]\tLoss: 28.071674\n",
      "Train Epoch: 5 [32000/39785 (1%)]\tLoss: 29.696507\n",
      "Train Epoch: 5 [33000/39785 (1%)]\tLoss: 26.870031\n",
      "Train Epoch: 5 [34000/39785 (1%)]\tLoss: 26.857092\n",
      "Train Epoch: 5 [35000/39785 (1%)]\tLoss: 25.696968\n",
      "Train Epoch: 5 [36000/39785 (1%)]\tLoss: 25.381647\n",
      "Train Epoch: 5 [37000/39785 (1%)]\tLoss: 29.394262\n",
      "Train Epoch: 5 [38000/39785 (1%)]\tLoss: 31.301662\n",
      "Train Epoch: 5 [39000/39785 (1%)]\tLoss: 23.061773\n",
      "Train Epoch: 6 [1000/39785 (0%)]\tLoss: 26.358023\n",
      "Train Epoch: 6 [2000/39785 (0%)]\tLoss: 26.033119\n",
      "Train Epoch: 6 [3000/39785 (0%)]\tLoss: 26.422991\n",
      "Train Epoch: 6 [4000/39785 (0%)]\tLoss: 26.267689\n",
      "Train Epoch: 6 [5000/39785 (0%)]\tLoss: 28.671207\n",
      "Train Epoch: 6 [6000/39785 (0%)]\tLoss: 26.648533\n",
      "Train Epoch: 6 [7000/39785 (0%)]\tLoss: 27.507042\n",
      "Train Epoch: 6 [8000/39785 (0%)]\tLoss: 26.875332\n",
      "Train Epoch: 6 [9000/39785 (0%)]\tLoss: 23.586344\n",
      "Train Epoch: 6 [10000/39785 (0%)]\tLoss: 31.109512\n",
      "Train Epoch: 6 [11000/39785 (0%)]\tLoss: 26.907965\n",
      "Train Epoch: 6 [12000/39785 (0%)]\tLoss: 27.957510\n",
      "Train Epoch: 6 [13000/39785 (0%)]\tLoss: 29.742102\n",
      "Train Epoch: 6 [14000/39785 (0%)]\tLoss: 28.905237\n",
      "Train Epoch: 6 [15000/39785 (0%)]\tLoss: 22.670280\n",
      "Train Epoch: 6 [16000/39785 (0%)]\tLoss: 22.907623\n",
      "Train Epoch: 6 [17000/39785 (0%)]\tLoss: 24.294340\n",
      "Train Epoch: 6 [18000/39785 (0%)]\tLoss: 26.005610\n",
      "Train Epoch: 6 [19000/39785 (0%)]\tLoss: 25.947550\n",
      "Train Epoch: 6 [20000/39785 (1%)]\tLoss: 24.482872\n",
      "Train Epoch: 6 [21000/39785 (1%)]\tLoss: 27.691910\n",
      "Train Epoch: 6 [22000/39785 (1%)]\tLoss: 26.360130\n",
      "Train Epoch: 6 [23000/39785 (1%)]\tLoss: 26.128899\n",
      "Train Epoch: 6 [24000/39785 (1%)]\tLoss: 25.649479\n",
      "Train Epoch: 6 [25000/39785 (1%)]\tLoss: 31.262819\n",
      "Train Epoch: 6 [26000/39785 (1%)]\tLoss: 26.211094\n",
      "Train Epoch: 6 [27000/39785 (1%)]\tLoss: 23.156855\n",
      "Train Epoch: 6 [28000/39785 (1%)]\tLoss: 28.947266\n",
      "Train Epoch: 6 [29000/39785 (1%)]\tLoss: 28.948950\n",
      "Train Epoch: 6 [30000/39785 (1%)]\tLoss: 26.122307\n",
      "Train Epoch: 6 [31000/39785 (1%)]\tLoss: 27.931839\n",
      "Train Epoch: 6 [32000/39785 (1%)]\tLoss: 22.573467\n",
      "Train Epoch: 6 [33000/39785 (1%)]\tLoss: 28.388243\n",
      "Train Epoch: 6 [34000/39785 (1%)]\tLoss: 30.695702\n",
      "Train Epoch: 6 [35000/39785 (1%)]\tLoss: 24.615589\n",
      "Train Epoch: 6 [36000/39785 (1%)]\tLoss: 26.036936\n",
      "Train Epoch: 6 [37000/39785 (1%)]\tLoss: 24.510263\n",
      "Train Epoch: 6 [38000/39785 (1%)]\tLoss: 24.464182\n",
      "Train Epoch: 6 [39000/39785 (1%)]\tLoss: 28.008577\n",
      "Train Epoch: 7 [1000/39785 (0%)]\tLoss: 22.496862\n",
      "Train Epoch: 7 [2000/39785 (0%)]\tLoss: 26.136728\n",
      "Train Epoch: 7 [3000/39785 (0%)]\tLoss: 25.171972\n",
      "Train Epoch: 7 [4000/39785 (0%)]\tLoss: 25.281548\n",
      "Train Epoch: 7 [5000/39785 (0%)]\tLoss: 24.768270\n",
      "Train Epoch: 7 [6000/39785 (0%)]\tLoss: 29.757357\n",
      "Train Epoch: 7 [7000/39785 (0%)]\tLoss: 25.599503\n",
      "Train Epoch: 7 [8000/39785 (0%)]\tLoss: 25.833515\n",
      "Train Epoch: 7 [9000/39785 (0%)]\tLoss: 29.038607\n",
      "Train Epoch: 7 [10000/39785 (0%)]\tLoss: 29.524368\n",
      "Train Epoch: 7 [11000/39785 (0%)]\tLoss: 29.283308\n",
      "Train Epoch: 7 [12000/39785 (0%)]\tLoss: 33.022732\n",
      "Train Epoch: 7 [13000/39785 (0%)]\tLoss: 31.498299\n",
      "Train Epoch: 7 [14000/39785 (0%)]\tLoss: 26.301991\n",
      "Train Epoch: 7 [15000/39785 (0%)]\tLoss: 26.807014\n",
      "Train Epoch: 7 [16000/39785 (0%)]\tLoss: 29.399626\n",
      "Train Epoch: 7 [17000/39785 (0%)]\tLoss: 25.083654\n",
      "Train Epoch: 7 [18000/39785 (0%)]\tLoss: 25.171618\n",
      "Train Epoch: 7 [19000/39785 (0%)]\tLoss: 26.727760\n",
      "Train Epoch: 7 [20000/39785 (1%)]\tLoss: 23.469040\n",
      "Train Epoch: 7 [21000/39785 (1%)]\tLoss: 31.267138\n",
      "Train Epoch: 7 [22000/39785 (1%)]\tLoss: 25.206356\n",
      "Train Epoch: 7 [23000/39785 (1%)]\tLoss: 28.173990\n",
      "Train Epoch: 7 [24000/39785 (1%)]\tLoss: 24.681545\n",
      "Train Epoch: 7 [25000/39785 (1%)]\tLoss: 27.378489\n",
      "Train Epoch: 7 [26000/39785 (1%)]\tLoss: 28.604774\n",
      "Train Epoch: 7 [27000/39785 (1%)]\tLoss: 27.857479\n",
      "Train Epoch: 7 [28000/39785 (1%)]\tLoss: 23.831259\n",
      "Train Epoch: 7 [29000/39785 (1%)]\tLoss: 25.029745\n",
      "Train Epoch: 7 [30000/39785 (1%)]\tLoss: 27.251530\n",
      "Train Epoch: 7 [31000/39785 (1%)]\tLoss: 27.305780\n",
      "Train Epoch: 7 [32000/39785 (1%)]\tLoss: 27.138226\n",
      "Train Epoch: 7 [33000/39785 (1%)]\tLoss: 26.385616\n",
      "Train Epoch: 7 [34000/39785 (1%)]\tLoss: 23.574495\n",
      "Train Epoch: 7 [35000/39785 (1%)]\tLoss: 26.303978\n",
      "Train Epoch: 7 [36000/39785 (1%)]\tLoss: 28.928791\n",
      "Train Epoch: 7 [37000/39785 (1%)]\tLoss: 25.889240\n",
      "Train Epoch: 7 [38000/39785 (1%)]\tLoss: 28.411394\n",
      "Train Epoch: 7 [39000/39785 (1%)]\tLoss: 26.708670\n",
      "Train Epoch: 8 [1000/39785 (0%)]\tLoss: 27.043518\n",
      "Train Epoch: 8 [2000/39785 (0%)]\tLoss: 31.347893\n",
      "Train Epoch: 8 [3000/39785 (0%)]\tLoss: 30.995123\n",
      "Train Epoch: 8 [4000/39785 (0%)]\tLoss: 25.433811\n",
      "Train Epoch: 8 [5000/39785 (0%)]\tLoss: 24.988976\n",
      "Train Epoch: 8 [6000/39785 (0%)]\tLoss: 26.468695\n",
      "Train Epoch: 8 [7000/39785 (0%)]\tLoss: 30.852734\n",
      "Train Epoch: 8 [8000/39785 (0%)]\tLoss: 24.521376\n",
      "Train Epoch: 8 [9000/39785 (0%)]\tLoss: 24.777037\n",
      "Train Epoch: 8 [10000/39785 (0%)]\tLoss: 25.731579\n",
      "Train Epoch: 8 [11000/39785 (0%)]\tLoss: 25.386242\n",
      "Train Epoch: 8 [12000/39785 (0%)]\tLoss: 27.077414\n",
      "Train Epoch: 8 [13000/39785 (0%)]\tLoss: 26.057716\n",
      "Train Epoch: 8 [14000/39785 (0%)]\tLoss: 24.455429\n",
      "Train Epoch: 8 [15000/39785 (0%)]\tLoss: 25.052208\n",
      "Train Epoch: 8 [16000/39785 (0%)]\tLoss: 27.331055\n",
      "Train Epoch: 8 [17000/39785 (0%)]\tLoss: 28.244314\n",
      "Train Epoch: 8 [18000/39785 (0%)]\tLoss: 25.997997\n",
      "Train Epoch: 8 [19000/39785 (0%)]\tLoss: 23.704781\n",
      "Train Epoch: 8 [20000/39785 (1%)]\tLoss: 24.356577\n",
      "Train Epoch: 8 [21000/39785 (1%)]\tLoss: 25.674864\n",
      "Train Epoch: 8 [22000/39785 (1%)]\tLoss: 26.188917\n",
      "Train Epoch: 8 [23000/39785 (1%)]\tLoss: 24.893045\n",
      "Train Epoch: 8 [24000/39785 (1%)]\tLoss: 26.921904\n",
      "Train Epoch: 8 [25000/39785 (1%)]\tLoss: 25.362238\n",
      "Train Epoch: 8 [26000/39785 (1%)]\tLoss: 27.589031\n",
      "Train Epoch: 8 [27000/39785 (1%)]\tLoss: 28.354832\n",
      "Train Epoch: 8 [28000/39785 (1%)]\tLoss: 26.141254\n",
      "Train Epoch: 8 [29000/39785 (1%)]\tLoss: 27.117294\n",
      "Train Epoch: 8 [30000/39785 (1%)]\tLoss: 25.972115\n",
      "Train Epoch: 8 [31000/39785 (1%)]\tLoss: 28.391834\n",
      "Train Epoch: 8 [32000/39785 (1%)]\tLoss: 28.372894\n",
      "Train Epoch: 8 [33000/39785 (1%)]\tLoss: 29.706400\n",
      "Train Epoch: 8 [34000/39785 (1%)]\tLoss: 23.548538\n",
      "Train Epoch: 8 [35000/39785 (1%)]\tLoss: 24.328304\n",
      "Train Epoch: 8 [36000/39785 (1%)]\tLoss: 24.599083\n",
      "Train Epoch: 8 [37000/39785 (1%)]\tLoss: 27.460884\n",
      "Train Epoch: 8 [38000/39785 (1%)]\tLoss: 30.524939\n",
      "Train Epoch: 8 [39000/39785 (1%)]\tLoss: 25.180794\n",
      "Train Epoch: 9 [1000/39785 (0%)]\tLoss: 28.187159\n",
      "Train Epoch: 9 [2000/39785 (0%)]\tLoss: 27.607803\n",
      "Train Epoch: 9 [3000/39785 (0%)]\tLoss: 30.481020\n",
      "Train Epoch: 9 [4000/39785 (0%)]\tLoss: 28.433929\n",
      "Train Epoch: 9 [5000/39785 (0%)]\tLoss: 28.114870\n",
      "Train Epoch: 9 [6000/39785 (0%)]\tLoss: 23.611780\n",
      "Train Epoch: 9 [7000/39785 (0%)]\tLoss: 29.623276\n",
      "Train Epoch: 9 [8000/39785 (0%)]\tLoss: 26.512218\n",
      "Train Epoch: 9 [9000/39785 (0%)]\tLoss: 26.442898\n",
      "Train Epoch: 9 [10000/39785 (0%)]\tLoss: 26.951345\n",
      "Train Epoch: 9 [11000/39785 (0%)]\tLoss: 25.165785\n",
      "Train Epoch: 9 [12000/39785 (0%)]\tLoss: 22.700706\n",
      "Train Epoch: 9 [13000/39785 (0%)]\tLoss: 24.553711\n",
      "Train Epoch: 9 [14000/39785 (0%)]\tLoss: 29.943031\n",
      "Train Epoch: 9 [15000/39785 (0%)]\tLoss: 27.099247\n",
      "Train Epoch: 9 [16000/39785 (0%)]\tLoss: 25.869961\n",
      "Train Epoch: 9 [17000/39785 (0%)]\tLoss: 28.088394\n",
      "Train Epoch: 9 [18000/39785 (0%)]\tLoss: 27.418592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [19000/39785 (0%)]\tLoss: 29.666615\n",
      "Train Epoch: 9 [20000/39785 (1%)]\tLoss: 25.991741\n",
      "Train Epoch: 9 [21000/39785 (1%)]\tLoss: 26.139845\n",
      "Train Epoch: 9 [22000/39785 (1%)]\tLoss: 25.967220\n",
      "Train Epoch: 9 [23000/39785 (1%)]\tLoss: 25.522402\n",
      "Train Epoch: 9 [24000/39785 (1%)]\tLoss: 30.264156\n",
      "Train Epoch: 9 [25000/39785 (1%)]\tLoss: 25.929882\n",
      "Train Epoch: 9 [26000/39785 (1%)]\tLoss: 25.565189\n",
      "Train Epoch: 9 [27000/39785 (1%)]\tLoss: 27.156290\n",
      "Train Epoch: 9 [28000/39785 (1%)]\tLoss: 28.622025\n",
      "Train Epoch: 9 [29000/39785 (1%)]\tLoss: 25.866623\n",
      "Train Epoch: 9 [30000/39785 (1%)]\tLoss: 25.579834\n",
      "Train Epoch: 9 [31000/39785 (1%)]\tLoss: 26.742338\n",
      "Train Epoch: 9 [32000/39785 (1%)]\tLoss: 21.939323\n",
      "Train Epoch: 9 [33000/39785 (1%)]\tLoss: 28.412472\n",
      "Train Epoch: 9 [34000/39785 (1%)]\tLoss: 27.044867\n",
      "Train Epoch: 9 [35000/39785 (1%)]\tLoss: 22.056583\n",
      "Train Epoch: 9 [36000/39785 (1%)]\tLoss: 28.542240\n",
      "Train Epoch: 9 [37000/39785 (1%)]\tLoss: 28.105656\n",
      "Train Epoch: 9 [38000/39785 (1%)]\tLoss: 28.666237\n",
      "Train Epoch: 9 [39000/39785 (1%)]\tLoss: 27.379593\n",
      "Train Epoch: 10 [1000/39785 (0%)]\tLoss: 27.676239\n",
      "Train Epoch: 10 [2000/39785 (0%)]\tLoss: 27.871103\n",
      "Train Epoch: 10 [3000/39785 (0%)]\tLoss: 27.065269\n",
      "Train Epoch: 10 [4000/39785 (0%)]\tLoss: 22.567118\n",
      "Train Epoch: 10 [5000/39785 (0%)]\tLoss: 27.227924\n",
      "Train Epoch: 10 [6000/39785 (0%)]\tLoss: 28.173393\n",
      "Train Epoch: 10 [7000/39785 (0%)]\tLoss: 32.313431\n",
      "Train Epoch: 10 [8000/39785 (0%)]\tLoss: 26.063866\n",
      "Train Epoch: 10 [9000/39785 (0%)]\tLoss: 26.455038\n",
      "Train Epoch: 10 [10000/39785 (0%)]\tLoss: 26.278229\n",
      "Train Epoch: 10 [11000/39785 (0%)]\tLoss: 27.716337\n",
      "Train Epoch: 10 [12000/39785 (0%)]\tLoss: 26.850952\n",
      "Train Epoch: 10 [13000/39785 (0%)]\tLoss: 29.643969\n",
      "Train Epoch: 10 [14000/39785 (0%)]\tLoss: 24.658998\n",
      "Train Epoch: 10 [15000/39785 (0%)]\tLoss: 23.471279\n",
      "Train Epoch: 10 [16000/39785 (0%)]\tLoss: 29.758789\n",
      "Train Epoch: 10 [17000/39785 (0%)]\tLoss: 27.935268\n",
      "Train Epoch: 10 [18000/39785 (0%)]\tLoss: 27.275837\n",
      "Train Epoch: 10 [19000/39785 (0%)]\tLoss: 24.697525\n",
      "Train Epoch: 10 [20000/39785 (1%)]\tLoss: 25.716579\n",
      "Train Epoch: 10 [21000/39785 (1%)]\tLoss: 26.177460\n",
      "Train Epoch: 10 [22000/39785 (1%)]\tLoss: 26.713182\n",
      "Train Epoch: 10 [23000/39785 (1%)]\tLoss: 21.136728\n",
      "Train Epoch: 10 [24000/39785 (1%)]\tLoss: 25.170296\n",
      "Train Epoch: 10 [25000/39785 (1%)]\tLoss: 27.567352\n",
      "Train Epoch: 10 [26000/39785 (1%)]\tLoss: 26.411049\n",
      "Train Epoch: 10 [27000/39785 (1%)]\tLoss: 23.066118\n",
      "Train Epoch: 10 [28000/39785 (1%)]\tLoss: 27.360956\n",
      "Train Epoch: 10 [29000/39785 (1%)]\tLoss: 24.816414\n",
      "Train Epoch: 10 [30000/39785 (1%)]\tLoss: 25.818453\n",
      "Train Epoch: 10 [31000/39785 (1%)]\tLoss: 24.973429\n",
      "Train Epoch: 10 [32000/39785 (1%)]\tLoss: 21.207495\n",
      "Train Epoch: 10 [33000/39785 (1%)]\tLoss: 26.280489\n",
      "Train Epoch: 10 [34000/39785 (1%)]\tLoss: 26.594168\n",
      "Train Epoch: 10 [35000/39785 (1%)]\tLoss: 28.716885\n",
      "Train Epoch: 10 [36000/39785 (1%)]\tLoss: 27.131657\n",
      "Train Epoch: 10 [37000/39785 (1%)]\tLoss: 26.589172\n",
      "Train Epoch: 10 [38000/39785 (1%)]\tLoss: 26.515160\n",
      "Train Epoch: 10 [39000/39785 (1%)]\tLoss: 25.168163\n",
      "Train Epoch: 11 [1000/39785 (0%)]\tLoss: 25.053110\n",
      "Train Epoch: 11 [2000/39785 (0%)]\tLoss: 28.353413\n",
      "Train Epoch: 11 [3000/39785 (0%)]\tLoss: 28.575371\n",
      "Train Epoch: 11 [4000/39785 (0%)]\tLoss: 23.911507\n",
      "Train Epoch: 11 [5000/39785 (0%)]\tLoss: 22.570942\n",
      "Train Epoch: 11 [6000/39785 (0%)]\tLoss: 22.757889\n",
      "Train Epoch: 11 [7000/39785 (0%)]\tLoss: 22.051220\n",
      "Train Epoch: 11 [8000/39785 (0%)]\tLoss: 30.885620\n",
      "Train Epoch: 11 [9000/39785 (0%)]\tLoss: 28.467314\n",
      "Train Epoch: 11 [10000/39785 (0%)]\tLoss: 26.187222\n",
      "Train Epoch: 11 [11000/39785 (0%)]\tLoss: 28.389555\n",
      "Train Epoch: 11 [12000/39785 (0%)]\tLoss: 27.919241\n",
      "Train Epoch: 11 [13000/39785 (0%)]\tLoss: 28.714455\n",
      "Train Epoch: 11 [14000/39785 (0%)]\tLoss: 25.261915\n",
      "Train Epoch: 11 [15000/39785 (0%)]\tLoss: 27.264952\n",
      "Train Epoch: 11 [16000/39785 (0%)]\tLoss: 26.277393\n",
      "Train Epoch: 11 [17000/39785 (0%)]\tLoss: 26.499807\n",
      "Train Epoch: 11 [18000/39785 (0%)]\tLoss: 27.629726\n",
      "Train Epoch: 11 [19000/39785 (0%)]\tLoss: 27.689922\n",
      "Train Epoch: 11 [20000/39785 (1%)]\tLoss: 24.101721\n",
      "Train Epoch: 11 [21000/39785 (1%)]\tLoss: 27.297695\n",
      "Train Epoch: 11 [22000/39785 (1%)]\tLoss: 30.864059\n",
      "Train Epoch: 11 [23000/39785 (1%)]\tLoss: 29.928740\n",
      "Train Epoch: 11 [24000/39785 (1%)]\tLoss: 25.268633\n",
      "Train Epoch: 11 [25000/39785 (1%)]\tLoss: 23.583618\n",
      "Train Epoch: 11 [26000/39785 (1%)]\tLoss: 24.042881\n",
      "Train Epoch: 11 [27000/39785 (1%)]\tLoss: 25.254303\n",
      "Train Epoch: 11 [28000/39785 (1%)]\tLoss: 26.342115\n",
      "Train Epoch: 11 [29000/39785 (1%)]\tLoss: 27.548220\n",
      "Train Epoch: 11 [30000/39785 (1%)]\tLoss: 31.457918\n",
      "Train Epoch: 11 [31000/39785 (1%)]\tLoss: 28.138783\n",
      "Train Epoch: 11 [32000/39785 (1%)]\tLoss: 28.276955\n",
      "Train Epoch: 11 [33000/39785 (1%)]\tLoss: 25.556808\n",
      "Train Epoch: 11 [34000/39785 (1%)]\tLoss: 24.682400\n",
      "Train Epoch: 11 [35000/39785 (1%)]\tLoss: 29.363178\n",
      "Train Epoch: 11 [36000/39785 (1%)]\tLoss: 25.732738\n",
      "Train Epoch: 11 [37000/39785 (1%)]\tLoss: 23.590996\n",
      "Train Epoch: 11 [38000/39785 (1%)]\tLoss: 24.093849\n",
      "Train Epoch: 11 [39000/39785 (1%)]\tLoss: 32.479141\n",
      "Train Epoch: 12 [1000/39785 (0%)]\tLoss: 26.559628\n",
      "Train Epoch: 12 [2000/39785 (0%)]\tLoss: 27.968513\n",
      "Train Epoch: 12 [3000/39785 (0%)]\tLoss: 27.367170\n",
      "Train Epoch: 12 [4000/39785 (0%)]\tLoss: 29.781319\n",
      "Train Epoch: 12 [5000/39785 (0%)]\tLoss: 28.928993\n",
      "Train Epoch: 12 [6000/39785 (0%)]\tLoss: 24.118372\n",
      "Train Epoch: 12 [7000/39785 (0%)]\tLoss: 27.513144\n",
      "Train Epoch: 12 [8000/39785 (0%)]\tLoss: 26.468752\n",
      "Train Epoch: 12 [9000/39785 (0%)]\tLoss: 24.430601\n",
      "Train Epoch: 12 [10000/39785 (0%)]\tLoss: 28.013824\n",
      "Train Epoch: 12 [11000/39785 (0%)]\tLoss: 27.483669\n",
      "Train Epoch: 12 [12000/39785 (0%)]\tLoss: 25.548126\n",
      "Train Epoch: 12 [13000/39785 (0%)]\tLoss: 24.646017\n",
      "Train Epoch: 12 [14000/39785 (0%)]\tLoss: 24.278133\n",
      "Train Epoch: 12 [15000/39785 (0%)]\tLoss: 28.410431\n",
      "Train Epoch: 12 [16000/39785 (0%)]\tLoss: 21.572504\n",
      "Train Epoch: 12 [17000/39785 (0%)]\tLoss: 25.865730\n",
      "Train Epoch: 12 [18000/39785 (0%)]\tLoss: 31.107571\n",
      "Train Epoch: 12 [19000/39785 (0%)]\tLoss: 26.512695\n",
      "Train Epoch: 12 [20000/39785 (1%)]\tLoss: 31.944223\n",
      "Train Epoch: 12 [21000/39785 (1%)]\tLoss: 24.336897\n",
      "Train Epoch: 12 [22000/39785 (1%)]\tLoss: 32.136501\n",
      "Train Epoch: 12 [23000/39785 (1%)]\tLoss: 23.690708\n",
      "Train Epoch: 12 [24000/39785 (1%)]\tLoss: 27.650902\n",
      "Train Epoch: 12 [25000/39785 (1%)]\tLoss: 25.276131\n",
      "Train Epoch: 12 [26000/39785 (1%)]\tLoss: 23.802494\n",
      "Train Epoch: 12 [27000/39785 (1%)]\tLoss: 25.743851\n",
      "Train Epoch: 12 [28000/39785 (1%)]\tLoss: 27.350605\n",
      "Train Epoch: 12 [29000/39785 (1%)]\tLoss: 24.657486\n",
      "Train Epoch: 12 [30000/39785 (1%)]\tLoss: 26.361498\n",
      "Train Epoch: 12 [31000/39785 (1%)]\tLoss: 23.923418\n",
      "Train Epoch: 12 [32000/39785 (1%)]\tLoss: 24.415600\n",
      "Train Epoch: 12 [33000/39785 (1%)]\tLoss: 26.048008\n",
      "Train Epoch: 12 [34000/39785 (1%)]\tLoss: 25.063782\n",
      "Train Epoch: 12 [35000/39785 (1%)]\tLoss: 28.156860\n",
      "Train Epoch: 12 [36000/39785 (1%)]\tLoss: 24.454468\n",
      "Train Epoch: 12 [37000/39785 (1%)]\tLoss: 24.925102\n",
      "Train Epoch: 12 [38000/39785 (1%)]\tLoss: 28.501751\n",
      "Train Epoch: 12 [39000/39785 (1%)]\tLoss: 24.196249\n",
      "Train Epoch: 13 [1000/39785 (0%)]\tLoss: 27.379503\n",
      "Train Epoch: 13 [2000/39785 (0%)]\tLoss: 25.652279\n",
      "Train Epoch: 13 [3000/39785 (0%)]\tLoss: 25.784283\n",
      "Train Epoch: 13 [4000/39785 (0%)]\tLoss: 28.764391\n",
      "Train Epoch: 13 [5000/39785 (0%)]\tLoss: 23.617283\n",
      "Train Epoch: 13 [6000/39785 (0%)]\tLoss: 25.486458\n",
      "Train Epoch: 13 [7000/39785 (0%)]\tLoss: 28.113983\n",
      "Train Epoch: 13 [8000/39785 (0%)]\tLoss: 28.417858\n",
      "Train Epoch: 13 [9000/39785 (0%)]\tLoss: 24.858034\n",
      "Train Epoch: 13 [10000/39785 (0%)]\tLoss: 24.599302\n",
      "Train Epoch: 13 [11000/39785 (0%)]\tLoss: 26.854176\n",
      "Train Epoch: 13 [12000/39785 (0%)]\tLoss: 30.157112\n",
      "Train Epoch: 13 [13000/39785 (0%)]\tLoss: 27.542177\n",
      "Train Epoch: 13 [14000/39785 (0%)]\tLoss: 25.083525\n",
      "Train Epoch: 13 [15000/39785 (0%)]\tLoss: 23.995378\n",
      "Train Epoch: 13 [16000/39785 (0%)]\tLoss: 23.684793\n",
      "Train Epoch: 13 [17000/39785 (0%)]\tLoss: 24.928955\n",
      "Train Epoch: 13 [18000/39785 (0%)]\tLoss: 24.221146\n",
      "Train Epoch: 13 [19000/39785 (0%)]\tLoss: 23.551899\n",
      "Train Epoch: 13 [20000/39785 (1%)]\tLoss: 22.732967\n",
      "Train Epoch: 13 [21000/39785 (1%)]\tLoss: 23.435762\n",
      "Train Epoch: 13 [22000/39785 (1%)]\tLoss: 25.210747\n",
      "Train Epoch: 13 [23000/39785 (1%)]\tLoss: 28.184408\n",
      "Train Epoch: 13 [24000/39785 (1%)]\tLoss: 28.194920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [25000/39785 (1%)]\tLoss: 27.450760\n",
      "Train Epoch: 13 [26000/39785 (1%)]\tLoss: 23.736397\n",
      "Train Epoch: 13 [27000/39785 (1%)]\tLoss: 26.725424\n",
      "Train Epoch: 13 [28000/39785 (1%)]\tLoss: 26.009037\n",
      "Train Epoch: 13 [29000/39785 (1%)]\tLoss: 26.271196\n",
      "Train Epoch: 13 [30000/39785 (1%)]\tLoss: 25.008944\n",
      "Train Epoch: 13 [31000/39785 (1%)]\tLoss: 26.122383\n",
      "Train Epoch: 13 [32000/39785 (1%)]\tLoss: 23.952736\n",
      "Train Epoch: 13 [33000/39785 (1%)]\tLoss: 24.518227\n",
      "Train Epoch: 13 [34000/39785 (1%)]\tLoss: 27.931667\n",
      "Train Epoch: 13 [35000/39785 (1%)]\tLoss: 27.663984\n",
      "Train Epoch: 13 [36000/39785 (1%)]\tLoss: 23.597200\n",
      "Train Epoch: 13 [37000/39785 (1%)]\tLoss: 26.991192\n",
      "Train Epoch: 13 [38000/39785 (1%)]\tLoss: 24.231863\n",
      "Train Epoch: 13 [39000/39785 (1%)]\tLoss: 24.855963\n",
      "Train Epoch: 14 [1000/39785 (0%)]\tLoss: 23.244192\n",
      "Train Epoch: 14 [2000/39785 (0%)]\tLoss: 26.827066\n",
      "Train Epoch: 14 [3000/39785 (0%)]\tLoss: 26.714289\n",
      "Train Epoch: 14 [4000/39785 (0%)]\tLoss: 26.742910\n",
      "Train Epoch: 14 [5000/39785 (0%)]\tLoss: 22.837479\n",
      "Train Epoch: 14 [6000/39785 (0%)]\tLoss: 23.750439\n",
      "Train Epoch: 14 [7000/39785 (0%)]\tLoss: 25.880812\n",
      "Train Epoch: 14 [8000/39785 (0%)]\tLoss: 25.356237\n",
      "Train Epoch: 14 [9000/39785 (0%)]\tLoss: 27.680773\n",
      "Train Epoch: 14 [10000/39785 (0%)]\tLoss: 25.112534\n",
      "Train Epoch: 14 [11000/39785 (0%)]\tLoss: 22.476315\n",
      "Train Epoch: 14 [12000/39785 (0%)]\tLoss: 27.649952\n",
      "Train Epoch: 14 [13000/39785 (0%)]\tLoss: 27.721437\n",
      "Train Epoch: 14 [14000/39785 (0%)]\tLoss: 27.125607\n",
      "Train Epoch: 14 [15000/39785 (0%)]\tLoss: 30.159103\n",
      "Train Epoch: 14 [16000/39785 (0%)]\tLoss: 25.260807\n",
      "Train Epoch: 14 [17000/39785 (0%)]\tLoss: 28.236242\n",
      "Train Epoch: 14 [18000/39785 (0%)]\tLoss: 28.197123\n",
      "Train Epoch: 14 [19000/39785 (0%)]\tLoss: 25.512754\n",
      "Train Epoch: 14 [20000/39785 (1%)]\tLoss: 28.169434\n",
      "Train Epoch: 14 [21000/39785 (1%)]\tLoss: 23.594866\n",
      "Train Epoch: 14 [22000/39785 (1%)]\tLoss: 24.551573\n",
      "Train Epoch: 14 [23000/39785 (1%)]\tLoss: 25.949879\n",
      "Train Epoch: 14 [24000/39785 (1%)]\tLoss: 26.636414\n",
      "Train Epoch: 14 [25000/39785 (1%)]\tLoss: 23.078371\n",
      "Train Epoch: 14 [26000/39785 (1%)]\tLoss: 24.292053\n",
      "Train Epoch: 14 [27000/39785 (1%)]\tLoss: 25.982340\n",
      "Train Epoch: 14 [28000/39785 (1%)]\tLoss: 27.959383\n",
      "Train Epoch: 14 [29000/39785 (1%)]\tLoss: 22.170729\n",
      "Train Epoch: 14 [30000/39785 (1%)]\tLoss: 25.644543\n",
      "Train Epoch: 14 [31000/39785 (1%)]\tLoss: 31.257877\n",
      "Train Epoch: 14 [32000/39785 (1%)]\tLoss: 25.980270\n",
      "Train Epoch: 14 [33000/39785 (1%)]\tLoss: 25.740496\n",
      "Train Epoch: 14 [34000/39785 (1%)]\tLoss: 26.742710\n",
      "Train Epoch: 14 [35000/39785 (1%)]\tLoss: 25.036945\n",
      "Train Epoch: 14 [36000/39785 (1%)]\tLoss: 21.159739\n",
      "Train Epoch: 14 [37000/39785 (1%)]\tLoss: 28.989607\n",
      "Train Epoch: 14 [38000/39785 (1%)]\tLoss: 26.921329\n",
      "Train Epoch: 14 [39000/39785 (1%)]\tLoss: 22.445116\n",
      "Train Epoch: 15 [1000/39785 (0%)]\tLoss: 25.088974\n",
      "Train Epoch: 15 [2000/39785 (0%)]\tLoss: 23.710808\n",
      "Train Epoch: 15 [3000/39785 (0%)]\tLoss: 22.905212\n",
      "Train Epoch: 15 [4000/39785 (0%)]\tLoss: 25.032667\n",
      "Train Epoch: 15 [5000/39785 (0%)]\tLoss: 25.567619\n",
      "Train Epoch: 15 [6000/39785 (0%)]\tLoss: 25.651703\n",
      "Train Epoch: 15 [7000/39785 (0%)]\tLoss: 28.103642\n",
      "Train Epoch: 15 [8000/39785 (0%)]\tLoss: 24.213667\n",
      "Train Epoch: 15 [9000/39785 (0%)]\tLoss: 26.473160\n",
      "Train Epoch: 15 [10000/39785 (0%)]\tLoss: 24.933697\n",
      "Train Epoch: 15 [11000/39785 (0%)]\tLoss: 26.535997\n",
      "Train Epoch: 15 [12000/39785 (0%)]\tLoss: 26.178989\n",
      "Train Epoch: 15 [13000/39785 (0%)]\tLoss: 25.227396\n",
      "Train Epoch: 15 [14000/39785 (0%)]\tLoss: 24.401325\n",
      "Train Epoch: 15 [15000/39785 (0%)]\tLoss: 21.724073\n",
      "Train Epoch: 15 [16000/39785 (0%)]\tLoss: 31.965006\n",
      "Train Epoch: 15 [17000/39785 (0%)]\tLoss: 22.038328\n",
      "Train Epoch: 15 [18000/39785 (0%)]\tLoss: 26.871582\n",
      "Train Epoch: 15 [19000/39785 (0%)]\tLoss: 23.201040\n",
      "Train Epoch: 15 [20000/39785 (1%)]\tLoss: 24.665443\n",
      "Train Epoch: 15 [21000/39785 (1%)]\tLoss: 23.785355\n",
      "Train Epoch: 15 [22000/39785 (1%)]\tLoss: 22.818920\n",
      "Train Epoch: 15 [23000/39785 (1%)]\tLoss: 24.460735\n",
      "Train Epoch: 15 [24000/39785 (1%)]\tLoss: 27.717823\n",
      "Train Epoch: 15 [25000/39785 (1%)]\tLoss: 24.462585\n",
      "Train Epoch: 15 [26000/39785 (1%)]\tLoss: 23.524147\n",
      "Train Epoch: 15 [27000/39785 (1%)]\tLoss: 28.172415\n",
      "Train Epoch: 15 [28000/39785 (1%)]\tLoss: 29.693016\n",
      "Train Epoch: 15 [29000/39785 (1%)]\tLoss: 25.252413\n",
      "Train Epoch: 15 [30000/39785 (1%)]\tLoss: 28.211096\n",
      "Train Epoch: 15 [31000/39785 (1%)]\tLoss: 24.337845\n",
      "Train Epoch: 15 [32000/39785 (1%)]\tLoss: 20.654669\n",
      "Train Epoch: 15 [33000/39785 (1%)]\tLoss: 24.396896\n",
      "Train Epoch: 15 [34000/39785 (1%)]\tLoss: 23.183126\n",
      "Train Epoch: 15 [35000/39785 (1%)]\tLoss: 28.180630\n",
      "Train Epoch: 15 [36000/39785 (1%)]\tLoss: 29.057590\n",
      "Train Epoch: 15 [37000/39785 (1%)]\tLoss: 30.308016\n",
      "Train Epoch: 15 [38000/39785 (1%)]\tLoss: 26.980530\n",
      "Train Epoch: 15 [39000/39785 (1%)]\tLoss: 25.297520\n",
      "Train Epoch: 16 [1000/39785 (0%)]\tLoss: 27.125126\n",
      "Train Epoch: 16 [2000/39785 (0%)]\tLoss: 24.549393\n",
      "Train Epoch: 16 [3000/39785 (0%)]\tLoss: 24.052053\n",
      "Train Epoch: 16 [4000/39785 (0%)]\tLoss: 26.161547\n",
      "Train Epoch: 16 [5000/39785 (0%)]\tLoss: 23.483515\n",
      "Train Epoch: 16 [6000/39785 (0%)]\tLoss: 26.184431\n",
      "Train Epoch: 16 [7000/39785 (0%)]\tLoss: 26.148270\n",
      "Train Epoch: 16 [8000/39785 (0%)]\tLoss: 25.991390\n",
      "Train Epoch: 16 [9000/39785 (0%)]\tLoss: 20.274790\n",
      "Train Epoch: 16 [10000/39785 (0%)]\tLoss: 23.351130\n",
      "Train Epoch: 16 [11000/39785 (0%)]\tLoss: 29.183632\n",
      "Train Epoch: 16 [12000/39785 (0%)]\tLoss: 27.099907\n",
      "Train Epoch: 16 [13000/39785 (0%)]\tLoss: 27.208429\n",
      "Train Epoch: 16 [14000/39785 (0%)]\tLoss: 27.068260\n",
      "Train Epoch: 16 [15000/39785 (0%)]\tLoss: 21.699614\n",
      "Train Epoch: 16 [16000/39785 (0%)]\tLoss: 28.854015\n",
      "Train Epoch: 16 [17000/39785 (0%)]\tLoss: 26.524662\n",
      "Train Epoch: 16 [18000/39785 (0%)]\tLoss: 25.145134\n",
      "Train Epoch: 16 [19000/39785 (0%)]\tLoss: 27.162731\n",
      "Train Epoch: 16 [20000/39785 (1%)]\tLoss: 25.415735\n",
      "Train Epoch: 16 [21000/39785 (1%)]\tLoss: 25.481319\n",
      "Train Epoch: 16 [22000/39785 (1%)]\tLoss: 22.172466\n",
      "Train Epoch: 16 [23000/39785 (1%)]\tLoss: 25.415306\n",
      "Train Epoch: 16 [24000/39785 (1%)]\tLoss: 22.766066\n",
      "Train Epoch: 16 [25000/39785 (1%)]\tLoss: 26.270466\n",
      "Train Epoch: 16 [26000/39785 (1%)]\tLoss: 27.940651\n",
      "Train Epoch: 16 [27000/39785 (1%)]\tLoss: 21.514462\n",
      "Train Epoch: 16 [28000/39785 (1%)]\tLoss: 25.045383\n",
      "Train Epoch: 16 [29000/39785 (1%)]\tLoss: 28.179455\n",
      "Train Epoch: 16 [30000/39785 (1%)]\tLoss: 24.137159\n",
      "Train Epoch: 16 [31000/39785 (1%)]\tLoss: 24.549696\n",
      "Train Epoch: 16 [32000/39785 (1%)]\tLoss: 23.362434\n",
      "Train Epoch: 16 [33000/39785 (1%)]\tLoss: 22.092808\n",
      "Train Epoch: 16 [34000/39785 (1%)]\tLoss: 25.641611\n",
      "Train Epoch: 16 [35000/39785 (1%)]\tLoss: 29.623375\n",
      "Train Epoch: 16 [36000/39785 (1%)]\tLoss: 28.611113\n",
      "Train Epoch: 16 [37000/39785 (1%)]\tLoss: 26.159798\n",
      "Train Epoch: 16 [38000/39785 (1%)]\tLoss: 27.875952\n",
      "Train Epoch: 16 [39000/39785 (1%)]\tLoss: 26.575243\n",
      "Train Epoch: 17 [1000/39785 (0%)]\tLoss: 25.623960\n",
      "Train Epoch: 17 [2000/39785 (0%)]\tLoss: 21.343218\n",
      "Train Epoch: 17 [3000/39785 (0%)]\tLoss: 26.109222\n",
      "Train Epoch: 17 [4000/39785 (0%)]\tLoss: 23.699385\n",
      "Train Epoch: 17 [5000/39785 (0%)]\tLoss: 26.100222\n",
      "Train Epoch: 17 [6000/39785 (0%)]\tLoss: 27.064589\n",
      "Train Epoch: 17 [7000/39785 (0%)]\tLoss: 25.155807\n",
      "Train Epoch: 17 [8000/39785 (0%)]\tLoss: 25.930700\n",
      "Train Epoch: 17 [9000/39785 (0%)]\tLoss: 26.607487\n",
      "Train Epoch: 17 [10000/39785 (0%)]\tLoss: 24.677074\n",
      "Train Epoch: 17 [11000/39785 (0%)]\tLoss: 26.313187\n",
      "Train Epoch: 17 [12000/39785 (0%)]\tLoss: 27.386900\n",
      "Train Epoch: 17 [13000/39785 (0%)]\tLoss: 24.664814\n",
      "Train Epoch: 17 [14000/39785 (0%)]\tLoss: 27.551958\n",
      "Train Epoch: 17 [15000/39785 (0%)]\tLoss: 27.728218\n",
      "Train Epoch: 17 [16000/39785 (0%)]\tLoss: 23.593933\n",
      "Train Epoch: 17 [17000/39785 (0%)]\tLoss: 26.252846\n",
      "Train Epoch: 17 [18000/39785 (0%)]\tLoss: 32.593243\n",
      "Train Epoch: 17 [19000/39785 (0%)]\tLoss: 29.635786\n",
      "Train Epoch: 17 [20000/39785 (1%)]\tLoss: 27.078667\n",
      "Train Epoch: 17 [21000/39785 (1%)]\tLoss: 25.804239\n",
      "Train Epoch: 17 [22000/39785 (1%)]\tLoss: 26.062832\n",
      "Train Epoch: 17 [23000/39785 (1%)]\tLoss: 22.997795\n",
      "Train Epoch: 17 [24000/39785 (1%)]\tLoss: 24.248734\n",
      "Train Epoch: 17 [25000/39785 (1%)]\tLoss: 24.242231\n",
      "Train Epoch: 17 [26000/39785 (1%)]\tLoss: 28.723915\n",
      "Train Epoch: 17 [27000/39785 (1%)]\tLoss: 24.261742\n",
      "Train Epoch: 17 [28000/39785 (1%)]\tLoss: 22.547035\n",
      "Train Epoch: 17 [29000/39785 (1%)]\tLoss: 23.760323\n",
      "Train Epoch: 17 [30000/39785 (1%)]\tLoss: 21.048092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [31000/39785 (1%)]\tLoss: 28.341581\n",
      "Train Epoch: 17 [32000/39785 (1%)]\tLoss: 22.179310\n",
      "Train Epoch: 17 [33000/39785 (1%)]\tLoss: 24.968006\n",
      "Train Epoch: 17 [34000/39785 (1%)]\tLoss: 25.764803\n",
      "Train Epoch: 17 [35000/39785 (1%)]\tLoss: 27.684168\n",
      "Train Epoch: 17 [36000/39785 (1%)]\tLoss: 25.411375\n",
      "Train Epoch: 17 [37000/39785 (1%)]\tLoss: 28.350323\n",
      "Train Epoch: 17 [38000/39785 (1%)]\tLoss: 31.054224\n",
      "Train Epoch: 17 [39000/39785 (1%)]\tLoss: 20.608822\n",
      "Train Epoch: 18 [1000/39785 (0%)]\tLoss: 22.640676\n",
      "Train Epoch: 18 [2000/39785 (0%)]\tLoss: 28.908781\n",
      "Train Epoch: 18 [3000/39785 (0%)]\tLoss: 22.096617\n",
      "Train Epoch: 18 [4000/39785 (0%)]\tLoss: 26.823452\n",
      "Train Epoch: 18 [5000/39785 (0%)]\tLoss: 25.277042\n",
      "Train Epoch: 18 [6000/39785 (0%)]\tLoss: 24.861174\n",
      "Train Epoch: 18 [7000/39785 (0%)]\tLoss: 25.793291\n",
      "Train Epoch: 18 [8000/39785 (0%)]\tLoss: 28.109453\n",
      "Train Epoch: 18 [9000/39785 (0%)]\tLoss: 24.596329\n",
      "Train Epoch: 18 [10000/39785 (0%)]\tLoss: 25.332283\n",
      "Train Epoch: 18 [11000/39785 (0%)]\tLoss: 26.264334\n",
      "Train Epoch: 18 [12000/39785 (0%)]\tLoss: 24.544470\n",
      "Train Epoch: 18 [13000/39785 (0%)]\tLoss: 24.574184\n",
      "Train Epoch: 18 [14000/39785 (0%)]\tLoss: 24.406271\n",
      "Train Epoch: 18 [15000/39785 (0%)]\tLoss: 24.248343\n",
      "Train Epoch: 18 [16000/39785 (0%)]\tLoss: 23.956444\n",
      "Train Epoch: 18 [17000/39785 (0%)]\tLoss: 25.965914\n",
      "Train Epoch: 18 [18000/39785 (0%)]\tLoss: 30.385399\n",
      "Train Epoch: 18 [19000/39785 (0%)]\tLoss: 24.852301\n",
      "Train Epoch: 18 [20000/39785 (1%)]\tLoss: 22.203974\n",
      "Train Epoch: 18 [21000/39785 (1%)]\tLoss: 26.673765\n",
      "Train Epoch: 18 [22000/39785 (1%)]\tLoss: 25.151264\n",
      "Train Epoch: 18 [23000/39785 (1%)]\tLoss: 21.618214\n",
      "Train Epoch: 18 [24000/39785 (1%)]\tLoss: 26.518074\n",
      "Train Epoch: 18 [25000/39785 (1%)]\tLoss: 25.984356\n",
      "Train Epoch: 18 [26000/39785 (1%)]\tLoss: 26.190290\n",
      "Train Epoch: 18 [27000/39785 (1%)]\tLoss: 27.041458\n",
      "Train Epoch: 18 [28000/39785 (1%)]\tLoss: 24.636349\n",
      "Train Epoch: 18 [29000/39785 (1%)]\tLoss: 24.929104\n",
      "Train Epoch: 18 [30000/39785 (1%)]\tLoss: 22.501476\n",
      "Train Epoch: 18 [31000/39785 (1%)]\tLoss: 28.249342\n",
      "Train Epoch: 18 [32000/39785 (1%)]\tLoss: 27.905725\n",
      "Train Epoch: 18 [33000/39785 (1%)]\tLoss: 20.640312\n",
      "Train Epoch: 18 [34000/39785 (1%)]\tLoss: 24.878557\n",
      "Train Epoch: 18 [35000/39785 (1%)]\tLoss: 23.800560\n",
      "Train Epoch: 18 [36000/39785 (1%)]\tLoss: 28.177618\n",
      "Train Epoch: 18 [37000/39785 (1%)]\tLoss: 28.211658\n",
      "Train Epoch: 18 [38000/39785 (1%)]\tLoss: 26.670795\n",
      "Train Epoch: 18 [39000/39785 (1%)]\tLoss: 28.240570\n",
      "Train Epoch: 19 [1000/39785 (0%)]\tLoss: 23.648125\n",
      "Train Epoch: 19 [2000/39785 (0%)]\tLoss: 23.339710\n",
      "Train Epoch: 19 [3000/39785 (0%)]\tLoss: 22.311430\n",
      "Train Epoch: 19 [4000/39785 (0%)]\tLoss: 25.784052\n",
      "Train Epoch: 19 [5000/39785 (0%)]\tLoss: 28.789482\n",
      "Train Epoch: 19 [6000/39785 (0%)]\tLoss: 25.255808\n",
      "Train Epoch: 19 [7000/39785 (0%)]\tLoss: 28.098259\n",
      "Train Epoch: 19 [8000/39785 (0%)]\tLoss: 24.015976\n",
      "Train Epoch: 19 [9000/39785 (0%)]\tLoss: 23.940924\n",
      "Train Epoch: 19 [10000/39785 (0%)]\tLoss: 20.220413\n",
      "Train Epoch: 19 [11000/39785 (0%)]\tLoss: 27.449781\n",
      "Train Epoch: 19 [12000/39785 (0%)]\tLoss: 25.929863\n",
      "Train Epoch: 19 [13000/39785 (0%)]\tLoss: 23.645206\n",
      "Train Epoch: 19 [14000/39785 (0%)]\tLoss: 25.849266\n",
      "Train Epoch: 19 [15000/39785 (0%)]\tLoss: 24.133099\n",
      "Train Epoch: 19 [16000/39785 (0%)]\tLoss: 24.007284\n",
      "Train Epoch: 19 [17000/39785 (0%)]\tLoss: 22.902313\n",
      "Train Epoch: 19 [18000/39785 (0%)]\tLoss: 24.598104\n",
      "Train Epoch: 19 [19000/39785 (0%)]\tLoss: 22.759943\n",
      "Train Epoch: 19 [20000/39785 (1%)]\tLoss: 23.933540\n",
      "Train Epoch: 19 [21000/39785 (1%)]\tLoss: 23.516338\n",
      "Train Epoch: 19 [22000/39785 (1%)]\tLoss: 25.133345\n",
      "Train Epoch: 19 [23000/39785 (1%)]\tLoss: 23.669758\n",
      "Train Epoch: 19 [24000/39785 (1%)]\tLoss: 26.248196\n",
      "Train Epoch: 19 [25000/39785 (1%)]\tLoss: 28.759686\n",
      "Train Epoch: 19 [26000/39785 (1%)]\tLoss: 25.310431\n",
      "Train Epoch: 19 [27000/39785 (1%)]\tLoss: 28.623848\n",
      "Train Epoch: 19 [28000/39785 (1%)]\tLoss: 25.002886\n",
      "Train Epoch: 19 [29000/39785 (1%)]\tLoss: 28.647648\n",
      "Train Epoch: 19 [30000/39785 (1%)]\tLoss: 27.870502\n",
      "Train Epoch: 19 [31000/39785 (1%)]\tLoss: 21.695076\n",
      "Train Epoch: 19 [32000/39785 (1%)]\tLoss: 22.988621\n",
      "Train Epoch: 19 [33000/39785 (1%)]\tLoss: 30.173874\n",
      "Train Epoch: 19 [34000/39785 (1%)]\tLoss: 25.636633\n",
      "Train Epoch: 19 [35000/39785 (1%)]\tLoss: 24.498257\n",
      "Train Epoch: 19 [36000/39785 (1%)]\tLoss: 24.278730\n",
      "Train Epoch: 19 [37000/39785 (1%)]\tLoss: 25.821606\n",
      "Train Epoch: 19 [38000/39785 (1%)]\tLoss: 24.997627\n",
      "Train Epoch: 19 [39000/39785 (1%)]\tLoss: 26.607441\n",
      "Train Epoch: 20 [1000/39785 (0%)]\tLoss: 27.425018\n",
      "Train Epoch: 20 [2000/39785 (0%)]\tLoss: 24.716980\n",
      "Train Epoch: 20 [3000/39785 (0%)]\tLoss: 24.785831\n",
      "Train Epoch: 20 [4000/39785 (0%)]\tLoss: 26.121376\n",
      "Train Epoch: 20 [5000/39785 (0%)]\tLoss: 24.367682\n",
      "Train Epoch: 20 [6000/39785 (0%)]\tLoss: 25.362259\n",
      "Train Epoch: 20 [7000/39785 (0%)]\tLoss: 25.001514\n",
      "Train Epoch: 20 [8000/39785 (0%)]\tLoss: 30.907454\n",
      "Train Epoch: 20 [9000/39785 (0%)]\tLoss: 23.459881\n",
      "Train Epoch: 20 [10000/39785 (0%)]\tLoss: 24.541481\n",
      "Train Epoch: 20 [11000/39785 (0%)]\tLoss: 23.994234\n",
      "Train Epoch: 20 [12000/39785 (0%)]\tLoss: 24.149879\n",
      "Train Epoch: 20 [13000/39785 (0%)]\tLoss: 21.191660\n",
      "Train Epoch: 20 [14000/39785 (0%)]\tLoss: 24.234177\n",
      "Train Epoch: 20 [15000/39785 (0%)]\tLoss: 25.858767\n",
      "Train Epoch: 20 [16000/39785 (0%)]\tLoss: 24.185457\n",
      "Train Epoch: 20 [17000/39785 (0%)]\tLoss: 20.123892\n",
      "Train Epoch: 20 [18000/39785 (0%)]\tLoss: 28.556852\n",
      "Train Epoch: 20 [19000/39785 (0%)]\tLoss: 27.614988\n",
      "Train Epoch: 20 [20000/39785 (1%)]\tLoss: 24.268114\n",
      "Train Epoch: 20 [21000/39785 (1%)]\tLoss: 27.363913\n",
      "Train Epoch: 20 [22000/39785 (1%)]\tLoss: 26.978651\n",
      "Train Epoch: 20 [23000/39785 (1%)]\tLoss: 23.771965\n",
      "Train Epoch: 20 [24000/39785 (1%)]\tLoss: 23.785610\n",
      "Train Epoch: 20 [25000/39785 (1%)]\tLoss: 22.398426\n",
      "Train Epoch: 20 [26000/39785 (1%)]\tLoss: 21.744438\n",
      "Train Epoch: 20 [27000/39785 (1%)]\tLoss: 27.547380\n",
      "Train Epoch: 20 [28000/39785 (1%)]\tLoss: 22.066200\n",
      "Train Epoch: 20 [29000/39785 (1%)]\tLoss: 26.194904\n",
      "Train Epoch: 20 [30000/39785 (1%)]\tLoss: 25.035873\n",
      "Train Epoch: 20 [31000/39785 (1%)]\tLoss: 25.718594\n",
      "Train Epoch: 20 [32000/39785 (1%)]\tLoss: 25.413826\n",
      "Train Epoch: 20 [33000/39785 (1%)]\tLoss: 27.375278\n",
      "Train Epoch: 20 [34000/39785 (1%)]\tLoss: 25.292074\n",
      "Train Epoch: 20 [35000/39785 (1%)]\tLoss: 24.687008\n",
      "Train Epoch: 20 [36000/39785 (1%)]\tLoss: 27.470955\n",
      "Train Epoch: 20 [37000/39785 (1%)]\tLoss: 21.514753\n",
      "Train Epoch: 20 [38000/39785 (1%)]\tLoss: 22.990089\n",
      "Train Epoch: 20 [39000/39785 (1%)]\tLoss: 24.338066\n",
      "Train Epoch: 22 [1000/39785 (0%)]\tLoss: 25.947784\n",
      "Train Epoch: 22 [2000/39785 (0%)]\tLoss: 24.325066\n",
      "Train Epoch: 22 [3000/39785 (0%)]\tLoss: 24.184616\n",
      "Train Epoch: 22 [4000/39785 (0%)]\tLoss: 21.583597\n",
      "Train Epoch: 22 [5000/39785 (0%)]\tLoss: 22.338863\n",
      "Train Epoch: 22 [6000/39785 (0%)]\tLoss: 21.827379\n",
      "Train Epoch: 22 [7000/39785 (0%)]\tLoss: 28.013939\n",
      "Train Epoch: 22 [8000/39785 (0%)]\tLoss: 23.408346\n",
      "Train Epoch: 22 [9000/39785 (0%)]\tLoss: 24.762043\n",
      "Train Epoch: 22 [10000/39785 (0%)]\tLoss: 25.746954\n",
      "Train Epoch: 22 [11000/39785 (0%)]\tLoss: 24.942904\n",
      "Train Epoch: 22 [12000/39785 (0%)]\tLoss: 22.579012\n",
      "Train Epoch: 22 [13000/39785 (0%)]\tLoss: 26.412209\n",
      "Train Epoch: 22 [14000/39785 (0%)]\tLoss: 26.526703\n",
      "Train Epoch: 22 [15000/39785 (0%)]\tLoss: 22.375883\n",
      "Train Epoch: 22 [16000/39785 (0%)]\tLoss: 32.455711\n",
      "Train Epoch: 22 [17000/39785 (0%)]\tLoss: 26.233643\n",
      "Train Epoch: 22 [18000/39785 (0%)]\tLoss: 26.636990\n",
      "Train Epoch: 22 [19000/39785 (0%)]\tLoss: 23.821058\n",
      "Train Epoch: 22 [20000/39785 (1%)]\tLoss: 23.949362\n",
      "Train Epoch: 22 [21000/39785 (1%)]\tLoss: 27.854280\n",
      "Train Epoch: 22 [22000/39785 (1%)]\tLoss: 20.655025\n",
      "Train Epoch: 22 [23000/39785 (1%)]\tLoss: 30.657299\n",
      "Train Epoch: 22 [24000/39785 (1%)]\tLoss: 26.272335\n",
      "Train Epoch: 22 [25000/39785 (1%)]\tLoss: 22.536568\n",
      "Train Epoch: 22 [26000/39785 (1%)]\tLoss: 27.918800\n",
      "Train Epoch: 22 [27000/39785 (1%)]\tLoss: 27.304840\n",
      "Train Epoch: 22 [28000/39785 (1%)]\tLoss: 22.508987\n",
      "Train Epoch: 22 [29000/39785 (1%)]\tLoss: 25.560427\n",
      "Train Epoch: 22 [30000/39785 (1%)]\tLoss: 24.439499\n",
      "Train Epoch: 22 [31000/39785 (1%)]\tLoss: 22.848970\n",
      "Train Epoch: 22 [32000/39785 (1%)]\tLoss: 21.908298\n",
      "Train Epoch: 22 [33000/39785 (1%)]\tLoss: 23.758009\n",
      "Train Epoch: 22 [34000/39785 (1%)]\tLoss: 24.836020\n",
      "Train Epoch: 22 [35000/39785 (1%)]\tLoss: 23.189796\n",
      "Train Epoch: 22 [36000/39785 (1%)]\tLoss: 21.646580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [37000/39785 (1%)]\tLoss: 26.466637\n",
      "Train Epoch: 22 [38000/39785 (1%)]\tLoss: 24.819136\n",
      "Train Epoch: 22 [39000/39785 (1%)]\tLoss: 28.324224\n",
      "Train Epoch: 23 [1000/39785 (0%)]\tLoss: 28.958685\n",
      "Train Epoch: 23 [2000/39785 (0%)]\tLoss: 27.610186\n",
      "Train Epoch: 23 [3000/39785 (0%)]\tLoss: 27.235241\n",
      "Train Epoch: 23 [4000/39785 (0%)]\tLoss: 24.641510\n",
      "Train Epoch: 23 [5000/39785 (0%)]\tLoss: 23.856258\n",
      "Train Epoch: 23 [6000/39785 (0%)]\tLoss: 23.594107\n",
      "Train Epoch: 23 [7000/39785 (0%)]\tLoss: 23.593330\n",
      "Train Epoch: 23 [8000/39785 (0%)]\tLoss: 27.665970\n",
      "Train Epoch: 23 [9000/39785 (0%)]\tLoss: 27.895754\n",
      "Train Epoch: 23 [10000/39785 (0%)]\tLoss: 33.166286\n",
      "Train Epoch: 23 [11000/39785 (0%)]\tLoss: 28.109337\n",
      "Train Epoch: 23 [12000/39785 (0%)]\tLoss: 25.986193\n",
      "Train Epoch: 23 [13000/39785 (0%)]\tLoss: 25.531797\n",
      "Train Epoch: 23 [14000/39785 (0%)]\tLoss: 25.783121\n",
      "Train Epoch: 23 [15000/39785 (0%)]\tLoss: 24.092127\n",
      "Train Epoch: 23 [16000/39785 (0%)]\tLoss: 26.370464\n",
      "Train Epoch: 23 [17000/39785 (0%)]\tLoss: 25.454512\n",
      "Train Epoch: 23 [18000/39785 (0%)]\tLoss: 24.072548\n",
      "Train Epoch: 23 [19000/39785 (0%)]\tLoss: 22.528042\n",
      "Train Epoch: 23 [20000/39785 (1%)]\tLoss: 26.734322\n",
      "Train Epoch: 23 [21000/39785 (1%)]\tLoss: 23.138161\n",
      "Train Epoch: 23 [22000/39785 (1%)]\tLoss: 21.447630\n",
      "Train Epoch: 23 [23000/39785 (1%)]\tLoss: 21.794867\n",
      "Train Epoch: 23 [24000/39785 (1%)]\tLoss: 24.553850\n",
      "Train Epoch: 23 [25000/39785 (1%)]\tLoss: 24.607737\n",
      "Train Epoch: 23 [26000/39785 (1%)]\tLoss: 25.491539\n",
      "Train Epoch: 23 [27000/39785 (1%)]\tLoss: 27.665291\n",
      "Train Epoch: 23 [28000/39785 (1%)]\tLoss: 23.593498\n",
      "Train Epoch: 23 [29000/39785 (1%)]\tLoss: 26.552633\n",
      "Train Epoch: 23 [30000/39785 (1%)]\tLoss: 24.169296\n",
      "Train Epoch: 23 [31000/39785 (1%)]\tLoss: 23.743654\n",
      "Train Epoch: 23 [32000/39785 (1%)]\tLoss: 25.942183\n",
      "Train Epoch: 23 [33000/39785 (1%)]\tLoss: 25.174776\n",
      "Train Epoch: 23 [34000/39785 (1%)]\tLoss: 22.314812\n",
      "Train Epoch: 23 [35000/39785 (1%)]\tLoss: 23.105917\n",
      "Train Epoch: 23 [36000/39785 (1%)]\tLoss: 23.562883\n",
      "Train Epoch: 23 [37000/39785 (1%)]\tLoss: 25.838343\n",
      "Train Epoch: 23 [38000/39785 (1%)]\tLoss: 28.660524\n",
      "Train Epoch: 23 [39000/39785 (1%)]\tLoss: 21.432373\n",
      "Train Epoch: 24 [1000/39785 (0%)]\tLoss: 26.983437\n",
      "Train Epoch: 24 [2000/39785 (0%)]\tLoss: 27.543291\n",
      "Train Epoch: 24 [3000/39785 (0%)]\tLoss: 24.940722\n",
      "Train Epoch: 24 [4000/39785 (0%)]\tLoss: 22.585152\n",
      "Train Epoch: 24 [5000/39785 (0%)]\tLoss: 24.868027\n",
      "Train Epoch: 24 [6000/39785 (0%)]\tLoss: 25.996107\n",
      "Train Epoch: 24 [7000/39785 (0%)]\tLoss: 25.554218\n",
      "Train Epoch: 24 [8000/39785 (0%)]\tLoss: 21.839808\n",
      "Train Epoch: 24 [9000/39785 (0%)]\tLoss: 26.292288\n",
      "Train Epoch: 24 [10000/39785 (0%)]\tLoss: 20.988604\n",
      "Train Epoch: 24 [11000/39785 (0%)]\tLoss: 25.692583\n",
      "Train Epoch: 24 [12000/39785 (0%)]\tLoss: 24.104811\n",
      "Train Epoch: 24 [13000/39785 (0%)]\tLoss: 23.025726\n",
      "Train Epoch: 24 [14000/39785 (0%)]\tLoss: 23.970547\n",
      "Train Epoch: 24 [15000/39785 (0%)]\tLoss: 24.426168\n",
      "Train Epoch: 24 [16000/39785 (0%)]\tLoss: 24.980370\n",
      "Train Epoch: 24 [17000/39785 (0%)]\tLoss: 26.527685\n",
      "Train Epoch: 24 [18000/39785 (0%)]\tLoss: 24.577499\n",
      "Train Epoch: 24 [19000/39785 (0%)]\tLoss: 21.007833\n",
      "Train Epoch: 24 [20000/39785 (1%)]\tLoss: 27.130405\n",
      "Train Epoch: 24 [21000/39785 (1%)]\tLoss: 23.609871\n",
      "Train Epoch: 24 [22000/39785 (1%)]\tLoss: 23.908520\n",
      "Train Epoch: 24 [23000/39785 (1%)]\tLoss: 26.152740\n",
      "Train Epoch: 24 [24000/39785 (1%)]\tLoss: 28.280222\n",
      "Train Epoch: 24 [25000/39785 (1%)]\tLoss: 28.090296\n",
      "Train Epoch: 24 [26000/39785 (1%)]\tLoss: 25.680252\n",
      "Train Epoch: 24 [27000/39785 (1%)]\tLoss: 27.326029\n",
      "Train Epoch: 24 [28000/39785 (1%)]\tLoss: 24.612585\n",
      "Train Epoch: 24 [29000/39785 (1%)]\tLoss: 23.475689\n",
      "Train Epoch: 24 [30000/39785 (1%)]\tLoss: 25.360620\n",
      "Train Epoch: 24 [31000/39785 (1%)]\tLoss: 23.647696\n",
      "Train Epoch: 24 [32000/39785 (1%)]\tLoss: 23.109295\n",
      "Train Epoch: 24 [33000/39785 (1%)]\tLoss: 23.217789\n",
      "Train Epoch: 24 [34000/39785 (1%)]\tLoss: 21.547024\n",
      "Train Epoch: 24 [35000/39785 (1%)]\tLoss: 26.889843\n",
      "Train Epoch: 24 [36000/39785 (1%)]\tLoss: 28.320986\n",
      "Train Epoch: 24 [37000/39785 (1%)]\tLoss: 24.727291\n",
      "Train Epoch: 24 [38000/39785 (1%)]\tLoss: 25.064455\n",
      "Train Epoch: 24 [39000/39785 (1%)]\tLoss: 24.725042\n",
      "Train Epoch: 25 [1000/39785 (0%)]\tLoss: 22.500093\n",
      "Train Epoch: 25 [2000/39785 (0%)]\tLoss: 23.949184\n",
      "Train Epoch: 25 [3000/39785 (0%)]\tLoss: 22.471434\n",
      "Train Epoch: 25 [4000/39785 (0%)]\tLoss: 24.011951\n",
      "Train Epoch: 25 [5000/39785 (0%)]\tLoss: 26.024097\n",
      "Train Epoch: 25 [6000/39785 (0%)]\tLoss: 24.248270\n",
      "Train Epoch: 25 [7000/39785 (0%)]\tLoss: 25.647455\n",
      "Train Epoch: 25 [8000/39785 (0%)]\tLoss: 26.440044\n",
      "Train Epoch: 25 [9000/39785 (0%)]\tLoss: 26.831448\n",
      "Train Epoch: 25 [10000/39785 (0%)]\tLoss: 28.193314\n",
      "Train Epoch: 25 [11000/39785 (0%)]\tLoss: 25.893347\n",
      "Train Epoch: 25 [12000/39785 (0%)]\tLoss: 22.785152\n",
      "Train Epoch: 25 [13000/39785 (0%)]\tLoss: 25.533428\n",
      "Train Epoch: 25 [14000/39785 (0%)]\tLoss: 21.441282\n",
      "Train Epoch: 25 [15000/39785 (0%)]\tLoss: 26.259943\n",
      "Train Epoch: 25 [16000/39785 (0%)]\tLoss: 26.101570\n",
      "Train Epoch: 25 [17000/39785 (0%)]\tLoss: 28.784941\n",
      "Train Epoch: 25 [18000/39785 (0%)]\tLoss: 23.824827\n",
      "Train Epoch: 25 [19000/39785 (0%)]\tLoss: 21.701490\n",
      "Train Epoch: 25 [20000/39785 (1%)]\tLoss: 29.393997\n",
      "Train Epoch: 25 [21000/39785 (1%)]\tLoss: 23.033386\n",
      "Train Epoch: 25 [22000/39785 (1%)]\tLoss: 25.585028\n",
      "Train Epoch: 25 [23000/39785 (1%)]\tLoss: 24.542208\n",
      "Train Epoch: 25 [24000/39785 (1%)]\tLoss: 28.187805\n",
      "Train Epoch: 25 [25000/39785 (1%)]\tLoss: 25.828732\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-dc1bfb9aabe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_custom_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecr_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# test(model_hard, device, test_set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-260-34fd3fc0ebef>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;31m# loss_fn = nn.MSELoss(reduction='sum')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# loss = loss_fn(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-260-34fd3fc0ebef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# x = self.gated(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tf.reshape(x,[batchSize,-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/se3cnn-0.0.0-py3.7.egg/se3cnn/convolution.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(1)\n",
    "\n",
    "model_custom_loss = EquiNet().to(device)\n",
    "learning_rate = 5e-3\n",
    "optimizer = torch.optim.Adam(model_custom_loss.parameters(), lr=learning_rate)\n",
    "\n",
    "per_epoch = 5\n",
    "decr_rate = 0.99\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model_custom_loss, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate)\n",
    "    # test(model_hard, device, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_test = model_custom_loss(torch.from_numpy(test_set._images[:100].reshape(batch_size,1,24,24,24)).type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8) [0.878501296043396, 0.14600880444049835, -0.009620994329452515, -0.04242924600839615, -0.10463349521160126, 0.5524479150772095]\n",
      "[ 7.          0.8140826   0.16944312  0.01647427 -0.07471883 -0.16377677\n",
      "  0.5252441 ]\n",
      "\n",
      "tensor(8) [0.014157235622406006, 0.8191781044006348, 0.25201231241226196, -0.5993931889533997, 0.038873735815286636, -0.15627287328243256]\n",
      "[ 7.          0.01401387  0.8029993   0.18298681 -0.5421038   0.071615\n",
      " -0.15002087]\n",
      "\n",
      "tensor(3) [0.929155707359314, 0.052798449993133545, 0.00979757308959961, -0.04924049228429794, -0.08797045052051544, -0.28930455446243286]\n",
      "[ 7.0000000e+00  9.5146030e-01  4.8440255e-02  9.9439159e-05\n",
      " -3.1038227e-03  1.3755901e-02 -3.0360824e-01]\n",
      "\n",
      "tensor(9) [0.13180002570152283, 0.5320850610733032, 0.3538301885128021, -0.5595158934593201, -0.3730732798576355, 0.5256956815719604]\n",
      "[ 7.          0.23470888  0.4653611   0.29993004 -0.5283479  -0.37522325\n",
      "  0.46738502]\n",
      "\n",
      "tensor(7) [0.5261337757110596, 0.3531031310558319, 0.18525788187980652, -0.35418975353240967, 0.39325040578842163, -0.6269180178642273]\n",
      "[ 7.          0.45699063  0.31786323  0.22514616 -0.37832707  0.4536291\n",
      " -0.53900003]\n",
      "\n",
      "tensor(2) [0.24626193940639496, 0.3468398451805115, 0.3792957663536072, 0.5498379468917847, 0.3598175048828125, 0.48003947734832764]\n",
      "[7.         0.22514616 0.45699063 0.31786323 0.53900003 0.37832707\n",
      " 0.4536291 ]\n",
      "\n",
      "tensor(8) [0.05667535960674286, 0.7225899696350098, 0.23789703845977783, -0.5165285468101501, 0.050803665071725845, -0.07188016176223755]\n",
      "[ 7.          0.01647427  0.8140826   0.16944312 -0.5252441   0.07471883\n",
      " -0.16377677]\n",
      "\n",
      "tensor(8) [0.11530345678329468, -0.014194130897521973, 0.8689937591552734, 0.16755108535289764, 0.6063413023948669, 0.03157956525683403]\n",
      "[7.         0.18298681 0.01401387 0.8029993  0.15002087 0.5421038\n",
      " 0.071615  ]\n",
      "\n",
      "tensor(9) [-0.0857740044593811, 1.0420341491699219, 0.04209916293621063, 0.2914595603942871, -0.04460563883185387, 0.023291677236557007]\n",
      "[7.0000000e+00 9.9439159e-05 9.5146030e-01 4.8440255e-02 3.0360824e-01\n",
      " 3.1038227e-03 1.3755901e-02]\n",
      "\n",
      "tensor(9) [0.22344225645065308, 0.2577078342437744, 0.5293176174163818, -0.5107458233833313, 0.5619484782218933, -0.30399078130722046]\n",
      "[ 7.          0.29993004  0.23470888  0.4653611  -0.46738502  0.5283479\n",
      " -0.37522325]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(answer_test[i][:NUM_CLASSES])\n",
    "    print(torch.argmax(answer_test[i][:NUM_CLASSES]), answer_test[i][NUM_CLASSES:].data.tolist())\n",
    "    print(test_set._labels[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_custom_loss(output, target):\n",
    "    order_out = output[:, 0 : NUM_CLASSES]\n",
    "    order_target = target[:, 0 : 1].type(torch.LongTensor).squeeze_()\n",
    "    axis_out = output[:, NUM_CLASSES : NUM_CLASSES + 6]\n",
    "    axis_target = target[:, 1 : 7]\n",
    "\n",
    "    loss = 1 * nn.CrossEntropyLoss()(order_out, order_target) + nn.MSELoss(reduction='sum')(axis_out, axis_target)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = SE3Convolution(repr_in_1, repr_out_1, size=4)\n",
    "        self.pool1 = nn.AvgPool3d(pool_size, pool_stride)\n",
    "        self.conv2 = SE3Convolution(repr_in_2, repr_out_2, size=4)\n",
    "        self.pool2 = nn.AvgPool3d(pool_size, pool_stride)\n",
    "        \n",
    "        self.lin1 = nn.Linear(n_input_1, n_output_1)\n",
    "        self.lin2 = nn.Linear(n_output_1, NUM_CLASSES+6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.conv1(x))\n",
    "        x = self.pool2(self.conv2(x))\n",
    "        x = x.view(batch_size,-1) \n",
    "        x = F.leaky_relu(self.lin1(x))\n",
    "        return self.lin2(x)\n",
    "    \n",
    "    \n",
    "def train(model, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate):\n",
    "    model.train()\n",
    "    flag = True\n",
    "    new_epoch = True\n",
    "    \n",
    "    if new_epoch:\n",
    "        batch_idx = 1\n",
    "        new_epoch = False\n",
    "        data, target, _ = train_set.next_batch(batch_size)\n",
    "        data = torch.from_numpy(data.reshape(batch_size,1,24,24,24)).type(torch.FloatTensor)\n",
    "        target = torch.from_numpy(target.reshape(batch_size,-1)).type(torch.FloatTensor)\n",
    "        cnt = epoch // per_epoch\n",
    "        if ((epoch+1) // per_epoch > cnt) and flag:\n",
    "            lr = 0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            lr *= decr_rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            flag = False\n",
    "        if ((epoch+1) // per_epoch <= cnt):\n",
    "            flag = True\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss_fn = nn.MSELoss(reduction='sum')\n",
    "        # loss = loss_fn(output, target)\n",
    "        loss = custom_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    while (train_set._index_in_epoch + batch_size) < train_set._num_examples:\n",
    "        batch_idx += 1\n",
    "        data, target, _ = train_set.next_batch(batch_size)\n",
    "        data = torch.from_numpy(data.reshape(batch_size,1,24,24,24)).type(torch.FloatTensor)\n",
    "        target = torch.from_numpy(target.reshape(batch_size,-1)).type(torch.FloatTensor)\n",
    "        cnt = epoch // per_epoch\n",
    "        if ((epoch+1) // per_epoch > cnt) and flag:\n",
    "            lr = 0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            lr *= decr_rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            flag = False\n",
    "        if ((epoch+1) // per_epoch <= cnt):\n",
    "            flag = True\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss_fn = nn.MSELoss(reduction='sum')\n",
    "        # loss = loss_fn(output, target)\n",
    "        loss = weighted_custom_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, train_set._num_examples,\n",
    "                100. * batch_idx / train_set._num_examples, loss.item()))\n",
    "\n",
    "def test(model, device, test_set):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_set:\n",
    "            output = model(data)\n",
    "            loss_fn = nn.MSELoss(reduction='sum')\n",
    "            test_loss += loss_fn(output, target) \n",
    "            # pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += int(torch.argmax(output) == torch.argmax(target))\n",
    "\n",
    "    test_loss /= len(test_set)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_set),\n",
    "        100. * correct / len(test_set)))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_in_1 = [(1,0)]\n",
    "repr_out_1 = [(2,0),(2,1),(2,2),(2,3),(2,4),(2,5)]\n",
    "repr_in_2 = [(2,0),(2,1),(2,2),(2,3),(2,4),(2,5)]\n",
    "repr_out_2 = [(1,0),(2,1)]\n",
    "size = 4\n",
    "activation = (None, F.leaky_relu)\n",
    "pool_size = 2\n",
    "pool_stride = 2\n",
    "bias = True\n",
    "\n",
    "n_input_1 = 189\n",
    "n_output_1 = 74 \n",
    "n_output_2 = 40\n",
    "\n",
    "batch_size = 100\n",
    "prob = 0.5\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../deepSymmetry/data/fromScripts/dataReady0\n",
      "Extracting ../deepSymmetry/data/fromScripts/dataReady0_label\n",
      "(39785, 13824)\n"
     ]
    }
   ],
   "source": [
    "train_name = '../deepSymmetry/data/fromScripts/dataReady0'\n",
    "train_set = load_data.read_data_set(train_name, dtype=dtypes.float16, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute 16.pkl.gz... save 16.pkl.gz... done\n",
      "compute 5.pkl.gz... save 5.pkl.gz... done\n",
      "compute 17.pkl.gz... save 17.pkl.gz... done\n",
      "compute 18.pkl.gz... save 18.pkl.gz... done\n",
      "compute 19.pkl.gz... save 19.pkl.gz... done\n",
      "compute 20.pkl.gz... save 20.pkl.gz... done\n",
      "compute 21.pkl.gz... save 21.pkl.gz... done\n",
      "compute 22.pkl.gz... save 22.pkl.gz... done\n",
      "compute 23.pkl.gz... save 23.pkl.gz... done\n",
      "compute 24.pkl.gz... save 24.pkl.gz... done\n",
      "compute 6.pkl.gz... save 6.pkl.gz... done\n",
      "compute 25.pkl.gz... save 25.pkl.gz... done\n",
      "Train Epoch: 1 [1000/39785 (0%)]\tLoss: 40.160805\n",
      "Train Epoch: 1 [2000/39785 (0%)]\tLoss: 40.602524\n",
      "Train Epoch: 1 [3000/39785 (0%)]\tLoss: 32.945190\n",
      "Train Epoch: 1 [4000/39785 (0%)]\tLoss: 29.836855\n",
      "Train Epoch: 1 [5000/39785 (0%)]\tLoss: 24.029175\n",
      "Train Epoch: 1 [6000/39785 (0%)]\tLoss: 30.144970\n",
      "Train Epoch: 1 [7000/39785 (0%)]\tLoss: 26.246704\n",
      "Train Epoch: 1 [8000/39785 (0%)]\tLoss: 17.176540\n",
      "Train Epoch: 1 [9000/39785 (0%)]\tLoss: 21.882401\n",
      "Train Epoch: 1 [10000/39785 (0%)]\tLoss: 24.670935\n",
      "Train Epoch: 1 [11000/39785 (0%)]\tLoss: 24.106155\n",
      "Train Epoch: 1 [12000/39785 (0%)]\tLoss: 19.496010\n",
      "Train Epoch: 1 [13000/39785 (0%)]\tLoss: 19.775131\n",
      "Train Epoch: 1 [14000/39785 (0%)]\tLoss: 21.128464\n",
      "Train Epoch: 1 [15000/39785 (0%)]\tLoss: 19.408840\n",
      "Train Epoch: 1 [16000/39785 (0%)]\tLoss: 22.073565\n",
      "Train Epoch: 1 [17000/39785 (0%)]\tLoss: 23.534571\n",
      "Train Epoch: 1 [18000/39785 (0%)]\tLoss: 18.174896\n",
      "Train Epoch: 1 [19000/39785 (0%)]\tLoss: 20.270264\n",
      "Train Epoch: 1 [20000/39785 (1%)]\tLoss: 21.621033\n",
      "Train Epoch: 1 [21000/39785 (1%)]\tLoss: 17.591303\n",
      "Train Epoch: 1 [22000/39785 (1%)]\tLoss: 17.096746\n",
      "Train Epoch: 1 [23000/39785 (1%)]\tLoss: 15.543367\n",
      "Train Epoch: 1 [24000/39785 (1%)]\tLoss: 18.687521\n",
      "Train Epoch: 1 [25000/39785 (1%)]\tLoss: 15.615738\n",
      "Train Epoch: 1 [26000/39785 (1%)]\tLoss: 17.527258\n",
      "Train Epoch: 1 [27000/39785 (1%)]\tLoss: 14.899817\n",
      "Train Epoch: 1 [28000/39785 (1%)]\tLoss: 19.027191\n",
      "Train Epoch: 1 [29000/39785 (1%)]\tLoss: 15.705893\n",
      "Train Epoch: 1 [30000/39785 (1%)]\tLoss: 16.832808\n",
      "Train Epoch: 1 [31000/39785 (1%)]\tLoss: 19.397940\n",
      "Train Epoch: 1 [32000/39785 (1%)]\tLoss: 14.948553\n",
      "Train Epoch: 1 [33000/39785 (1%)]\tLoss: 18.165001\n",
      "Train Epoch: 1 [34000/39785 (1%)]\tLoss: 17.411926\n",
      "Train Epoch: 1 [35000/39785 (1%)]\tLoss: 21.430954\n",
      "Train Epoch: 1 [36000/39785 (1%)]\tLoss: 18.686901\n",
      "Train Epoch: 1 [37000/39785 (1%)]\tLoss: 17.551304\n",
      "Train Epoch: 1 [38000/39785 (1%)]\tLoss: 20.260323\n",
      "Train Epoch: 1 [39000/39785 (1%)]\tLoss: 15.587329\n",
      "Train Epoch: 2 [1000/39785 (0%)]\tLoss: 13.878142\n",
      "Train Epoch: 2 [2000/39785 (0%)]\tLoss: 18.316212\n",
      "Train Epoch: 2 [3000/39785 (0%)]\tLoss: 19.332668\n",
      "Train Epoch: 2 [4000/39785 (0%)]\tLoss: 16.304243\n",
      "Train Epoch: 2 [5000/39785 (0%)]\tLoss: 14.388625\n",
      "Train Epoch: 2 [6000/39785 (0%)]\tLoss: 12.635264\n",
      "Train Epoch: 2 [7000/39785 (0%)]\tLoss: 15.387100\n",
      "Train Epoch: 2 [8000/39785 (0%)]\tLoss: 15.632046\n",
      "Train Epoch: 2 [9000/39785 (0%)]\tLoss: 13.620913\n",
      "Train Epoch: 2 [10000/39785 (0%)]\tLoss: 18.070320\n",
      "Train Epoch: 2 [11000/39785 (0%)]\tLoss: 13.999759\n",
      "Train Epoch: 2 [12000/39785 (0%)]\tLoss: 19.529331\n",
      "Train Epoch: 2 [13000/39785 (0%)]\tLoss: 15.538761\n",
      "Train Epoch: 2 [14000/39785 (0%)]\tLoss: 17.018120\n",
      "Train Epoch: 2 [15000/39785 (0%)]\tLoss: 14.110698\n",
      "Train Epoch: 2 [16000/39785 (0%)]\tLoss: 19.800566\n",
      "Train Epoch: 2 [17000/39785 (0%)]\tLoss: 15.997024\n",
      "Train Epoch: 2 [18000/39785 (0%)]\tLoss: 16.621122\n",
      "Train Epoch: 2 [19000/39785 (0%)]\tLoss: 17.843527\n",
      "Train Epoch: 2 [20000/39785 (1%)]\tLoss: 17.950527\n",
      "Train Epoch: 2 [21000/39785 (1%)]\tLoss: 21.576498\n",
      "Train Epoch: 2 [22000/39785 (1%)]\tLoss: 16.224518\n",
      "Train Epoch: 2 [23000/39785 (1%)]\tLoss: 15.664017\n",
      "Train Epoch: 2 [24000/39785 (1%)]\tLoss: 13.717863\n",
      "Train Epoch: 2 [25000/39785 (1%)]\tLoss: 14.792047\n",
      "Train Epoch: 2 [26000/39785 (1%)]\tLoss: 18.783726\n",
      "Train Epoch: 2 [27000/39785 (1%)]\tLoss: 15.152455\n",
      "Train Epoch: 2 [28000/39785 (1%)]\tLoss: 12.327486\n",
      "Train Epoch: 2 [29000/39785 (1%)]\tLoss: 17.003611\n",
      "Train Epoch: 2 [30000/39785 (1%)]\tLoss: 19.599436\n",
      "Train Epoch: 2 [31000/39785 (1%)]\tLoss: 16.627167\n",
      "Train Epoch: 2 [32000/39785 (1%)]\tLoss: 16.914242\n",
      "Train Epoch: 2 [33000/39785 (1%)]\tLoss: 14.671468\n",
      "Train Epoch: 2 [34000/39785 (1%)]\tLoss: 14.502645\n",
      "Train Epoch: 2 [35000/39785 (1%)]\tLoss: 15.372845\n",
      "Train Epoch: 2 [36000/39785 (1%)]\tLoss: 18.126867\n",
      "Train Epoch: 2 [37000/39785 (1%)]\tLoss: 16.730261\n",
      "Train Epoch: 2 [38000/39785 (1%)]\tLoss: 17.055565\n",
      "Train Epoch: 2 [39000/39785 (1%)]\tLoss: 14.671506\n",
      "Train Epoch: 3 [1000/39785 (0%)]\tLoss: 14.291867\n",
      "Train Epoch: 3 [2000/39785 (0%)]\tLoss: 17.187193\n",
      "Train Epoch: 3 [3000/39785 (0%)]\tLoss: 13.274265\n",
      "Train Epoch: 3 [4000/39785 (0%)]\tLoss: 17.609596\n",
      "Train Epoch: 3 [5000/39785 (0%)]\tLoss: 12.380456\n",
      "Train Epoch: 3 [6000/39785 (0%)]\tLoss: 20.246771\n",
      "Train Epoch: 3 [7000/39785 (0%)]\tLoss: 19.288618\n",
      "Train Epoch: 3 [8000/39785 (0%)]\tLoss: 16.312157\n",
      "Train Epoch: 3 [9000/39785 (0%)]\tLoss: 12.838863\n",
      "Train Epoch: 3 [10000/39785 (0%)]\tLoss: 14.405619\n",
      "Train Epoch: 3 [11000/39785 (0%)]\tLoss: 15.757339\n",
      "Train Epoch: 3 [12000/39785 (0%)]\tLoss: 13.274601\n",
      "Train Epoch: 3 [13000/39785 (0%)]\tLoss: 13.883376\n",
      "Train Epoch: 3 [14000/39785 (0%)]\tLoss: 10.735296\n",
      "Train Epoch: 3 [15000/39785 (0%)]\tLoss: 14.371981\n",
      "Train Epoch: 3 [16000/39785 (0%)]\tLoss: 17.722338\n",
      "Train Epoch: 3 [17000/39785 (0%)]\tLoss: 14.223542\n",
      "Train Epoch: 3 [18000/39785 (0%)]\tLoss: 15.806733\n",
      "Train Epoch: 3 [19000/39785 (0%)]\tLoss: 17.883656\n",
      "Train Epoch: 3 [20000/39785 (1%)]\tLoss: 12.281547\n",
      "Train Epoch: 3 [21000/39785 (1%)]\tLoss: 13.259034\n",
      "Train Epoch: 3 [22000/39785 (1%)]\tLoss: 15.129809\n",
      "Train Epoch: 3 [23000/39785 (1%)]\tLoss: 18.729683\n",
      "Train Epoch: 3 [24000/39785 (1%)]\tLoss: 16.585674\n",
      "Train Epoch: 3 [25000/39785 (1%)]\tLoss: 15.672014\n",
      "Train Epoch: 3 [26000/39785 (1%)]\tLoss: 17.909439\n",
      "Train Epoch: 3 [27000/39785 (1%)]\tLoss: 12.227210\n",
      "Train Epoch: 3 [28000/39785 (1%)]\tLoss: 16.325827\n",
      "Train Epoch: 3 [29000/39785 (1%)]\tLoss: 15.261149\n",
      "Train Epoch: 3 [30000/39785 (1%)]\tLoss: 14.926018\n",
      "Train Epoch: 3 [31000/39785 (1%)]\tLoss: 15.161015\n",
      "Train Epoch: 3 [32000/39785 (1%)]\tLoss: 15.179037\n",
      "Train Epoch: 3 [33000/39785 (1%)]\tLoss: 16.720896\n",
      "Train Epoch: 3 [34000/39785 (1%)]\tLoss: 15.845310\n",
      "Train Epoch: 3 [35000/39785 (1%)]\tLoss: 13.263337\n",
      "Train Epoch: 3 [36000/39785 (1%)]\tLoss: 15.352869\n",
      "Train Epoch: 3 [37000/39785 (1%)]\tLoss: 13.280912\n",
      "Train Epoch: 3 [38000/39785 (1%)]\tLoss: 14.176372\n",
      "Train Epoch: 3 [39000/39785 (1%)]\tLoss: 15.999092\n",
      "Train Epoch: 4 [1000/39785 (0%)]\tLoss: 14.299209\n",
      "Train Epoch: 4 [2000/39785 (0%)]\tLoss: 14.684279\n",
      "Train Epoch: 4 [3000/39785 (0%)]\tLoss: 13.047579\n",
      "Train Epoch: 4 [4000/39785 (0%)]\tLoss: 13.079076\n",
      "Train Epoch: 4 [5000/39785 (0%)]\tLoss: 12.783484\n",
      "Train Epoch: 4 [6000/39785 (0%)]\tLoss: 11.441223\n",
      "Train Epoch: 4 [7000/39785 (0%)]\tLoss: 15.368904\n",
      "Train Epoch: 4 [8000/39785 (0%)]\tLoss: 14.415436\n",
      "Train Epoch: 4 [9000/39785 (0%)]\tLoss: 13.959956\n",
      "Train Epoch: 4 [10000/39785 (0%)]\tLoss: 15.608984\n",
      "Train Epoch: 4 [11000/39785 (0%)]\tLoss: 18.564438\n",
      "Train Epoch: 4 [12000/39785 (0%)]\tLoss: 12.584574\n",
      "Train Epoch: 4 [13000/39785 (0%)]\tLoss: 13.358888\n",
      "Train Epoch: 4 [14000/39785 (0%)]\tLoss: 19.024874\n",
      "Train Epoch: 4 [15000/39785 (0%)]\tLoss: 11.723083\n",
      "Train Epoch: 4 [16000/39785 (0%)]\tLoss: 14.940018\n",
      "Train Epoch: 4 [17000/39785 (0%)]\tLoss: 15.098281\n",
      "Train Epoch: 4 [18000/39785 (0%)]\tLoss: 15.852306\n",
      "Train Epoch: 4 [19000/39785 (0%)]\tLoss: 13.293898\n",
      "Train Epoch: 4 [20000/39785 (1%)]\tLoss: 14.608222\n",
      "Train Epoch: 4 [21000/39785 (1%)]\tLoss: 17.031429\n",
      "Train Epoch: 4 [22000/39785 (1%)]\tLoss: 14.810150\n",
      "Train Epoch: 4 [23000/39785 (1%)]\tLoss: 14.429428\n",
      "Train Epoch: 4 [24000/39785 (1%)]\tLoss: 12.196026\n",
      "Train Epoch: 4 [25000/39785 (1%)]\tLoss: 17.337013\n",
      "Train Epoch: 4 [26000/39785 (1%)]\tLoss: 14.951493\n",
      "Train Epoch: 4 [27000/39785 (1%)]\tLoss: 14.489878\n",
      "Train Epoch: 4 [28000/39785 (1%)]\tLoss: 15.878920\n",
      "Train Epoch: 4 [29000/39785 (1%)]\tLoss: 18.655558\n",
      "Train Epoch: 4 [30000/39785 (1%)]\tLoss: 15.128433\n",
      "Train Epoch: 4 [31000/39785 (1%)]\tLoss: 17.192083\n",
      "Train Epoch: 4 [32000/39785 (1%)]\tLoss: 14.414990\n",
      "Train Epoch: 4 [33000/39785 (1%)]\tLoss: 13.160789\n",
      "Train Epoch: 4 [34000/39785 (1%)]\tLoss: 13.383416\n",
      "Train Epoch: 4 [35000/39785 (1%)]\tLoss: 18.234623\n",
      "Train Epoch: 4 [36000/39785 (1%)]\tLoss: 14.625727\n",
      "Train Epoch: 4 [37000/39785 (1%)]\tLoss: 14.339396\n",
      "Train Epoch: 4 [38000/39785 (1%)]\tLoss: 11.980387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [39000/39785 (1%)]\tLoss: 15.258318\n",
      "Train Epoch: 5 [1000/39785 (0%)]\tLoss: 11.483993\n",
      "Train Epoch: 5 [2000/39785 (0%)]\tLoss: 11.006619\n",
      "Train Epoch: 5 [3000/39785 (0%)]\tLoss: 14.269030\n",
      "Train Epoch: 5 [4000/39785 (0%)]\tLoss: 11.494339\n",
      "Train Epoch: 5 [5000/39785 (0%)]\tLoss: 13.041487\n",
      "Train Epoch: 5 [6000/39785 (0%)]\tLoss: 13.576275\n",
      "Train Epoch: 5 [7000/39785 (0%)]\tLoss: 16.329958\n",
      "Train Epoch: 5 [8000/39785 (0%)]\tLoss: 11.608188\n",
      "Train Epoch: 5 [9000/39785 (0%)]\tLoss: 13.923944\n",
      "Train Epoch: 5 [10000/39785 (0%)]\tLoss: 12.059420\n",
      "Train Epoch: 5 [11000/39785 (0%)]\tLoss: 13.456617\n",
      "Train Epoch: 5 [12000/39785 (0%)]\tLoss: 10.243171\n",
      "Train Epoch: 5 [13000/39785 (0%)]\tLoss: 16.861450\n",
      "Train Epoch: 5 [14000/39785 (0%)]\tLoss: 15.189270\n",
      "Train Epoch: 5 [15000/39785 (0%)]\tLoss: 12.037784\n",
      "Train Epoch: 5 [16000/39785 (0%)]\tLoss: 14.140921\n",
      "Train Epoch: 5 [17000/39785 (0%)]\tLoss: 16.919897\n",
      "Train Epoch: 5 [18000/39785 (0%)]\tLoss: 15.057847\n",
      "Train Epoch: 5 [19000/39785 (0%)]\tLoss: 15.233223\n",
      "Train Epoch: 5 [20000/39785 (1%)]\tLoss: 11.172960\n",
      "Train Epoch: 5 [21000/39785 (1%)]\tLoss: 13.002768\n",
      "Train Epoch: 5 [22000/39785 (1%)]\tLoss: 12.861090\n",
      "Train Epoch: 5 [23000/39785 (1%)]\tLoss: 14.076733\n",
      "Train Epoch: 5 [24000/39785 (1%)]\tLoss: 13.180705\n",
      "Train Epoch: 5 [25000/39785 (1%)]\tLoss: 13.747004\n",
      "Train Epoch: 5 [26000/39785 (1%)]\tLoss: 13.453096\n",
      "Train Epoch: 5 [27000/39785 (1%)]\tLoss: 11.095353\n",
      "Train Epoch: 5 [28000/39785 (1%)]\tLoss: 14.730513\n",
      "Train Epoch: 5 [29000/39785 (1%)]\tLoss: 13.675060\n",
      "Train Epoch: 5 [30000/39785 (1%)]\tLoss: 14.144802\n",
      "Train Epoch: 5 [31000/39785 (1%)]\tLoss: 11.851130\n",
      "Train Epoch: 5 [32000/39785 (1%)]\tLoss: 16.965494\n",
      "Train Epoch: 5 [33000/39785 (1%)]\tLoss: 15.082075\n",
      "Train Epoch: 5 [34000/39785 (1%)]\tLoss: 14.993416\n",
      "Train Epoch: 5 [35000/39785 (1%)]\tLoss: 14.329552\n",
      "Train Epoch: 5 [36000/39785 (1%)]\tLoss: 13.169136\n",
      "Train Epoch: 5 [37000/39785 (1%)]\tLoss: 16.578281\n",
      "Train Epoch: 5 [38000/39785 (1%)]\tLoss: 18.812746\n",
      "Train Epoch: 5 [39000/39785 (1%)]\tLoss: 12.950813\n",
      "Train Epoch: 6 [1000/39785 (0%)]\tLoss: 14.393819\n",
      "Train Epoch: 6 [2000/39785 (0%)]\tLoss: 13.829530\n",
      "Train Epoch: 6 [3000/39785 (0%)]\tLoss: 11.947329\n",
      "Train Epoch: 6 [4000/39785 (0%)]\tLoss: 10.446830\n",
      "Train Epoch: 6 [5000/39785 (0%)]\tLoss: 14.410204\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-268-5ac95fa729dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fifth_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecr_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# test(model_hard, device, test_set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-265-1fbff2ecd3cb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;31m# loss_fn = nn.MSELoss(reduction='sum')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# loss = loss_fn(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-265-1fbff2ecd3cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/se3cnn-0.0.0-py3.7.egg/se3cnn/convolution.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(1)\n",
    "\n",
    "model_fifth_order = EquiNet().to(device)\n",
    "learning_rate = 5e-3\n",
    "optimizer = torch.optim.Adam(model_fifth_order.parameters(), lr=learning_rate)\n",
    "\n",
    "per_epoch = 10\n",
    "decr_rate = 0.99\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model_fifth_order, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate)\n",
    "    # test(model_hard, device, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_custom_loss(output, target):\n",
    "    order_out = output[:, 0 : NUM_CLASSES]\n",
    "    order_target = target[:, 0 : 1].type(torch.LongTensor).squeeze_()\n",
    "    axis_out = output[:, NUM_CLASSES : NUM_CLASSES + 6]\n",
    "    axis_target = target[:, 1 : 7]\n",
    "\n",
    "    loss = 1 * nn.CrossEntropyLoss()(order_out, order_target) + nn.MSELoss(reduction='sum')(axis_out, axis_target)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = SE3Convolution(repr_in_1, repr_out_1, size=4)\n",
    "        self.pool1 = nn.AvgPool3d(pool_size, pool_stride)\n",
    "        self.conv2 = SE3Convolution(repr_in_2, repr_out_2, size=4)\n",
    "        self.pool2 = nn.AvgPool3d(pool_size, pool_stride)\n",
    "        \n",
    "        self.lin1 = nn.Linear(n_input_1, n_output_1)\n",
    "        self.lin2 = nn.Linear(n_output_1, NUM_CLASSES+6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.conv1(x))\n",
    "        x = self.pool2(self.conv2(x))\n",
    "        x = x.view(batch_size,-1) \n",
    "        x = F.leaky_relu(self.lin1(x))\n",
    "        return self.lin2(x)\n",
    "    \n",
    "    \n",
    "def train(model, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate):\n",
    "    model.train()\n",
    "    flag = True\n",
    "    new_epoch = True\n",
    "    \n",
    "    if new_epoch:\n",
    "        batch_idx = 1\n",
    "        new_epoch = False\n",
    "        data, target, _ = train_set.next_batch(batch_size)\n",
    "        data = torch.from_numpy(data.reshape(batch_size,1,24,24,24)).type(torch.FloatTensor)\n",
    "        target = torch.from_numpy(target.reshape(batch_size,-1)).type(torch.FloatTensor)\n",
    "        cnt = epoch // per_epoch\n",
    "        if ((epoch+1) // per_epoch > cnt) and flag:\n",
    "            lr = 0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            lr *= decr_rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            flag = False\n",
    "        if ((epoch+1) // per_epoch <= cnt):\n",
    "            flag = True\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss_fn = nn.MSELoss(reduction='sum')\n",
    "        # loss = loss_fn(output, target)\n",
    "        loss = weighted_custom_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    while (train_set._index_in_epoch + batch_size) < train_set._num_examples:\n",
    "        batch_idx += 1\n",
    "        data, target, _ = train_set.next_batch(batch_size)\n",
    "        data = torch.from_numpy(data.reshape(batch_size,1,24,24,24)).type(torch.FloatTensor)\n",
    "        target = torch.from_numpy(target.reshape(batch_size,-1)).type(torch.FloatTensor)\n",
    "        cnt = epoch // per_epoch\n",
    "        if ((epoch+1) // per_epoch > cnt) and flag:\n",
    "            lr = 0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            lr *= decr_rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            flag = False\n",
    "        if ((epoch+1) // per_epoch <= cnt):\n",
    "            flag = True\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss_fn = nn.MSELoss(reduction='sum')\n",
    "        # loss = loss_fn(output, target)\n",
    "        loss = weighted_custom_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * batch_size, train_set._num_examples,\n",
    "                100. * batch_idx / train_set._num_examples, loss.item()))\n",
    "\n",
    "def test(model, device, test_set):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_set:\n",
    "            output = model(data)\n",
    "            loss_fn = nn.MSELoss(reduction='sum')\n",
    "            test_loss += loss_fn(output, target) \n",
    "            # pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += int(torch.argmax(output) == torch.argmax(target))\n",
    "\n",
    "    test_loss /= len(test_set)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_set),\n",
    "        100. * correct / len(test_set)))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_in_1 = [(1,0)]\n",
    "repr_out_1 = [(2,0),(2,1),(2,2),(2,3),(2,4),(2,5),(2,6),(2,7),(2,8),(2,9)]\n",
    "repr_in_2 = [(2,0),(2,1),(2,2),(2,3),(2,4),(2,5),(2,6),(2,7),(2,8),(2,9)]\n",
    "repr_out_2 = [(1,0),(2,1),(2,2),(2,3)]\n",
    "size = 4\n",
    "activation = (None, F.leaky_relu)\n",
    "pool_size = 2\n",
    "pool_stride = 2\n",
    "bias = True\n",
    "\n",
    "n_input_1 = 837\n",
    "n_output_1 = 420 \n",
    "n_output_2 = 40\n",
    "\n",
    "batch_size = 100\n",
    "prob = 0.5\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../deepSymmetry/data/fromScripts/dataReady0\n",
      "Extracting ../deepSymmetry/data/fromScripts/dataReady0_label\n",
      "(39785, 13824)\n"
     ]
    }
   ],
   "source": [
    "train_name = '../deepSymmetry/data/fromScripts/dataReady0'\n",
    "train_set = load_data.read_data_set(train_name, dtype=dtypes.float16, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1000/39785 (0%)]\tLoss: 36.971638\n",
      "Train Epoch: 1 [2000/39785 (0%)]\tLoss: 27.032562\n",
      "Train Epoch: 1 [3000/39785 (0%)]\tLoss: 23.561869\n",
      "Train Epoch: 1 [4000/39785 (0%)]\tLoss: 24.894772\n",
      "Train Epoch: 1 [5000/39785 (0%)]\tLoss: 20.401770\n",
      "Train Epoch: 1 [6000/39785 (0%)]\tLoss: 24.369877\n",
      "Train Epoch: 1 [7000/39785 (0%)]\tLoss: 21.327436\n",
      "Train Epoch: 1 [8000/39785 (0%)]\tLoss: 18.343349\n",
      "Train Epoch: 1 [9000/39785 (0%)]\tLoss: 21.651529\n",
      "Train Epoch: 1 [10000/39785 (0%)]\tLoss: 20.213943\n",
      "Train Epoch: 1 [11000/39785 (0%)]\tLoss: 19.364433\n",
      "Train Epoch: 1 [12000/39785 (0%)]\tLoss: 18.184734\n",
      "Train Epoch: 1 [13000/39785 (0%)]\tLoss: 19.650126\n",
      "Train Epoch: 1 [14000/39785 (0%)]\tLoss: 19.353704\n",
      "Train Epoch: 1 [15000/39785 (0%)]\tLoss: 19.617815\n",
      "Train Epoch: 1 [16000/39785 (0%)]\tLoss: 18.656876\n",
      "Train Epoch: 1 [17000/39785 (0%)]\tLoss: 18.036095\n",
      "Train Epoch: 1 [18000/39785 (0%)]\tLoss: 15.091098\n",
      "Train Epoch: 1 [19000/39785 (0%)]\tLoss: 21.126528\n",
      "Train Epoch: 1 [20000/39785 (1%)]\tLoss: 18.754930\n",
      "Train Epoch: 1 [21000/39785 (1%)]\tLoss: 15.746633\n",
      "Train Epoch: 1 [22000/39785 (1%)]\tLoss: 18.449741\n",
      "Train Epoch: 1 [23000/39785 (1%)]\tLoss: 15.147270\n",
      "Train Epoch: 1 [24000/39785 (1%)]\tLoss: 22.901356\n",
      "Train Epoch: 1 [25000/39785 (1%)]\tLoss: 15.273707\n",
      "Train Epoch: 1 [26000/39785 (1%)]\tLoss: 15.519489\n",
      "Train Epoch: 1 [27000/39785 (1%)]\tLoss: 12.778928\n",
      "Train Epoch: 1 [28000/39785 (1%)]\tLoss: 16.062729\n",
      "Train Epoch: 1 [29000/39785 (1%)]\tLoss: 13.259072\n",
      "Train Epoch: 1 [30000/39785 (1%)]\tLoss: 17.941521\n",
      "Train Epoch: 1 [31000/39785 (1%)]\tLoss: 16.880930\n",
      "Train Epoch: 1 [32000/39785 (1%)]\tLoss: 18.749519\n",
      "Train Epoch: 1 [33000/39785 (1%)]\tLoss: 16.653097\n",
      "Train Epoch: 1 [34000/39785 (1%)]\tLoss: 15.431999\n",
      "Train Epoch: 1 [35000/39785 (1%)]\tLoss: 14.961232\n",
      "Train Epoch: 1 [36000/39785 (1%)]\tLoss: 15.771474\n",
      "Train Epoch: 1 [37000/39785 (1%)]\tLoss: 14.343337\n",
      "Train Epoch: 1 [38000/39785 (1%)]\tLoss: 18.089851\n",
      "Train Epoch: 1 [39000/39785 (1%)]\tLoss: 18.118507\n",
      "Train Epoch: 2 [1000/39785 (0%)]\tLoss: 12.588966\n",
      "Train Epoch: 2 [2000/39785 (0%)]\tLoss: 16.970194\n",
      "Train Epoch: 2 [3000/39785 (0%)]\tLoss: 16.498365\n",
      "Train Epoch: 2 [4000/39785 (0%)]\tLoss: 14.479910\n",
      "Train Epoch: 2 [5000/39785 (0%)]\tLoss: 13.111893\n",
      "Train Epoch: 2 [6000/39785 (0%)]\tLoss: 10.924115\n",
      "Train Epoch: 2 [7000/39785 (0%)]\tLoss: 14.430315\n",
      "Train Epoch: 2 [8000/39785 (0%)]\tLoss: 13.925749\n",
      "Train Epoch: 2 [9000/39785 (0%)]\tLoss: 13.224945\n",
      "Train Epoch: 2 [10000/39785 (0%)]\tLoss: 17.901197\n",
      "Train Epoch: 2 [11000/39785 (0%)]\tLoss: 13.590507\n",
      "Train Epoch: 2 [12000/39785 (0%)]\tLoss: 17.518854\n",
      "Train Epoch: 2 [13000/39785 (0%)]\tLoss: 14.745496\n",
      "Train Epoch: 2 [14000/39785 (0%)]\tLoss: 15.101554\n",
      "Train Epoch: 2 [15000/39785 (0%)]\tLoss: 13.186643\n",
      "Train Epoch: 2 [16000/39785 (0%)]\tLoss: 18.352238\n",
      "Train Epoch: 2 [17000/39785 (0%)]\tLoss: 15.087712\n",
      "Train Epoch: 2 [18000/39785 (0%)]\tLoss: 14.600554\n",
      "Train Epoch: 2 [19000/39785 (0%)]\tLoss: 14.804815\n",
      "Train Epoch: 2 [20000/39785 (1%)]\tLoss: 15.437190\n",
      "Train Epoch: 2 [21000/39785 (1%)]\tLoss: 18.247398\n",
      "Train Epoch: 2 [22000/39785 (1%)]\tLoss: 15.008407\n",
      "Train Epoch: 2 [23000/39785 (1%)]\tLoss: 13.677311\n",
      "Train Epoch: 2 [24000/39785 (1%)]\tLoss: 12.493389\n",
      "Train Epoch: 2 [25000/39785 (1%)]\tLoss: 13.146784\n",
      "Train Epoch: 2 [26000/39785 (1%)]\tLoss: 17.418783\n",
      "Train Epoch: 2 [27000/39785 (1%)]\tLoss: 13.954413\n",
      "Train Epoch: 2 [28000/39785 (1%)]\tLoss: 10.981833\n",
      "Train Epoch: 2 [29000/39785 (1%)]\tLoss: 16.115089\n",
      "Train Epoch: 2 [30000/39785 (1%)]\tLoss: 18.193089\n",
      "Train Epoch: 2 [31000/39785 (1%)]\tLoss: 14.713193\n",
      "Train Epoch: 2 [32000/39785 (1%)]\tLoss: 14.823102\n",
      "Train Epoch: 2 [33000/39785 (1%)]\tLoss: 13.637030\n",
      "Train Epoch: 2 [34000/39785 (1%)]\tLoss: 13.124445\n",
      "Train Epoch: 2 [35000/39785 (1%)]\tLoss: 14.137985\n",
      "Train Epoch: 2 [36000/39785 (1%)]\tLoss: 16.766571\n",
      "Train Epoch: 2 [37000/39785 (1%)]\tLoss: 16.016396\n",
      "Train Epoch: 2 [38000/39785 (1%)]\tLoss: 14.733309\n",
      "Train Epoch: 2 [39000/39785 (1%)]\tLoss: 12.752810\n",
      "Train Epoch: 3 [1000/39785 (0%)]\tLoss: 11.923238\n",
      "Train Epoch: 3 [2000/39785 (0%)]\tLoss: 15.603017\n",
      "Train Epoch: 3 [3000/39785 (0%)]\tLoss: 11.906375\n",
      "Train Epoch: 3 [4000/39785 (0%)]\tLoss: 14.684380\n",
      "Train Epoch: 3 [5000/39785 (0%)]\tLoss: 10.788286\n",
      "Train Epoch: 3 [6000/39785 (0%)]\tLoss: 17.304668\n",
      "Train Epoch: 3 [7000/39785 (0%)]\tLoss: 17.302103\n",
      "Train Epoch: 3 [8000/39785 (0%)]\tLoss: 14.402951\n",
      "Train Epoch: 3 [9000/39785 (0%)]\tLoss: 11.255808\n",
      "Train Epoch: 3 [10000/39785 (0%)]\tLoss: 11.478432\n",
      "Train Epoch: 3 [11000/39785 (0%)]\tLoss: 14.629057\n",
      "Train Epoch: 3 [12000/39785 (0%)]\tLoss: 10.979990\n",
      "Train Epoch: 3 [13000/39785 (0%)]\tLoss: 10.961370\n",
      "Train Epoch: 3 [14000/39785 (0%)]\tLoss: 10.685287\n",
      "Train Epoch: 3 [15000/39785 (0%)]\tLoss: 13.877472\n",
      "Train Epoch: 3 [16000/39785 (0%)]\tLoss: 15.799727\n",
      "Train Epoch: 3 [17000/39785 (0%)]\tLoss: 11.775331\n",
      "Train Epoch: 3 [18000/39785 (0%)]\tLoss: 14.042850\n",
      "Train Epoch: 3 [19000/39785 (0%)]\tLoss: 16.125055\n",
      "Train Epoch: 3 [20000/39785 (1%)]\tLoss: 11.762181\n",
      "Train Epoch: 3 [21000/39785 (1%)]\tLoss: 11.086044\n",
      "Train Epoch: 3 [22000/39785 (1%)]\tLoss: 13.813207\n",
      "Train Epoch: 3 [23000/39785 (1%)]\tLoss: 15.930159\n",
      "Train Epoch: 3 [24000/39785 (1%)]\tLoss: 14.643330\n",
      "Train Epoch: 3 [25000/39785 (1%)]\tLoss: 14.129863\n",
      "Train Epoch: 3 [26000/39785 (1%)]\tLoss: 15.209128\n",
      "Train Epoch: 3 [27000/39785 (1%)]\tLoss: 10.983301\n",
      "Train Epoch: 3 [28000/39785 (1%)]\tLoss: 13.370661\n",
      "Train Epoch: 3 [29000/39785 (1%)]\tLoss: 13.439129\n",
      "Train Epoch: 3 [30000/39785 (1%)]\tLoss: 13.512231\n",
      "Train Epoch: 3 [31000/39785 (1%)]\tLoss: 13.101620\n",
      "Train Epoch: 3 [32000/39785 (1%)]\tLoss: 13.410427\n",
      "Train Epoch: 3 [33000/39785 (1%)]\tLoss: 15.154329\n",
      "Train Epoch: 3 [34000/39785 (1%)]\tLoss: 14.272800\n",
      "Train Epoch: 3 [35000/39785 (1%)]\tLoss: 12.894032\n",
      "Train Epoch: 3 [36000/39785 (1%)]\tLoss: 13.722972\n",
      "Train Epoch: 3 [37000/39785 (1%)]\tLoss: 12.499772\n",
      "Train Epoch: 3 [38000/39785 (1%)]\tLoss: 12.295725\n",
      "Train Epoch: 3 [39000/39785 (1%)]\tLoss: 13.722796\n",
      "Train Epoch: 4 [1000/39785 (0%)]\tLoss: 12.145130\n",
      "Train Epoch: 4 [2000/39785 (0%)]\tLoss: 12.450748\n",
      "Train Epoch: 4 [3000/39785 (0%)]\tLoss: 10.774899\n",
      "Train Epoch: 4 [4000/39785 (0%)]\tLoss: 9.745061\n",
      "Train Epoch: 4 [5000/39785 (0%)]\tLoss: 10.678366\n",
      "Train Epoch: 4 [6000/39785 (0%)]\tLoss: 8.262537\n",
      "Train Epoch: 4 [7000/39785 (0%)]\tLoss: 13.650915\n",
      "Train Epoch: 4 [8000/39785 (0%)]\tLoss: 11.274448\n",
      "Train Epoch: 4 [9000/39785 (0%)]\tLoss: 11.521769\n",
      "Train Epoch: 4 [10000/39785 (0%)]\tLoss: 13.425657\n",
      "Train Epoch: 4 [11000/39785 (0%)]\tLoss: 15.264997\n",
      "Train Epoch: 4 [12000/39785 (0%)]\tLoss: 11.004498\n",
      "Train Epoch: 4 [13000/39785 (0%)]\tLoss: 11.154139\n",
      "Train Epoch: 4 [14000/39785 (0%)]\tLoss: 14.937483\n",
      "Train Epoch: 4 [15000/39785 (0%)]\tLoss: 9.728086\n",
      "Train Epoch: 4 [16000/39785 (0%)]\tLoss: 11.895742\n",
      "Train Epoch: 4 [17000/39785 (0%)]\tLoss: 13.909657\n",
      "Train Epoch: 4 [18000/39785 (0%)]\tLoss: 13.635286\n",
      "Train Epoch: 4 [19000/39785 (0%)]\tLoss: 10.710316\n",
      "Train Epoch: 4 [20000/39785 (1%)]\tLoss: 11.747253\n",
      "Train Epoch: 4 [21000/39785 (1%)]\tLoss: 14.503221\n",
      "Train Epoch: 4 [22000/39785 (1%)]\tLoss: 13.219482\n",
      "Train Epoch: 4 [23000/39785 (1%)]\tLoss: 11.969779\n",
      "Train Epoch: 4 [24000/39785 (1%)]\tLoss: 9.490429\n",
      "Train Epoch: 4 [25000/39785 (1%)]\tLoss: 14.128164\n",
      "Train Epoch: 4 [26000/39785 (1%)]\tLoss: 13.377362\n",
      "Train Epoch: 4 [27000/39785 (1%)]\tLoss: 11.964520\n",
      "Train Epoch: 4 [28000/39785 (1%)]\tLoss: 14.152924\n",
      "Train Epoch: 4 [29000/39785 (1%)]\tLoss: 15.887041\n",
      "Train Epoch: 4 [30000/39785 (1%)]\tLoss: 12.580455\n",
      "Train Epoch: 4 [31000/39785 (1%)]\tLoss: 15.299199\n",
      "Train Epoch: 4 [32000/39785 (1%)]\tLoss: 12.510704\n",
      "Train Epoch: 4 [33000/39785 (1%)]\tLoss: 10.850352\n",
      "Train Epoch: 4 [34000/39785 (1%)]\tLoss: 10.747472\n",
      "Train Epoch: 4 [35000/39785 (1%)]\tLoss: 16.138680\n",
      "Train Epoch: 4 [36000/39785 (1%)]\tLoss: 12.133453\n",
      "Train Epoch: 4 [37000/39785 (1%)]\tLoss: 13.109976\n",
      "Train Epoch: 4 [38000/39785 (1%)]\tLoss: 9.685691\n",
      "Train Epoch: 4 [39000/39785 (1%)]\tLoss: 13.553909\n",
      "Train Epoch: 5 [1000/39785 (0%)]\tLoss: 9.499995\n",
      "Train Epoch: 5 [2000/39785 (0%)]\tLoss: 8.077560\n",
      "Train Epoch: 5 [3000/39785 (0%)]\tLoss: 11.668694\n",
      "Train Epoch: 5 [4000/39785 (0%)]\tLoss: 8.506262\n",
      "Train Epoch: 5 [5000/39785 (0%)]\tLoss: 10.437169\n",
      "Train Epoch: 5 [6000/39785 (0%)]\tLoss: 10.891011\n",
      "Train Epoch: 5 [7000/39785 (0%)]\tLoss: 12.572106\n",
      "Train Epoch: 5 [8000/39785 (0%)]\tLoss: 8.317531\n",
      "Train Epoch: 5 [9000/39785 (0%)]\tLoss: 12.834187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [10000/39785 (0%)]\tLoss: 10.510989\n",
      "Train Epoch: 5 [11000/39785 (0%)]\tLoss: 10.718228\n",
      "Train Epoch: 5 [12000/39785 (0%)]\tLoss: 7.922806\n",
      "Train Epoch: 5 [13000/39785 (0%)]\tLoss: 14.894974\n",
      "Train Epoch: 5 [14000/39785 (0%)]\tLoss: 11.784818\n",
      "Train Epoch: 5 [15000/39785 (0%)]\tLoss: 9.821644\n",
      "Train Epoch: 5 [16000/39785 (0%)]\tLoss: 10.861672\n",
      "Train Epoch: 5 [17000/39785 (0%)]\tLoss: 14.176741\n",
      "Train Epoch: 5 [18000/39785 (0%)]\tLoss: 12.759933\n",
      "Train Epoch: 5 [19000/39785 (0%)]\tLoss: 12.121784\n",
      "Train Epoch: 5 [20000/39785 (1%)]\tLoss: 9.804792\n",
      "Train Epoch: 5 [21000/39785 (1%)]\tLoss: 11.179785\n",
      "Train Epoch: 5 [22000/39785 (1%)]\tLoss: 10.303892\n",
      "Train Epoch: 5 [23000/39785 (1%)]\tLoss: 11.660330\n",
      "Train Epoch: 5 [24000/39785 (1%)]\tLoss: 11.954089\n",
      "Train Epoch: 5 [25000/39785 (1%)]\tLoss: 11.476882\n",
      "Train Epoch: 5 [26000/39785 (1%)]\tLoss: 10.912248\n",
      "Train Epoch: 5 [27000/39785 (1%)]\tLoss: 8.913859\n",
      "Train Epoch: 5 [28000/39785 (1%)]\tLoss: 12.401588\n",
      "Train Epoch: 5 [29000/39785 (1%)]\tLoss: 11.974815\n",
      "Train Epoch: 5 [30000/39785 (1%)]\tLoss: 12.300537\n",
      "Train Epoch: 5 [31000/39785 (1%)]\tLoss: 10.249289\n",
      "Train Epoch: 5 [32000/39785 (1%)]\tLoss: 12.770573\n",
      "Train Epoch: 5 [33000/39785 (1%)]\tLoss: 12.384429\n",
      "Train Epoch: 5 [34000/39785 (1%)]\tLoss: 12.398878\n",
      "Train Epoch: 5 [35000/39785 (1%)]\tLoss: 12.382504\n",
      "Train Epoch: 5 [36000/39785 (1%)]\tLoss: 11.044916\n",
      "Train Epoch: 5 [37000/39785 (1%)]\tLoss: 14.237926\n",
      "Train Epoch: 5 [38000/39785 (1%)]\tLoss: 15.191333\n",
      "Train Epoch: 5 [39000/39785 (1%)]\tLoss: 9.942471\n",
      "Train Epoch: 6 [1000/39785 (0%)]\tLoss: 11.360165\n",
      "Train Epoch: 6 [2000/39785 (0%)]\tLoss: 10.613295\n",
      "Train Epoch: 6 [3000/39785 (0%)]\tLoss: 8.799349\n",
      "Train Epoch: 6 [4000/39785 (0%)]\tLoss: 9.517645\n",
      "Train Epoch: 6 [5000/39785 (0%)]\tLoss: 11.501777\n",
      "Train Epoch: 6 [6000/39785 (0%)]\tLoss: 11.746693\n",
      "Train Epoch: 6 [7000/39785 (0%)]\tLoss: 9.773201\n",
      "Train Epoch: 6 [8000/39785 (0%)]\tLoss: 12.971827\n",
      "Train Epoch: 6 [9000/39785 (0%)]\tLoss: 9.029795\n",
      "Train Epoch: 6 [10000/39785 (0%)]\tLoss: 12.205933\n",
      "Train Epoch: 6 [11000/39785 (0%)]\tLoss: 11.854642\n",
      "Train Epoch: 6 [12000/39785 (0%)]\tLoss: 9.876003\n",
      "Train Epoch: 6 [13000/39785 (0%)]\tLoss: 13.527818\n",
      "Train Epoch: 6 [14000/39785 (0%)]\tLoss: 10.750508\n",
      "Train Epoch: 6 [15000/39785 (0%)]\tLoss: 9.185160\n",
      "Train Epoch: 6 [16000/39785 (0%)]\tLoss: 8.096805\n",
      "Train Epoch: 6 [17000/39785 (0%)]\tLoss: 10.816500\n",
      "Train Epoch: 6 [18000/39785 (0%)]\tLoss: 10.450933\n",
      "Train Epoch: 6 [19000/39785 (0%)]\tLoss: 8.708715\n",
      "Train Epoch: 6 [20000/39785 (1%)]\tLoss: 8.108576\n",
      "Train Epoch: 6 [21000/39785 (1%)]\tLoss: 11.834053\n",
      "Train Epoch: 6 [22000/39785 (1%)]\tLoss: 10.084846\n",
      "Train Epoch: 6 [23000/39785 (1%)]\tLoss: 9.992413\n",
      "Train Epoch: 6 [24000/39785 (1%)]\tLoss: 11.066447\n",
      "Train Epoch: 6 [25000/39785 (1%)]\tLoss: 14.882278\n",
      "Train Epoch: 6 [26000/39785 (1%)]\tLoss: 15.135458\n",
      "Train Epoch: 6 [27000/39785 (1%)]\tLoss: 10.456391\n",
      "Train Epoch: 6 [28000/39785 (1%)]\tLoss: 11.792235\n",
      "Train Epoch: 6 [29000/39785 (1%)]\tLoss: 12.838940\n",
      "Train Epoch: 6 [30000/39785 (1%)]\tLoss: 10.666804\n",
      "Train Epoch: 6 [31000/39785 (1%)]\tLoss: 14.421374\n",
      "Train Epoch: 6 [32000/39785 (1%)]\tLoss: 8.986191\n",
      "Train Epoch: 6 [33000/39785 (1%)]\tLoss: 11.928389\n",
      "Train Epoch: 6 [34000/39785 (1%)]\tLoss: 12.314631\n",
      "Train Epoch: 6 [35000/39785 (1%)]\tLoss: 8.228506\n",
      "Train Epoch: 6 [36000/39785 (1%)]\tLoss: 9.058852\n",
      "Train Epoch: 6 [37000/39785 (1%)]\tLoss: 12.407178\n",
      "Train Epoch: 6 [38000/39785 (1%)]\tLoss: 12.837334\n",
      "Train Epoch: 6 [39000/39785 (1%)]\tLoss: 12.955566\n",
      "Train Epoch: 7 [1000/39785 (0%)]\tLoss: 9.665354\n",
      "Train Epoch: 7 [2000/39785 (0%)]\tLoss: 11.887804\n",
      "Train Epoch: 7 [3000/39785 (0%)]\tLoss: 8.485218\n",
      "Train Epoch: 7 [4000/39785 (0%)]\tLoss: 11.102291\n",
      "Train Epoch: 7 [5000/39785 (0%)]\tLoss: 10.360838\n",
      "Train Epoch: 7 [6000/39785 (0%)]\tLoss: 13.905516\n",
      "Train Epoch: 7 [7000/39785 (0%)]\tLoss: 9.690752\n",
      "Train Epoch: 7 [8000/39785 (0%)]\tLoss: 10.247813\n",
      "Train Epoch: 7 [9000/39785 (0%)]\tLoss: 12.035638\n",
      "Train Epoch: 7 [10000/39785 (0%)]\tLoss: 14.546378\n",
      "Train Epoch: 7 [11000/39785 (0%)]\tLoss: 9.816586\n",
      "Train Epoch: 7 [12000/39785 (0%)]\tLoss: 11.987326\n",
      "Train Epoch: 7 [13000/39785 (0%)]\tLoss: 15.266471\n",
      "Train Epoch: 7 [14000/39785 (0%)]\tLoss: 11.124205\n",
      "Train Epoch: 7 [15000/39785 (0%)]\tLoss: 10.263285\n",
      "Train Epoch: 7 [16000/39785 (0%)]\tLoss: 12.559507\n",
      "Train Epoch: 7 [17000/39785 (0%)]\tLoss: 9.651829\n",
      "Train Epoch: 7 [18000/39785 (0%)]\tLoss: 12.169521\n",
      "Train Epoch: 7 [19000/39785 (0%)]\tLoss: 12.441956\n",
      "Train Epoch: 7 [20000/39785 (1%)]\tLoss: 9.858644\n",
      "Train Epoch: 7 [21000/39785 (1%)]\tLoss: 15.981798\n",
      "Train Epoch: 7 [22000/39785 (1%)]\tLoss: 9.444729\n",
      "Train Epoch: 7 [23000/39785 (1%)]\tLoss: 9.608633\n",
      "Train Epoch: 7 [24000/39785 (1%)]\tLoss: 8.842941\n",
      "Train Epoch: 7 [25000/39785 (1%)]\tLoss: 12.961447\n",
      "Train Epoch: 7 [26000/39785 (1%)]\tLoss: 11.668109\n",
      "Train Epoch: 7 [27000/39785 (1%)]\tLoss: 11.362700\n",
      "Train Epoch: 7 [28000/39785 (1%)]\tLoss: 10.600719\n",
      "Train Epoch: 7 [29000/39785 (1%)]\tLoss: 10.574531\n",
      "Train Epoch: 7 [30000/39785 (1%)]\tLoss: 11.241688\n",
      "Train Epoch: 7 [31000/39785 (1%)]\tLoss: 13.521992\n",
      "Train Epoch: 7 [32000/39785 (1%)]\tLoss: 11.266159\n",
      "Train Epoch: 7 [33000/39785 (1%)]\tLoss: 8.645132\n",
      "Train Epoch: 7 [34000/39785 (1%)]\tLoss: 9.041847\n",
      "Train Epoch: 7 [35000/39785 (1%)]\tLoss: 10.975681\n",
      "Train Epoch: 7 [36000/39785 (1%)]\tLoss: 11.872229\n",
      "Train Epoch: 7 [37000/39785 (1%)]\tLoss: 10.306356\n",
      "Train Epoch: 7 [38000/39785 (1%)]\tLoss: 10.260798\n",
      "Train Epoch: 7 [39000/39785 (1%)]\tLoss: 10.566804\n",
      "Train Epoch: 8 [1000/39785 (0%)]\tLoss: 7.668596\n",
      "Train Epoch: 8 [2000/39785 (0%)]\tLoss: 12.852792\n",
      "Train Epoch: 8 [3000/39785 (0%)]\tLoss: 11.590486\n",
      "Train Epoch: 8 [4000/39785 (0%)]\tLoss: 7.721113\n",
      "Train Epoch: 8 [5000/39785 (0%)]\tLoss: 7.915934\n",
      "Train Epoch: 8 [6000/39785 (0%)]\tLoss: 9.346263\n",
      "Train Epoch: 8 [7000/39785 (0%)]\tLoss: 9.957869\n",
      "Train Epoch: 8 [8000/39785 (0%)]\tLoss: 10.502193\n",
      "Train Epoch: 8 [9000/39785 (0%)]\tLoss: 8.134409\n",
      "Train Epoch: 8 [10000/39785 (0%)]\tLoss: 9.348130\n",
      "Train Epoch: 8 [11000/39785 (0%)]\tLoss: 11.459622\n",
      "Train Epoch: 8 [12000/39785 (0%)]\tLoss: 11.763407\n",
      "Train Epoch: 8 [13000/39785 (0%)]\tLoss: 10.096090\n",
      "Train Epoch: 8 [14000/39785 (0%)]\tLoss: 8.143514\n",
      "Train Epoch: 8 [15000/39785 (0%)]\tLoss: 9.639771\n",
      "Train Epoch: 8 [16000/39785 (0%)]\tLoss: 11.888204\n",
      "Train Epoch: 8 [17000/39785 (0%)]\tLoss: 10.137979\n",
      "Train Epoch: 8 [18000/39785 (0%)]\tLoss: 10.218756\n",
      "Train Epoch: 8 [19000/39785 (0%)]\tLoss: 8.989399\n",
      "Train Epoch: 8 [20000/39785 (1%)]\tLoss: 8.507615\n",
      "Train Epoch: 8 [21000/39785 (1%)]\tLoss: 10.727369\n",
      "Train Epoch: 8 [22000/39785 (1%)]\tLoss: 11.529354\n",
      "Train Epoch: 8 [23000/39785 (1%)]\tLoss: 10.772899\n",
      "Train Epoch: 8 [24000/39785 (1%)]\tLoss: 11.681362\n",
      "Train Epoch: 8 [25000/39785 (1%)]\tLoss: 12.268296\n",
      "Train Epoch: 8 [26000/39785 (1%)]\tLoss: 10.409933\n",
      "Train Epoch: 8 [27000/39785 (1%)]\tLoss: 11.178635\n",
      "Train Epoch: 8 [28000/39785 (1%)]\tLoss: 12.306271\n",
      "Train Epoch: 8 [29000/39785 (1%)]\tLoss: 9.777649\n",
      "Train Epoch: 8 [30000/39785 (1%)]\tLoss: 9.233191\n",
      "Train Epoch: 8 [31000/39785 (1%)]\tLoss: 10.224838\n",
      "Train Epoch: 8 [32000/39785 (1%)]\tLoss: 9.285387\n",
      "Train Epoch: 8 [33000/39785 (1%)]\tLoss: 12.575866\n",
      "Train Epoch: 8 [34000/39785 (1%)]\tLoss: 9.423273\n",
      "Train Epoch: 8 [35000/39785 (1%)]\tLoss: 8.901126\n",
      "Train Epoch: 8 [36000/39785 (1%)]\tLoss: 10.640512\n",
      "Train Epoch: 8 [37000/39785 (1%)]\tLoss: 11.008687\n",
      "Train Epoch: 8 [38000/39785 (1%)]\tLoss: 11.244993\n",
      "Train Epoch: 8 [39000/39785 (1%)]\tLoss: 9.305240\n",
      "Train Epoch: 9 [1000/39785 (0%)]\tLoss: 9.011935\n",
      "Train Epoch: 9 [2000/39785 (0%)]\tLoss: 12.181772\n",
      "Train Epoch: 9 [3000/39785 (0%)]\tLoss: 11.532679\n",
      "Train Epoch: 9 [4000/39785 (0%)]\tLoss: 8.302569\n",
      "Train Epoch: 9 [5000/39785 (0%)]\tLoss: 9.121655\n",
      "Train Epoch: 9 [6000/39785 (0%)]\tLoss: 8.942342\n",
      "Train Epoch: 9 [7000/39785 (0%)]\tLoss: 12.704951\n",
      "Train Epoch: 9 [8000/39785 (0%)]\tLoss: 9.802648\n",
      "Train Epoch: 9 [9000/39785 (0%)]\tLoss: 10.324233\n",
      "Train Epoch: 9 [10000/39785 (0%)]\tLoss: 10.772277\n",
      "Train Epoch: 9 [11000/39785 (0%)]\tLoss: 6.911510\n",
      "Train Epoch: 9 [12000/39785 (0%)]\tLoss: 7.659304\n",
      "Train Epoch: 9 [13000/39785 (0%)]\tLoss: 8.318600\n",
      "Train Epoch: 9 [14000/39785 (0%)]\tLoss: 11.297739\n",
      "Train Epoch: 9 [15000/39785 (0%)]\tLoss: 10.303308\n",
      "Train Epoch: 9 [16000/39785 (0%)]\tLoss: 9.388419\n",
      "Train Epoch: 9 [17000/39785 (0%)]\tLoss: 9.416415\n",
      "Train Epoch: 9 [18000/39785 (0%)]\tLoss: 10.604971\n",
      "Train Epoch: 9 [19000/39785 (0%)]\tLoss: 11.132648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [20000/39785 (1%)]\tLoss: 9.403354\n",
      "Train Epoch: 9 [21000/39785 (1%)]\tLoss: 7.567673\n",
      "Train Epoch: 9 [22000/39785 (1%)]\tLoss: 7.521990\n",
      "Train Epoch: 9 [23000/39785 (1%)]\tLoss: 10.357711\n",
      "Train Epoch: 9 [24000/39785 (1%)]\tLoss: 10.111736\n",
      "Train Epoch: 9 [25000/39785 (1%)]\tLoss: 11.512489\n",
      "Train Epoch: 9 [26000/39785 (1%)]\tLoss: 10.731125\n",
      "Train Epoch: 9 [27000/39785 (1%)]\tLoss: 10.346197\n",
      "Train Epoch: 9 [28000/39785 (1%)]\tLoss: 12.059620\n",
      "Train Epoch: 9 [29000/39785 (1%)]\tLoss: 10.319165\n",
      "Train Epoch: 9 [30000/39785 (1%)]\tLoss: 9.478619\n",
      "Train Epoch: 9 [31000/39785 (1%)]\tLoss: 10.168149\n",
      "Train Epoch: 9 [32000/39785 (1%)]\tLoss: 8.625074\n",
      "Train Epoch: 9 [33000/39785 (1%)]\tLoss: 11.278180\n",
      "Train Epoch: 9 [34000/39785 (1%)]\tLoss: 10.272439\n",
      "Train Epoch: 9 [35000/39785 (1%)]\tLoss: 6.097641\n",
      "Train Epoch: 9 [36000/39785 (1%)]\tLoss: 10.355350\n",
      "Train Epoch: 9 [37000/39785 (1%)]\tLoss: 10.753444\n",
      "Train Epoch: 9 [38000/39785 (1%)]\tLoss: 11.263067\n",
      "Train Epoch: 9 [39000/39785 (1%)]\tLoss: 10.748221\n",
      "Train Epoch: 10 [1000/39785 (0%)]\tLoss: 9.230186\n",
      "Train Epoch: 10 [2000/39785 (0%)]\tLoss: 9.531084\n",
      "Train Epoch: 10 [3000/39785 (0%)]\tLoss: 9.727263\n",
      "Train Epoch: 10 [4000/39785 (0%)]\tLoss: 7.207639\n",
      "Train Epoch: 10 [5000/39785 (0%)]\tLoss: 7.528049\n",
      "Train Epoch: 10 [6000/39785 (0%)]\tLoss: 9.352911\n",
      "Train Epoch: 10 [7000/39785 (0%)]\tLoss: 8.589514\n",
      "Train Epoch: 10 [8000/39785 (0%)]\tLoss: 8.558571\n",
      "Train Epoch: 10 [9000/39785 (0%)]\tLoss: 8.050261\n",
      "Train Epoch: 10 [10000/39785 (0%)]\tLoss: 9.740830\n",
      "Train Epoch: 10 [11000/39785 (0%)]\tLoss: 9.525594\n",
      "Train Epoch: 10 [12000/39785 (0%)]\tLoss: 9.734592\n",
      "Train Epoch: 10 [13000/39785 (0%)]\tLoss: 9.275701\n",
      "Train Epoch: 10 [14000/39785 (0%)]\tLoss: 7.048173\n",
      "Train Epoch: 10 [15000/39785 (0%)]\tLoss: 7.570764\n",
      "Train Epoch: 10 [16000/39785 (0%)]\tLoss: 8.977932\n",
      "Train Epoch: 10 [17000/39785 (0%)]\tLoss: 11.202758\n",
      "Train Epoch: 10 [18000/39785 (0%)]\tLoss: 10.166031\n",
      "Train Epoch: 10 [19000/39785 (0%)]\tLoss: 6.752423\n",
      "Train Epoch: 10 [20000/39785 (1%)]\tLoss: 9.454049\n",
      "Train Epoch: 10 [21000/39785 (1%)]\tLoss: 8.757171\n",
      "Train Epoch: 10 [22000/39785 (1%)]\tLoss: 8.890665\n",
      "Train Epoch: 10 [23000/39785 (1%)]\tLoss: 6.150814\n",
      "Train Epoch: 10 [24000/39785 (1%)]\tLoss: 8.731179\n",
      "Train Epoch: 10 [25000/39785 (1%)]\tLoss: 9.570926\n",
      "Train Epoch: 10 [26000/39785 (1%)]\tLoss: 7.689251\n",
      "Train Epoch: 10 [27000/39785 (1%)]\tLoss: 7.323430\n",
      "Train Epoch: 10 [28000/39785 (1%)]\tLoss: 10.131422\n",
      "Train Epoch: 10 [29000/39785 (1%)]\tLoss: 9.436980\n",
      "Train Epoch: 10 [30000/39785 (1%)]\tLoss: 9.904615\n",
      "Train Epoch: 10 [31000/39785 (1%)]\tLoss: 7.813006\n",
      "Train Epoch: 10 [32000/39785 (1%)]\tLoss: 6.923284\n",
      "Train Epoch: 10 [33000/39785 (1%)]\tLoss: 8.557057\n",
      "Train Epoch: 10 [34000/39785 (1%)]\tLoss: 9.991748\n",
      "Train Epoch: 10 [35000/39785 (1%)]\tLoss: 9.949749\n",
      "Train Epoch: 10 [36000/39785 (1%)]\tLoss: 9.959764\n",
      "Train Epoch: 10 [37000/39785 (1%)]\tLoss: 7.628066\n",
      "Train Epoch: 10 [38000/39785 (1%)]\tLoss: 8.154764\n",
      "Train Epoch: 10 [39000/39785 (1%)]\tLoss: 10.304965\n",
      "Train Epoch: 11 [1000/39785 (0%)]\tLoss: 7.849487\n",
      "Train Epoch: 11 [2000/39785 (0%)]\tLoss: 8.230769\n",
      "Train Epoch: 11 [3000/39785 (0%)]\tLoss: 10.535581\n",
      "Train Epoch: 11 [4000/39785 (0%)]\tLoss: 8.358374\n",
      "Train Epoch: 11 [5000/39785 (0%)]\tLoss: 7.522527\n",
      "Train Epoch: 11 [6000/39785 (0%)]\tLoss: 6.315425\n",
      "Train Epoch: 11 [7000/39785 (0%)]\tLoss: 6.960181\n",
      "Train Epoch: 11 [8000/39785 (0%)]\tLoss: 11.053988\n",
      "Train Epoch: 11 [9000/39785 (0%)]\tLoss: 9.355865\n",
      "Train Epoch: 11 [10000/39785 (0%)]\tLoss: 8.905884\n",
      "Train Epoch: 11 [11000/39785 (0%)]\tLoss: 7.750262\n",
      "Train Epoch: 11 [12000/39785 (0%)]\tLoss: 9.783164\n",
      "Train Epoch: 11 [13000/39785 (0%)]\tLoss: 11.045035\n",
      "Train Epoch: 11 [14000/39785 (0%)]\tLoss: 7.565612\n",
      "Train Epoch: 11 [15000/39785 (0%)]\tLoss: 8.321271\n",
      "Train Epoch: 11 [16000/39785 (0%)]\tLoss: 8.739724\n",
      "Train Epoch: 11 [17000/39785 (0%)]\tLoss: 7.526693\n",
      "Train Epoch: 11 [18000/39785 (0%)]\tLoss: 9.423281\n",
      "Train Epoch: 11 [19000/39785 (0%)]\tLoss: 10.190203\n",
      "Train Epoch: 11 [20000/39785 (1%)]\tLoss: 8.845225\n",
      "Train Epoch: 11 [21000/39785 (1%)]\tLoss: 9.877118\n",
      "Train Epoch: 11 [22000/39785 (1%)]\tLoss: 11.749790\n",
      "Train Epoch: 11 [23000/39785 (1%)]\tLoss: 9.040720\n",
      "Train Epoch: 11 [24000/39785 (1%)]\tLoss: 8.076435\n",
      "Train Epoch: 11 [25000/39785 (1%)]\tLoss: 6.773091\n",
      "Train Epoch: 11 [26000/39785 (1%)]\tLoss: 8.347397\n",
      "Train Epoch: 11 [27000/39785 (1%)]\tLoss: 9.951138\n",
      "Train Epoch: 11 [28000/39785 (1%)]\tLoss: 6.604151\n",
      "Train Epoch: 11 [29000/39785 (1%)]\tLoss: 9.537327\n",
      "Train Epoch: 11 [30000/39785 (1%)]\tLoss: 10.437510\n",
      "Train Epoch: 11 [31000/39785 (1%)]\tLoss: 9.192111\n",
      "Train Epoch: 11 [32000/39785 (1%)]\tLoss: 11.800134\n",
      "Train Epoch: 11 [33000/39785 (1%)]\tLoss: 8.626674\n",
      "Train Epoch: 11 [34000/39785 (1%)]\tLoss: 7.845610\n",
      "Train Epoch: 11 [35000/39785 (1%)]\tLoss: 10.010152\n",
      "Train Epoch: 11 [36000/39785 (1%)]\tLoss: 8.720120\n",
      "Train Epoch: 11 [37000/39785 (1%)]\tLoss: 8.118203\n",
      "Train Epoch: 11 [38000/39785 (1%)]\tLoss: 7.881593\n",
      "Train Epoch: 11 [39000/39785 (1%)]\tLoss: 9.947758\n",
      "Train Epoch: 12 [1000/39785 (0%)]\tLoss: 8.367774\n",
      "Train Epoch: 12 [2000/39785 (0%)]\tLoss: 7.223809\n",
      "Train Epoch: 12 [3000/39785 (0%)]\tLoss: 6.657205\n",
      "Train Epoch: 12 [4000/39785 (0%)]\tLoss: 8.841225\n",
      "Train Epoch: 12 [5000/39785 (0%)]\tLoss: 8.450151\n",
      "Train Epoch: 12 [6000/39785 (0%)]\tLoss: 5.827125\n",
      "Train Epoch: 12 [7000/39785 (0%)]\tLoss: 8.851330\n",
      "Train Epoch: 12 [8000/39785 (0%)]\tLoss: 6.956513\n",
      "Train Epoch: 12 [9000/39785 (0%)]\tLoss: 7.205274\n",
      "Train Epoch: 12 [10000/39785 (0%)]\tLoss: 10.628160\n",
      "Train Epoch: 12 [11000/39785 (0%)]\tLoss: 8.466872\n",
      "Train Epoch: 12 [12000/39785 (0%)]\tLoss: 7.088268\n",
      "Train Epoch: 12 [13000/39785 (0%)]\tLoss: 8.183619\n",
      "Train Epoch: 12 [14000/39785 (0%)]\tLoss: 6.727639\n",
      "Train Epoch: 12 [15000/39785 (0%)]\tLoss: 7.331431\n",
      "Train Epoch: 12 [16000/39785 (0%)]\tLoss: 6.057433\n",
      "Train Epoch: 12 [17000/39785 (0%)]\tLoss: 6.572924\n",
      "Train Epoch: 12 [18000/39785 (0%)]\tLoss: 8.813948\n",
      "Train Epoch: 12 [19000/39785 (0%)]\tLoss: 8.923443\n",
      "Train Epoch: 12 [20000/39785 (1%)]\tLoss: 10.191666\n",
      "Train Epoch: 12 [21000/39785 (1%)]\tLoss: 8.426776\n",
      "Train Epoch: 12 [22000/39785 (1%)]\tLoss: 10.662655\n",
      "Train Epoch: 12 [23000/39785 (1%)]\tLoss: 7.779619\n",
      "Train Epoch: 12 [24000/39785 (1%)]\tLoss: 8.933590\n",
      "Train Epoch: 12 [25000/39785 (1%)]\tLoss: 7.812879\n",
      "Train Epoch: 12 [26000/39785 (1%)]\tLoss: 6.057081\n",
      "Train Epoch: 12 [27000/39785 (1%)]\tLoss: 6.433381\n",
      "Train Epoch: 12 [28000/39785 (1%)]\tLoss: 8.657297\n",
      "Train Epoch: 12 [29000/39785 (1%)]\tLoss: 7.771948\n",
      "Train Epoch: 12 [30000/39785 (1%)]\tLoss: 7.779806\n",
      "Train Epoch: 12 [31000/39785 (1%)]\tLoss: 8.892301\n",
      "Train Epoch: 12 [32000/39785 (1%)]\tLoss: 6.604013\n",
      "Train Epoch: 12 [33000/39785 (1%)]\tLoss: 7.401593\n",
      "Train Epoch: 12 [34000/39785 (1%)]\tLoss: 7.034331\n",
      "Train Epoch: 12 [35000/39785 (1%)]\tLoss: 9.108131\n",
      "Train Epoch: 12 [36000/39785 (1%)]\tLoss: 9.472363\n",
      "Train Epoch: 12 [37000/39785 (1%)]\tLoss: 10.302196\n",
      "Train Epoch: 12 [38000/39785 (1%)]\tLoss: 8.982287\n",
      "Train Epoch: 12 [39000/39785 (1%)]\tLoss: 9.008263\n",
      "Train Epoch: 13 [1000/39785 (0%)]\tLoss: 7.175438\n",
      "Train Epoch: 13 [2000/39785 (0%)]\tLoss: 6.632494\n",
      "Train Epoch: 13 [3000/39785 (0%)]\tLoss: 5.574864\n",
      "Train Epoch: 13 [4000/39785 (0%)]\tLoss: 8.879244\n",
      "Train Epoch: 13 [5000/39785 (0%)]\tLoss: 6.787837\n",
      "Train Epoch: 13 [6000/39785 (0%)]\tLoss: 6.479558\n",
      "Train Epoch: 13 [7000/39785 (0%)]\tLoss: 7.183732\n",
      "Train Epoch: 13 [8000/39785 (0%)]\tLoss: 7.556695\n",
      "Train Epoch: 13 [9000/39785 (0%)]\tLoss: 6.592172\n",
      "Train Epoch: 13 [10000/39785 (0%)]\tLoss: 7.276890\n",
      "Train Epoch: 13 [11000/39785 (0%)]\tLoss: 7.164815\n",
      "Train Epoch: 13 [12000/39785 (0%)]\tLoss: 8.722439\n",
      "Train Epoch: 13 [13000/39785 (0%)]\tLoss: 8.611359\n",
      "Train Epoch: 13 [14000/39785 (0%)]\tLoss: 6.756455\n",
      "Train Epoch: 13 [15000/39785 (0%)]\tLoss: 6.595577\n",
      "Train Epoch: 13 [16000/39785 (0%)]\tLoss: 5.843686\n",
      "Train Epoch: 13 [17000/39785 (0%)]\tLoss: 6.335552\n",
      "Train Epoch: 13 [18000/39785 (0%)]\tLoss: 6.683812\n",
      "Train Epoch: 13 [19000/39785 (0%)]\tLoss: 8.216143\n",
      "Train Epoch: 13 [20000/39785 (1%)]\tLoss: 6.971176\n",
      "Train Epoch: 13 [21000/39785 (1%)]\tLoss: 6.734119\n",
      "Train Epoch: 13 [22000/39785 (1%)]\tLoss: 7.225158\n",
      "Train Epoch: 13 [23000/39785 (1%)]\tLoss: 9.416307\n",
      "Train Epoch: 13 [24000/39785 (1%)]\tLoss: 12.038808\n",
      "Train Epoch: 13 [25000/39785 (1%)]\tLoss: 7.371948\n",
      "Train Epoch: 13 [26000/39785 (1%)]\tLoss: 7.553825\n",
      "Train Epoch: 13 [27000/39785 (1%)]\tLoss: 10.737089\n",
      "Train Epoch: 13 [28000/39785 (1%)]\tLoss: 8.455490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [29000/39785 (1%)]\tLoss: 6.999557\n",
      "Train Epoch: 13 [30000/39785 (1%)]\tLoss: 8.564786\n",
      "Train Epoch: 13 [31000/39785 (1%)]\tLoss: 8.425055\n",
      "Train Epoch: 13 [32000/39785 (1%)]\tLoss: 5.095156\n",
      "Train Epoch: 13 [33000/39785 (1%)]\tLoss: 6.971272\n",
      "Train Epoch: 13 [34000/39785 (1%)]\tLoss: 9.011045\n",
      "Train Epoch: 13 [35000/39785 (1%)]\tLoss: 9.061323\n",
      "Train Epoch: 13 [36000/39785 (1%)]\tLoss: 6.386374\n",
      "Train Epoch: 13 [37000/39785 (1%)]\tLoss: 7.678381\n",
      "Train Epoch: 13 [38000/39785 (1%)]\tLoss: 7.761443\n",
      "Train Epoch: 13 [39000/39785 (1%)]\tLoss: 7.863189\n",
      "Train Epoch: 14 [1000/39785 (0%)]\tLoss: 6.257151\n",
      "Train Epoch: 14 [2000/39785 (0%)]\tLoss: 6.757326\n",
      "Train Epoch: 14 [3000/39785 (0%)]\tLoss: 7.111325\n",
      "Train Epoch: 14 [4000/39785 (0%)]\tLoss: 6.957067\n",
      "Train Epoch: 14 [5000/39785 (0%)]\tLoss: 6.344107\n",
      "Train Epoch: 14 [6000/39785 (0%)]\tLoss: 6.484881\n",
      "Train Epoch: 14 [7000/39785 (0%)]\tLoss: 6.959034\n",
      "Train Epoch: 14 [8000/39785 (0%)]\tLoss: 6.560190\n",
      "Train Epoch: 14 [9000/39785 (0%)]\tLoss: 7.983716\n",
      "Train Epoch: 14 [10000/39785 (0%)]\tLoss: 7.764360\n",
      "Train Epoch: 14 [11000/39785 (0%)]\tLoss: 4.601280\n",
      "Train Epoch: 14 [12000/39785 (0%)]\tLoss: 8.151326\n",
      "Train Epoch: 14 [13000/39785 (0%)]\tLoss: 7.734319\n",
      "Train Epoch: 14 [14000/39785 (0%)]\tLoss: 7.369637\n",
      "Train Epoch: 14 [15000/39785 (0%)]\tLoss: 8.999216\n",
      "Train Epoch: 14 [16000/39785 (0%)]\tLoss: 7.463114\n",
      "Train Epoch: 14 [17000/39785 (0%)]\tLoss: 6.810991\n",
      "Train Epoch: 14 [18000/39785 (0%)]\tLoss: 8.181272\n",
      "Train Epoch: 14 [19000/39785 (0%)]\tLoss: 6.912291\n",
      "Train Epoch: 14 [20000/39785 (1%)]\tLoss: 7.439074\n",
      "Train Epoch: 14 [21000/39785 (1%)]\tLoss: 6.732785\n",
      "Train Epoch: 14 [22000/39785 (1%)]\tLoss: 6.363039\n",
      "Train Epoch: 14 [23000/39785 (1%)]\tLoss: 7.376017\n",
      "Train Epoch: 14 [24000/39785 (1%)]\tLoss: 8.969343\n",
      "Train Epoch: 14 [25000/39785 (1%)]\tLoss: 6.877405\n",
      "Train Epoch: 14 [26000/39785 (1%)]\tLoss: 8.307736\n",
      "Train Epoch: 14 [27000/39785 (1%)]\tLoss: 8.254738\n",
      "Train Epoch: 14 [28000/39785 (1%)]\tLoss: 8.255856\n",
      "Train Epoch: 14 [29000/39785 (1%)]\tLoss: 7.114738\n",
      "Train Epoch: 14 [30000/39785 (1%)]\tLoss: 7.413349\n",
      "Train Epoch: 14 [31000/39785 (1%)]\tLoss: 8.326922\n",
      "Train Epoch: 14 [32000/39785 (1%)]\tLoss: 8.943339\n",
      "Train Epoch: 14 [33000/39785 (1%)]\tLoss: 8.155103\n",
      "Train Epoch: 14 [34000/39785 (1%)]\tLoss: 8.147686\n",
      "Train Epoch: 14 [35000/39785 (1%)]\tLoss: 6.289428\n",
      "Train Epoch: 14 [36000/39785 (1%)]\tLoss: 6.300996\n",
      "Train Epoch: 14 [37000/39785 (1%)]\tLoss: 7.779043\n",
      "Train Epoch: 14 [38000/39785 (1%)]\tLoss: 8.079407\n",
      "Train Epoch: 14 [39000/39785 (1%)]\tLoss: 6.555353\n",
      "Train Epoch: 15 [1000/39785 (0%)]\tLoss: 6.414292\n",
      "Train Epoch: 15 [2000/39785 (0%)]\tLoss: 7.053290\n",
      "Train Epoch: 15 [3000/39785 (0%)]\tLoss: 4.961973\n",
      "Train Epoch: 15 [4000/39785 (0%)]\tLoss: 6.740092\n",
      "Train Epoch: 15 [5000/39785 (0%)]\tLoss: 7.251776\n",
      "Train Epoch: 15 [6000/39785 (0%)]\tLoss: 7.175035\n",
      "Train Epoch: 15 [7000/39785 (0%)]\tLoss: 6.643988\n",
      "Train Epoch: 15 [8000/39785 (0%)]\tLoss: 6.624603\n",
      "Train Epoch: 15 [9000/39785 (0%)]\tLoss: 6.703293\n",
      "Train Epoch: 15 [10000/39785 (0%)]\tLoss: 8.281862\n",
      "Train Epoch: 15 [11000/39785 (0%)]\tLoss: 8.026196\n",
      "Train Epoch: 15 [12000/39785 (0%)]\tLoss: 7.362957\n",
      "Train Epoch: 15 [13000/39785 (0%)]\tLoss: 5.298702\n",
      "Train Epoch: 15 [14000/39785 (0%)]\tLoss: 6.894053\n",
      "Train Epoch: 15 [15000/39785 (0%)]\tLoss: 6.708974\n",
      "Train Epoch: 15 [16000/39785 (0%)]\tLoss: 7.337349\n",
      "Train Epoch: 15 [17000/39785 (0%)]\tLoss: 4.454477\n",
      "Train Epoch: 15 [18000/39785 (0%)]\tLoss: 7.461668\n",
      "Train Epoch: 15 [19000/39785 (0%)]\tLoss: 7.585062\n",
      "Train Epoch: 15 [20000/39785 (1%)]\tLoss: 6.059277\n",
      "Train Epoch: 15 [21000/39785 (1%)]\tLoss: 5.872464\n",
      "Train Epoch: 15 [22000/39785 (1%)]\tLoss: 6.966742\n",
      "Train Epoch: 15 [23000/39785 (1%)]\tLoss: 6.199611\n",
      "Train Epoch: 15 [24000/39785 (1%)]\tLoss: 6.440411\n",
      "Train Epoch: 15 [25000/39785 (1%)]\tLoss: 6.888699\n",
      "Train Epoch: 15 [26000/39785 (1%)]\tLoss: 5.604371\n",
      "Train Epoch: 15 [27000/39785 (1%)]\tLoss: 7.294767\n",
      "Train Epoch: 15 [28000/39785 (1%)]\tLoss: 8.788567\n",
      "Train Epoch: 15 [29000/39785 (1%)]\tLoss: 6.411347\n",
      "Train Epoch: 15 [30000/39785 (1%)]\tLoss: 8.473122\n",
      "Train Epoch: 15 [31000/39785 (1%)]\tLoss: 7.209316\n",
      "Train Epoch: 15 [32000/39785 (1%)]\tLoss: 4.894134\n",
      "Train Epoch: 15 [33000/39785 (1%)]\tLoss: 6.166090\n",
      "Train Epoch: 15 [34000/39785 (1%)]\tLoss: 6.216393\n",
      "Train Epoch: 15 [35000/39785 (1%)]\tLoss: 6.930696\n",
      "Train Epoch: 15 [36000/39785 (1%)]\tLoss: 9.020073\n",
      "Train Epoch: 15 [37000/39785 (1%)]\tLoss: 8.135713\n",
      "Train Epoch: 15 [38000/39785 (1%)]\tLoss: 10.177833\n",
      "Train Epoch: 15 [39000/39785 (1%)]\tLoss: 6.700096\n",
      "Train Epoch: 16 [1000/39785 (0%)]\tLoss: 5.950996\n",
      "Train Epoch: 16 [2000/39785 (0%)]\tLoss: 6.181982\n",
      "Train Epoch: 16 [3000/39785 (0%)]\tLoss: 4.891339\n",
      "Train Epoch: 16 [4000/39785 (0%)]\tLoss: 5.641156\n",
      "Train Epoch: 16 [5000/39785 (0%)]\tLoss: 4.780401\n",
      "Train Epoch: 16 [6000/39785 (0%)]\tLoss: 5.869816\n",
      "Train Epoch: 16 [7000/39785 (0%)]\tLoss: 7.597461\n",
      "Train Epoch: 16 [8000/39785 (0%)]\tLoss: 5.888093\n",
      "Train Epoch: 16 [9000/39785 (0%)]\tLoss: 5.554801\n",
      "Train Epoch: 16 [10000/39785 (0%)]\tLoss: 6.006882\n",
      "Train Epoch: 16 [11000/39785 (0%)]\tLoss: 8.158647\n",
      "Train Epoch: 16 [12000/39785 (0%)]\tLoss: 7.221055\n",
      "Train Epoch: 16 [13000/39785 (0%)]\tLoss: 6.061165\n",
      "Train Epoch: 16 [14000/39785 (0%)]\tLoss: 6.444142\n",
      "Train Epoch: 16 [15000/39785 (0%)]\tLoss: 5.535446\n",
      "Train Epoch: 16 [16000/39785 (0%)]\tLoss: 8.420644\n",
      "Train Epoch: 16 [17000/39785 (0%)]\tLoss: 6.391679\n",
      "Train Epoch: 16 [18000/39785 (0%)]\tLoss: 6.371879\n",
      "Train Epoch: 16 [19000/39785 (0%)]\tLoss: 6.971062\n",
      "Train Epoch: 16 [20000/39785 (1%)]\tLoss: 7.491920\n",
      "Train Epoch: 16 [21000/39785 (1%)]\tLoss: 4.733561\n",
      "Train Epoch: 16 [22000/39785 (1%)]\tLoss: 4.812935\n",
      "Train Epoch: 16 [23000/39785 (1%)]\tLoss: 5.479683\n",
      "Train Epoch: 16 [24000/39785 (1%)]\tLoss: 5.480606\n",
      "Train Epoch: 16 [25000/39785 (1%)]\tLoss: 7.011847\n",
      "Train Epoch: 16 [26000/39785 (1%)]\tLoss: 7.506154\n",
      "Train Epoch: 16 [27000/39785 (1%)]\tLoss: 5.803198\n",
      "Train Epoch: 16 [28000/39785 (1%)]\tLoss: 6.217276\n",
      "Train Epoch: 16 [29000/39785 (1%)]\tLoss: 7.085907\n",
      "Train Epoch: 16 [30000/39785 (1%)]\tLoss: 5.919602\n",
      "Train Epoch: 16 [31000/39785 (1%)]\tLoss: 7.935068\n",
      "Train Epoch: 16 [32000/39785 (1%)]\tLoss: 7.426947\n",
      "Train Epoch: 16 [33000/39785 (1%)]\tLoss: 5.313597\n",
      "Train Epoch: 16 [34000/39785 (1%)]\tLoss: 6.360900\n",
      "Train Epoch: 16 [35000/39785 (1%)]\tLoss: 7.147568\n",
      "Train Epoch: 16 [36000/39785 (1%)]\tLoss: 8.225827\n",
      "Train Epoch: 16 [37000/39785 (1%)]\tLoss: 8.277462\n",
      "Train Epoch: 16 [38000/39785 (1%)]\tLoss: 9.734157\n",
      "Train Epoch: 16 [39000/39785 (1%)]\tLoss: 7.814007\n",
      "Train Epoch: 17 [1000/39785 (0%)]\tLoss: 5.266311\n",
      "Train Epoch: 17 [2000/39785 (0%)]\tLoss: 6.363956\n",
      "Train Epoch: 17 [3000/39785 (0%)]\tLoss: 5.230094\n",
      "Train Epoch: 17 [4000/39785 (0%)]\tLoss: 6.345231\n",
      "Train Epoch: 17 [5000/39785 (0%)]\tLoss: 5.357375\n",
      "Train Epoch: 17 [6000/39785 (0%)]\tLoss: 7.058895\n",
      "Train Epoch: 17 [7000/39785 (0%)]\tLoss: 6.696708\n",
      "Train Epoch: 17 [8000/39785 (0%)]\tLoss: 6.181328\n",
      "Train Epoch: 17 [9000/39785 (0%)]\tLoss: 6.249345\n",
      "Train Epoch: 17 [10000/39785 (0%)]\tLoss: 6.965396\n",
      "Train Epoch: 17 [11000/39785 (0%)]\tLoss: 6.641282\n",
      "Train Epoch: 17 [12000/39785 (0%)]\tLoss: 6.437737\n",
      "Train Epoch: 17 [13000/39785 (0%)]\tLoss: 4.650779\n",
      "Train Epoch: 17 [14000/39785 (0%)]\tLoss: 7.214387\n",
      "Train Epoch: 17 [15000/39785 (0%)]\tLoss: 5.925697\n",
      "Train Epoch: 17 [16000/39785 (0%)]\tLoss: 5.254599\n",
      "Train Epoch: 17 [17000/39785 (0%)]\tLoss: 7.201235\n",
      "Train Epoch: 17 [18000/39785 (0%)]\tLoss: 7.225964\n",
      "Train Epoch: 17 [19000/39785 (0%)]\tLoss: 6.764977\n",
      "Train Epoch: 17 [20000/39785 (1%)]\tLoss: 6.416767\n",
      "Train Epoch: 17 [21000/39785 (1%)]\tLoss: 8.512831\n",
      "Train Epoch: 17 [22000/39785 (1%)]\tLoss: 7.238022\n",
      "Train Epoch: 17 [23000/39785 (1%)]\tLoss: 5.999014\n",
      "Train Epoch: 17 [24000/39785 (1%)]\tLoss: 6.527290\n",
      "Train Epoch: 17 [25000/39785 (1%)]\tLoss: 5.003458\n",
      "Train Epoch: 17 [26000/39785 (1%)]\tLoss: 8.610810\n",
      "Train Epoch: 17 [27000/39785 (1%)]\tLoss: 5.928643\n",
      "Train Epoch: 17 [28000/39785 (1%)]\tLoss: 5.149367\n",
      "Train Epoch: 17 [29000/39785 (1%)]\tLoss: 6.831331\n",
      "Train Epoch: 17 [30000/39785 (1%)]\tLoss: 4.332347\n",
      "Train Epoch: 17 [31000/39785 (1%)]\tLoss: 7.521624\n",
      "Train Epoch: 17 [32000/39785 (1%)]\tLoss: 7.557334\n",
      "Train Epoch: 17 [33000/39785 (1%)]\tLoss: 6.140361\n",
      "Train Epoch: 17 [34000/39785 (1%)]\tLoss: 6.755159\n",
      "Train Epoch: 17 [35000/39785 (1%)]\tLoss: 6.676275\n",
      "Train Epoch: 17 [36000/39785 (1%)]\tLoss: 6.194330\n",
      "Train Epoch: 17 [37000/39785 (1%)]\tLoss: 8.173445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [38000/39785 (1%)]\tLoss: 9.349587\n",
      "Train Epoch: 17 [39000/39785 (1%)]\tLoss: 5.430182\n",
      "Train Epoch: 18 [1000/39785 (0%)]\tLoss: 5.089432\n",
      "Train Epoch: 18 [2000/39785 (0%)]\tLoss: 5.682003\n",
      "Train Epoch: 18 [3000/39785 (0%)]\tLoss: 5.950202\n",
      "Train Epoch: 18 [4000/39785 (0%)]\tLoss: 5.828528\n",
      "Train Epoch: 18 [5000/39785 (0%)]\tLoss: 7.059165\n",
      "Train Epoch: 18 [6000/39785 (0%)]\tLoss: 6.049141\n",
      "Train Epoch: 18 [7000/39785 (0%)]\tLoss: 5.357966\n",
      "Train Epoch: 18 [8000/39785 (0%)]\tLoss: 5.727799\n",
      "Train Epoch: 18 [9000/39785 (0%)]\tLoss: 6.365763\n",
      "Train Epoch: 18 [10000/39785 (0%)]\tLoss: 5.479970\n",
      "Train Epoch: 18 [11000/39785 (0%)]\tLoss: 5.783562\n",
      "Train Epoch: 18 [12000/39785 (0%)]\tLoss: 6.516585\n",
      "Train Epoch: 18 [13000/39785 (0%)]\tLoss: 5.314655\n",
      "Train Epoch: 18 [14000/39785 (0%)]\tLoss: 6.594130\n",
      "Train Epoch: 18 [15000/39785 (0%)]\tLoss: 5.946997\n",
      "Train Epoch: 18 [16000/39785 (0%)]\tLoss: 5.620379\n",
      "Train Epoch: 18 [17000/39785 (0%)]\tLoss: 7.400437\n",
      "Train Epoch: 18 [18000/39785 (0%)]\tLoss: 8.443272\n",
      "Train Epoch: 18 [19000/39785 (0%)]\tLoss: 7.468901\n",
      "Train Epoch: 18 [20000/39785 (1%)]\tLoss: 4.901128\n",
      "Train Epoch: 18 [21000/39785 (1%)]\tLoss: 6.471050\n",
      "Train Epoch: 18 [22000/39785 (1%)]\tLoss: 5.233485\n",
      "Train Epoch: 18 [23000/39785 (1%)]\tLoss: 4.699365\n",
      "Train Epoch: 18 [24000/39785 (1%)]\tLoss: 5.080634\n",
      "Train Epoch: 18 [25000/39785 (1%)]\tLoss: 5.903672\n",
      "Train Epoch: 18 [26000/39785 (1%)]\tLoss: 5.226576\n",
      "Train Epoch: 18 [27000/39785 (1%)]\tLoss: 6.432416\n",
      "Train Epoch: 18 [28000/39785 (1%)]\tLoss: 6.291223\n",
      "Train Epoch: 18 [29000/39785 (1%)]\tLoss: 5.577214\n",
      "Train Epoch: 18 [30000/39785 (1%)]\tLoss: 6.753263\n",
      "Train Epoch: 18 [31000/39785 (1%)]\tLoss: 6.709447\n",
      "Train Epoch: 18 [32000/39785 (1%)]\tLoss: 6.286413\n",
      "Train Epoch: 18 [33000/39785 (1%)]\tLoss: 5.824219\n",
      "Train Epoch: 18 [34000/39785 (1%)]\tLoss: 8.161790\n",
      "Train Epoch: 18 [35000/39785 (1%)]\tLoss: 6.021101\n",
      "Train Epoch: 18 [36000/39785 (1%)]\tLoss: 8.301543\n",
      "Train Epoch: 18 [37000/39785 (1%)]\tLoss: 7.260141\n",
      "Train Epoch: 18 [38000/39785 (1%)]\tLoss: 6.625437\n",
      "Train Epoch: 18 [39000/39785 (1%)]\tLoss: 6.722966\n",
      "Train Epoch: 19 [1000/39785 (0%)]\tLoss: 5.127365\n",
      "Train Epoch: 19 [2000/39785 (0%)]\tLoss: 5.361839\n",
      "Train Epoch: 19 [3000/39785 (0%)]\tLoss: 4.158180\n",
      "Train Epoch: 19 [4000/39785 (0%)]\tLoss: 6.024853\n",
      "Train Epoch: 19 [5000/39785 (0%)]\tLoss: 6.124671\n",
      "Train Epoch: 19 [6000/39785 (0%)]\tLoss: 5.211885\n",
      "Train Epoch: 19 [7000/39785 (0%)]\tLoss: 5.695922\n",
      "Train Epoch: 19 [8000/39785 (0%)]\tLoss: 4.917104\n",
      "Train Epoch: 19 [9000/39785 (0%)]\tLoss: 7.474080\n",
      "Train Epoch: 19 [10000/39785 (0%)]\tLoss: 5.910542\n",
      "Train Epoch: 19 [11000/39785 (0%)]\tLoss: 5.422762\n",
      "Train Epoch: 19 [12000/39785 (0%)]\tLoss: 6.080512\n",
      "Train Epoch: 19 [13000/39785 (0%)]\tLoss: 5.181107\n",
      "Train Epoch: 19 [14000/39785 (0%)]\tLoss: 6.290399\n",
      "Train Epoch: 19 [15000/39785 (0%)]\tLoss: 6.660972\n",
      "Train Epoch: 19 [16000/39785 (0%)]\tLoss: 6.396919\n",
      "Train Epoch: 19 [17000/39785 (0%)]\tLoss: 6.066757\n",
      "Train Epoch: 19 [18000/39785 (0%)]\tLoss: 5.884200\n",
      "Train Epoch: 19 [19000/39785 (0%)]\tLoss: 4.820259\n",
      "Train Epoch: 19 [20000/39785 (1%)]\tLoss: 4.624312\n",
      "Train Epoch: 19 [21000/39785 (1%)]\tLoss: 5.289915\n",
      "Train Epoch: 19 [22000/39785 (1%)]\tLoss: 6.046940\n",
      "Train Epoch: 19 [23000/39785 (1%)]\tLoss: 4.857218\n",
      "Train Epoch: 19 [24000/39785 (1%)]\tLoss: 5.658081\n",
      "Train Epoch: 19 [25000/39785 (1%)]\tLoss: 7.168423\n",
      "Train Epoch: 19 [26000/39785 (1%)]\tLoss: 5.770111\n",
      "Train Epoch: 19 [27000/39785 (1%)]\tLoss: 6.331621\n",
      "Train Epoch: 19 [28000/39785 (1%)]\tLoss: 5.356830\n",
      "Train Epoch: 19 [29000/39785 (1%)]\tLoss: 5.817750\n",
      "Train Epoch: 19 [30000/39785 (1%)]\tLoss: 7.187019\n",
      "Train Epoch: 19 [31000/39785 (1%)]\tLoss: 6.608642\n",
      "Train Epoch: 19 [32000/39785 (1%)]\tLoss: 7.173996\n",
      "Train Epoch: 19 [33000/39785 (1%)]\tLoss: 6.465548\n",
      "Train Epoch: 19 [34000/39785 (1%)]\tLoss: 5.741314\n",
      "Train Epoch: 19 [35000/39785 (1%)]\tLoss: 5.272870\n",
      "Train Epoch: 19 [36000/39785 (1%)]\tLoss: 6.224559\n",
      "Train Epoch: 19 [37000/39785 (1%)]\tLoss: 5.453358\n",
      "Train Epoch: 19 [38000/39785 (1%)]\tLoss: 9.232087\n",
      "Train Epoch: 19 [39000/39785 (1%)]\tLoss: 5.985023\n",
      "Train Epoch: 20 [1000/39785 (0%)]\tLoss: 5.353914\n",
      "Train Epoch: 20 [2000/39785 (0%)]\tLoss: 6.618012\n",
      "Train Epoch: 20 [3000/39785 (0%)]\tLoss: 4.754771\n",
      "Train Epoch: 20 [4000/39785 (0%)]\tLoss: 5.400640\n",
      "Train Epoch: 20 [5000/39785 (0%)]\tLoss: 4.102911\n",
      "Train Epoch: 20 [6000/39785 (0%)]\tLoss: 6.184035\n",
      "Train Epoch: 20 [7000/39785 (0%)]\tLoss: 5.671991\n",
      "Train Epoch: 20 [8000/39785 (0%)]\tLoss: 7.312680\n",
      "Train Epoch: 20 [9000/39785 (0%)]\tLoss: 4.710417\n",
      "Train Epoch: 20 [10000/39785 (0%)]\tLoss: 5.918351\n",
      "Train Epoch: 20 [11000/39785 (0%)]\tLoss: 5.728949\n",
      "Train Epoch: 20 [12000/39785 (0%)]\tLoss: 5.562492\n",
      "Train Epoch: 20 [13000/39785 (0%)]\tLoss: 3.689057\n",
      "Train Epoch: 20 [14000/39785 (0%)]\tLoss: 6.107807\n",
      "Train Epoch: 20 [15000/39785 (0%)]\tLoss: 4.511224\n",
      "Train Epoch: 20 [16000/39785 (0%)]\tLoss: 5.230862\n",
      "Train Epoch: 20 [17000/39785 (0%)]\tLoss: 4.101728\n",
      "Train Epoch: 20 [18000/39785 (0%)]\tLoss: 6.583094\n",
      "Train Epoch: 20 [19000/39785 (0%)]\tLoss: 6.661294\n",
      "Train Epoch: 20 [20000/39785 (1%)]\tLoss: 6.748481\n",
      "Train Epoch: 20 [21000/39785 (1%)]\tLoss: 7.631565\n",
      "Train Epoch: 20 [22000/39785 (1%)]\tLoss: 5.988507\n",
      "Train Epoch: 20 [23000/39785 (1%)]\tLoss: 6.315874\n",
      "Train Epoch: 20 [24000/39785 (1%)]\tLoss: 5.729586\n",
      "Train Epoch: 20 [25000/39785 (1%)]\tLoss: 5.361336\n",
      "Train Epoch: 20 [26000/39785 (1%)]\tLoss: 5.154563\n",
      "Train Epoch: 20 [27000/39785 (1%)]\tLoss: 5.383518\n",
      "Train Epoch: 20 [28000/39785 (1%)]\tLoss: 5.958447\n",
      "Train Epoch: 20 [29000/39785 (1%)]\tLoss: 7.113735\n",
      "Train Epoch: 20 [30000/39785 (1%)]\tLoss: 6.092575\n",
      "Train Epoch: 20 [31000/39785 (1%)]\tLoss: 6.131405\n",
      "Train Epoch: 20 [32000/39785 (1%)]\tLoss: 5.935631\n",
      "Train Epoch: 20 [33000/39785 (1%)]\tLoss: 6.452978\n",
      "Train Epoch: 20 [34000/39785 (1%)]\tLoss: 6.287425\n",
      "Train Epoch: 20 [35000/39785 (1%)]\tLoss: 6.383678\n",
      "Train Epoch: 20 [36000/39785 (1%)]\tLoss: 5.639465\n",
      "Train Epoch: 20 [37000/39785 (1%)]\tLoss: 5.743880\n",
      "Train Epoch: 20 [38000/39785 (1%)]\tLoss: 5.700856\n",
      "Train Epoch: 20 [39000/39785 (1%)]\tLoss: 5.546570\n",
      "Train Epoch: 22 [1000/39785 (0%)]\tLoss: 5.632528\n",
      "Train Epoch: 22 [2000/39785 (0%)]\tLoss: 4.691900\n",
      "Train Epoch: 22 [3000/39785 (0%)]\tLoss: 6.863268\n",
      "Train Epoch: 22 [4000/39785 (0%)]\tLoss: 5.211525\n",
      "Train Epoch: 22 [5000/39785 (0%)]\tLoss: 4.502829\n",
      "Train Epoch: 22 [6000/39785 (0%)]\tLoss: 3.965451\n",
      "Train Epoch: 22 [7000/39785 (0%)]\tLoss: 6.179155\n",
      "Train Epoch: 22 [8000/39785 (0%)]\tLoss: 6.867124\n",
      "Train Epoch: 22 [9000/39785 (0%)]\tLoss: 6.270510\n",
      "Train Epoch: 22 [10000/39785 (0%)]\tLoss: 5.557461\n",
      "Train Epoch: 22 [11000/39785 (0%)]\tLoss: 4.529526\n",
      "Train Epoch: 22 [12000/39785 (0%)]\tLoss: 5.289324\n",
      "Train Epoch: 22 [13000/39785 (0%)]\tLoss: 6.812494\n",
      "Train Epoch: 22 [14000/39785 (0%)]\tLoss: 4.556177\n",
      "Train Epoch: 22 [15000/39785 (0%)]\tLoss: 4.485052\n",
      "Train Epoch: 22 [16000/39785 (0%)]\tLoss: 6.552610\n",
      "Train Epoch: 22 [17000/39785 (0%)]\tLoss: 5.274423\n",
      "Train Epoch: 22 [18000/39785 (0%)]\tLoss: 4.857225\n",
      "Train Epoch: 22 [19000/39785 (0%)]\tLoss: 6.298100\n",
      "Train Epoch: 22 [20000/39785 (1%)]\tLoss: 4.806652\n",
      "Train Epoch: 22 [21000/39785 (1%)]\tLoss: 7.216186\n",
      "Train Epoch: 22 [22000/39785 (1%)]\tLoss: 5.210569\n",
      "Train Epoch: 22 [23000/39785 (1%)]\tLoss: 7.015220\n",
      "Train Epoch: 22 [24000/39785 (1%)]\tLoss: 5.642925\n",
      "Train Epoch: 22 [25000/39785 (1%)]\tLoss: 5.110432\n",
      "Train Epoch: 22 [26000/39785 (1%)]\tLoss: 4.387439\n",
      "Train Epoch: 22 [27000/39785 (1%)]\tLoss: 6.304618\n",
      "Train Epoch: 22 [28000/39785 (1%)]\tLoss: 5.054828\n",
      "Train Epoch: 22 [29000/39785 (1%)]\tLoss: 4.434695\n",
      "Train Epoch: 22 [30000/39785 (1%)]\tLoss: 5.386749\n",
      "Train Epoch: 22 [31000/39785 (1%)]\tLoss: 4.893360\n",
      "Train Epoch: 22 [32000/39785 (1%)]\tLoss: 4.064099\n",
      "Train Epoch: 22 [33000/39785 (1%)]\tLoss: 5.451885\n",
      "Train Epoch: 22 [34000/39785 (1%)]\tLoss: 5.187622\n",
      "Train Epoch: 22 [35000/39785 (1%)]\tLoss: 6.296653\n",
      "Train Epoch: 22 [36000/39785 (1%)]\tLoss: 4.225095\n",
      "Train Epoch: 22 [37000/39785 (1%)]\tLoss: 5.358059\n",
      "Train Epoch: 22 [38000/39785 (1%)]\tLoss: 6.613518\n",
      "Train Epoch: 22 [39000/39785 (1%)]\tLoss: 5.693644\n",
      "Train Epoch: 23 [1000/39785 (0%)]\tLoss: 5.525904\n",
      "Train Epoch: 23 [2000/39785 (0%)]\tLoss: 5.405270\n",
      "Train Epoch: 23 [3000/39785 (0%)]\tLoss: 6.443157\n",
      "Train Epoch: 23 [4000/39785 (0%)]\tLoss: 4.202137\n",
      "Train Epoch: 23 [5000/39785 (0%)]\tLoss: 5.973722\n",
      "Train Epoch: 23 [6000/39785 (0%)]\tLoss: 3.851262\n",
      "Train Epoch: 23 [7000/39785 (0%)]\tLoss: 4.131193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [8000/39785 (0%)]\tLoss: 7.045302\n",
      "Train Epoch: 23 [9000/39785 (0%)]\tLoss: 5.849342\n",
      "Train Epoch: 23 [10000/39785 (0%)]\tLoss: 8.144588\n",
      "Train Epoch: 23 [11000/39785 (0%)]\tLoss: 5.854420\n",
      "Train Epoch: 23 [12000/39785 (0%)]\tLoss: 5.645767\n",
      "Train Epoch: 23 [13000/39785 (0%)]\tLoss: 4.330109\n",
      "Train Epoch: 23 [14000/39785 (0%)]\tLoss: 4.016644\n",
      "Train Epoch: 23 [15000/39785 (0%)]\tLoss: 5.574136\n",
      "Train Epoch: 23 [16000/39785 (0%)]\tLoss: 4.556806\n",
      "Train Epoch: 23 [17000/39785 (0%)]\tLoss: 4.918741\n",
      "Train Epoch: 23 [18000/39785 (0%)]\tLoss: 4.217258\n",
      "Train Epoch: 23 [19000/39785 (0%)]\tLoss: 4.552353\n",
      "Train Epoch: 23 [20000/39785 (1%)]\tLoss: 4.593202\n",
      "Train Epoch: 23 [21000/39785 (1%)]\tLoss: 6.643904\n",
      "Train Epoch: 23 [22000/39785 (1%)]\tLoss: 4.639333\n",
      "Train Epoch: 23 [23000/39785 (1%)]\tLoss: 4.600451\n",
      "Train Epoch: 23 [24000/39785 (1%)]\tLoss: 6.506300\n",
      "Train Epoch: 23 [25000/39785 (1%)]\tLoss: 6.356036\n",
      "Train Epoch: 23 [26000/39785 (1%)]\tLoss: 7.719636\n",
      "Train Epoch: 23 [27000/39785 (1%)]\tLoss: 6.775963\n",
      "Train Epoch: 23 [28000/39785 (1%)]\tLoss: 5.858132\n",
      "Train Epoch: 23 [29000/39785 (1%)]\tLoss: 7.224359\n",
      "Train Epoch: 23 [30000/39785 (1%)]\tLoss: 5.066690\n",
      "Train Epoch: 23 [31000/39785 (1%)]\tLoss: 4.941866\n",
      "Train Epoch: 23 [32000/39785 (1%)]\tLoss: 5.511324\n",
      "Train Epoch: 23 [33000/39785 (1%)]\tLoss: 5.013340\n",
      "Train Epoch: 23 [34000/39785 (1%)]\tLoss: 4.421229\n",
      "Train Epoch: 23 [35000/39785 (1%)]\tLoss: 6.289261\n",
      "Train Epoch: 23 [36000/39785 (1%)]\tLoss: 6.095030\n",
      "Train Epoch: 23 [37000/39785 (1%)]\tLoss: 5.030526\n",
      "Train Epoch: 23 [38000/39785 (1%)]\tLoss: 5.537387\n",
      "Train Epoch: 23 [39000/39785 (1%)]\tLoss: 3.963622\n",
      "Train Epoch: 24 [1000/39785 (0%)]\tLoss: 5.796663\n",
      "Train Epoch: 24 [2000/39785 (0%)]\tLoss: 4.811335\n",
      "Train Epoch: 24 [3000/39785 (0%)]\tLoss: 4.770886\n",
      "Train Epoch: 24 [4000/39785 (0%)]\tLoss: 5.160796\n",
      "Train Epoch: 24 [5000/39785 (0%)]\tLoss: 4.288039\n",
      "Train Epoch: 24 [6000/39785 (0%)]\tLoss: 4.820724\n",
      "Train Epoch: 24 [7000/39785 (0%)]\tLoss: 4.972652\n",
      "Train Epoch: 24 [8000/39785 (0%)]\tLoss: 6.487453\n",
      "Train Epoch: 24 [9000/39785 (0%)]\tLoss: 5.643666\n",
      "Train Epoch: 24 [10000/39785 (0%)]\tLoss: 4.508140\n",
      "Train Epoch: 24 [11000/39785 (0%)]\tLoss: 5.534518\n",
      "Train Epoch: 24 [12000/39785 (0%)]\tLoss: 4.322175\n",
      "Train Epoch: 24 [13000/39785 (0%)]\tLoss: 5.145354\n",
      "Train Epoch: 24 [14000/39785 (0%)]\tLoss: 5.621463\n",
      "Train Epoch: 24 [15000/39785 (0%)]\tLoss: 5.478647\n",
      "Train Epoch: 24 [16000/39785 (0%)]\tLoss: 5.686254\n",
      "Train Epoch: 24 [17000/39785 (0%)]\tLoss: 6.821760\n",
      "Train Epoch: 24 [18000/39785 (0%)]\tLoss: 4.978661\n",
      "Train Epoch: 24 [19000/39785 (0%)]\tLoss: 5.238662\n",
      "Train Epoch: 24 [20000/39785 (1%)]\tLoss: 5.752772\n",
      "Train Epoch: 24 [21000/39785 (1%)]\tLoss: 5.325283\n",
      "Train Epoch: 24 [22000/39785 (1%)]\tLoss: 4.693826\n",
      "Train Epoch: 24 [23000/39785 (1%)]\tLoss: 4.268675\n",
      "Train Epoch: 24 [24000/39785 (1%)]\tLoss: 4.501405\n",
      "Train Epoch: 24 [25000/39785 (1%)]\tLoss: 5.623064\n",
      "Train Epoch: 24 [26000/39785 (1%)]\tLoss: 5.607710\n",
      "Train Epoch: 24 [27000/39785 (1%)]\tLoss: 6.072042\n",
      "Train Epoch: 24 [28000/39785 (1%)]\tLoss: 4.935781\n",
      "Train Epoch: 24 [29000/39785 (1%)]\tLoss: 5.492764\n",
      "Train Epoch: 24 [30000/39785 (1%)]\tLoss: 4.216093\n",
      "Train Epoch: 24 [31000/39785 (1%)]\tLoss: 6.319520\n",
      "Train Epoch: 24 [32000/39785 (1%)]\tLoss: 5.308177\n",
      "Train Epoch: 24 [33000/39785 (1%)]\tLoss: 5.058271\n",
      "Train Epoch: 24 [34000/39785 (1%)]\tLoss: 5.534932\n",
      "Train Epoch: 24 [35000/39785 (1%)]\tLoss: 6.711979\n",
      "Train Epoch: 24 [36000/39785 (1%)]\tLoss: 6.774900\n",
      "Train Epoch: 24 [37000/39785 (1%)]\tLoss: 4.929388\n",
      "Train Epoch: 24 [38000/39785 (1%)]\tLoss: 7.445412\n",
      "Train Epoch: 24 [39000/39785 (1%)]\tLoss: 4.651770\n",
      "Train Epoch: 25 [1000/39785 (0%)]\tLoss: 4.793585\n",
      "Train Epoch: 25 [2000/39785 (0%)]\tLoss: 5.052901\n",
      "Train Epoch: 25 [3000/39785 (0%)]\tLoss: 4.520325\n",
      "Train Epoch: 25 [4000/39785 (0%)]\tLoss: 5.072360\n",
      "Train Epoch: 25 [5000/39785 (0%)]\tLoss: 5.632103\n",
      "Train Epoch: 25 [6000/39785 (0%)]\tLoss: 5.833802\n",
      "Train Epoch: 25 [7000/39785 (0%)]\tLoss: 4.539765\n",
      "Train Epoch: 25 [8000/39785 (0%)]\tLoss: 5.243230\n",
      "Train Epoch: 25 [9000/39785 (0%)]\tLoss: 5.258942\n",
      "Train Epoch: 25 [10000/39785 (0%)]\tLoss: 6.461611\n",
      "Train Epoch: 25 [11000/39785 (0%)]\tLoss: 6.300763\n",
      "Train Epoch: 25 [12000/39785 (0%)]\tLoss: 4.567225\n",
      "Train Epoch: 25 [13000/39785 (0%)]\tLoss: 5.439524\n",
      "Train Epoch: 25 [14000/39785 (0%)]\tLoss: 5.081326\n",
      "Train Epoch: 25 [15000/39785 (0%)]\tLoss: 5.282542\n",
      "Train Epoch: 25 [16000/39785 (0%)]\tLoss: 4.629481\n",
      "Train Epoch: 25 [17000/39785 (0%)]\tLoss: 6.417512\n",
      "Train Epoch: 25 [18000/39785 (0%)]\tLoss: 6.166517\n",
      "Train Epoch: 25 [19000/39785 (0%)]\tLoss: 4.970251\n",
      "Train Epoch: 25 [20000/39785 (1%)]\tLoss: 7.249216\n",
      "Train Epoch: 25 [21000/39785 (1%)]\tLoss: 5.000259\n",
      "Train Epoch: 25 [22000/39785 (1%)]\tLoss: 4.632485\n",
      "Train Epoch: 25 [23000/39785 (1%)]\tLoss: 4.626778\n",
      "Train Epoch: 25 [24000/39785 (1%)]\tLoss: 5.076887\n",
      "Train Epoch: 25 [25000/39785 (1%)]\tLoss: 4.486276\n",
      "Train Epoch: 25 [26000/39785 (1%)]\tLoss: 4.465942\n",
      "Train Epoch: 25 [27000/39785 (1%)]\tLoss: 3.928656\n",
      "Train Epoch: 25 [28000/39785 (1%)]\tLoss: 5.156228\n",
      "Train Epoch: 25 [29000/39785 (1%)]\tLoss: 5.174790\n",
      "Train Epoch: 25 [30000/39785 (1%)]\tLoss: 5.222019\n",
      "Train Epoch: 25 [31000/39785 (1%)]\tLoss: 4.341850\n",
      "Train Epoch: 25 [32000/39785 (1%)]\tLoss: 3.747557\n",
      "Train Epoch: 25 [33000/39785 (1%)]\tLoss: 5.007181\n",
      "Train Epoch: 25 [34000/39785 (1%)]\tLoss: 5.603913\n",
      "Train Epoch: 25 [35000/39785 (1%)]\tLoss: 3.789587\n",
      "Train Epoch: 25 [36000/39785 (1%)]\tLoss: 4.316035\n",
      "Train Epoch: 25 [37000/39785 (1%)]\tLoss: 5.709695\n",
      "Train Epoch: 25 [38000/39785 (1%)]\tLoss: 6.976552\n",
      "Train Epoch: 25 [39000/39785 (1%)]\tLoss: 4.364872\n",
      "Train Epoch: 26 [1000/39785 (0%)]\tLoss: 4.363659\n",
      "Train Epoch: 26 [2000/39785 (0%)]\tLoss: 5.792758\n",
      "Train Epoch: 26 [3000/39785 (0%)]\tLoss: 9.709709\n",
      "Train Epoch: 26 [4000/39785 (0%)]\tLoss: 3.704194\n",
      "Train Epoch: 26 [5000/39785 (0%)]\tLoss: 4.225252\n",
      "Train Epoch: 26 [6000/39785 (0%)]\tLoss: 3.950837\n",
      "Train Epoch: 26 [7000/39785 (0%)]\tLoss: 4.916121\n",
      "Train Epoch: 26 [8000/39785 (0%)]\tLoss: 3.981061\n",
      "Train Epoch: 26 [9000/39785 (0%)]\tLoss: 4.661890\n",
      "Train Epoch: 26 [10000/39785 (0%)]\tLoss: 3.541278\n",
      "Train Epoch: 26 [11000/39785 (0%)]\tLoss: 4.849256\n",
      "Train Epoch: 26 [12000/39785 (0%)]\tLoss: 5.965395\n",
      "Train Epoch: 26 [13000/39785 (0%)]\tLoss: 4.401819\n",
      "Train Epoch: 26 [14000/39785 (0%)]\tLoss: 5.864517\n",
      "Train Epoch: 26 [15000/39785 (0%)]\tLoss: 5.443764\n",
      "Train Epoch: 26 [16000/39785 (0%)]\tLoss: 3.916762\n",
      "Train Epoch: 26 [17000/39785 (0%)]\tLoss: 5.707360\n",
      "Train Epoch: 26 [18000/39785 (0%)]\tLoss: 6.964691\n",
      "Train Epoch: 26 [19000/39785 (0%)]\tLoss: 5.036254\n",
      "Train Epoch: 26 [20000/39785 (1%)]\tLoss: 4.872284\n",
      "Train Epoch: 26 [21000/39785 (1%)]\tLoss: 7.489709\n",
      "Train Epoch: 26 [22000/39785 (1%)]\tLoss: 6.436214\n",
      "Train Epoch: 26 [23000/39785 (1%)]\tLoss: 4.218987\n",
      "Train Epoch: 26 [24000/39785 (1%)]\tLoss: 4.478530\n",
      "Train Epoch: 26 [25000/39785 (1%)]\tLoss: 6.300398\n",
      "Train Epoch: 26 [26000/39785 (1%)]\tLoss: 5.184179\n",
      "Train Epoch: 26 [27000/39785 (1%)]\tLoss: 8.554482\n",
      "Train Epoch: 26 [28000/39785 (1%)]\tLoss: 5.391897\n",
      "Train Epoch: 26 [29000/39785 (1%)]\tLoss: 6.700047\n",
      "Train Epoch: 26 [30000/39785 (1%)]\tLoss: 5.305735\n",
      "Train Epoch: 26 [31000/39785 (1%)]\tLoss: 6.108054\n",
      "Train Epoch: 26 [32000/39785 (1%)]\tLoss: 5.846101\n",
      "Train Epoch: 26 [33000/39785 (1%)]\tLoss: 5.092384\n",
      "Train Epoch: 26 [34000/39785 (1%)]\tLoss: 3.617458\n",
      "Train Epoch: 26 [35000/39785 (1%)]\tLoss: 5.079686\n",
      "Train Epoch: 26 [36000/39785 (1%)]\tLoss: 5.855961\n",
      "Train Epoch: 26 [37000/39785 (1%)]\tLoss: 6.925262\n",
      "Train Epoch: 26 [38000/39785 (1%)]\tLoss: 3.764772\n",
      "Train Epoch: 26 [39000/39785 (1%)]\tLoss: 6.815624\n",
      "Train Epoch: 27 [1000/39785 (0%)]\tLoss: 4.468155\n",
      "Train Epoch: 27 [2000/39785 (0%)]\tLoss: 5.085660\n",
      "Train Epoch: 27 [3000/39785 (0%)]\tLoss: 6.477392\n",
      "Train Epoch: 27 [4000/39785 (0%)]\tLoss: 6.790807\n",
      "Train Epoch: 27 [5000/39785 (0%)]\tLoss: 4.457481\n",
      "Train Epoch: 27 [6000/39785 (0%)]\tLoss: 4.407071\n",
      "Train Epoch: 27 [7000/39785 (0%)]\tLoss: 5.612436\n",
      "Train Epoch: 27 [8000/39785 (0%)]\tLoss: 5.626621\n",
      "Train Epoch: 27 [9000/39785 (0%)]\tLoss: 4.648499\n",
      "Train Epoch: 27 [10000/39785 (0%)]\tLoss: 5.299542\n",
      "Train Epoch: 27 [11000/39785 (0%)]\tLoss: 4.728323\n",
      "Train Epoch: 27 [12000/39785 (0%)]\tLoss: 4.708334\n",
      "Train Epoch: 27 [13000/39785 (0%)]\tLoss: 4.682936\n",
      "Train Epoch: 27 [14000/39785 (0%)]\tLoss: 3.978510\n",
      "Train Epoch: 27 [15000/39785 (0%)]\tLoss: 4.826407\n",
      "Train Epoch: 27 [16000/39785 (0%)]\tLoss: 4.912545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 [17000/39785 (0%)]\tLoss: 6.703030\n",
      "Train Epoch: 27 [18000/39785 (0%)]\tLoss: 4.834484\n",
      "Train Epoch: 27 [19000/39785 (0%)]\tLoss: 5.962868\n",
      "Train Epoch: 27 [20000/39785 (1%)]\tLoss: 4.395610\n",
      "Train Epoch: 27 [21000/39785 (1%)]\tLoss: 4.678164\n",
      "Train Epoch: 27 [22000/39785 (1%)]\tLoss: 4.536694\n",
      "Train Epoch: 27 [23000/39785 (1%)]\tLoss: 5.460795\n",
      "Train Epoch: 27 [24000/39785 (1%)]\tLoss: 4.813757\n",
      "Train Epoch: 27 [25000/39785 (1%)]\tLoss: 5.027262\n",
      "Train Epoch: 27 [26000/39785 (1%)]\tLoss: 4.893330\n",
      "Train Epoch: 27 [27000/39785 (1%)]\tLoss: 4.772455\n",
      "Train Epoch: 27 [28000/39785 (1%)]\tLoss: 4.294953\n",
      "Train Epoch: 27 [29000/39785 (1%)]\tLoss: 5.553070\n",
      "Train Epoch: 27 [30000/39785 (1%)]\tLoss: 5.501843\n",
      "Train Epoch: 27 [31000/39785 (1%)]\tLoss: 4.970952\n",
      "Train Epoch: 27 [32000/39785 (1%)]\tLoss: 4.399627\n",
      "Train Epoch: 27 [33000/39785 (1%)]\tLoss: 6.837511\n",
      "Train Epoch: 27 [34000/39785 (1%)]\tLoss: 5.460639\n",
      "Train Epoch: 27 [35000/39785 (1%)]\tLoss: 5.336627\n",
      "Train Epoch: 27 [36000/39785 (1%)]\tLoss: 4.230852\n",
      "Train Epoch: 27 [37000/39785 (1%)]\tLoss: 5.628482\n",
      "Train Epoch: 27 [38000/39785 (1%)]\tLoss: 4.515171\n",
      "Train Epoch: 27 [39000/39785 (1%)]\tLoss: 4.972395\n",
      "Train Epoch: 28 [1000/39785 (0%)]\tLoss: 4.381656\n",
      "Train Epoch: 28 [2000/39785 (0%)]\tLoss: 3.560856\n",
      "Train Epoch: 28 [3000/39785 (0%)]\tLoss: 4.634864\n",
      "Train Epoch: 28 [4000/39785 (0%)]\tLoss: 4.814962\n",
      "Train Epoch: 28 [5000/39785 (0%)]\tLoss: 5.716784\n",
      "Train Epoch: 28 [6000/39785 (0%)]\tLoss: 3.765602\n",
      "Train Epoch: 28 [7000/39785 (0%)]\tLoss: 3.944946\n",
      "Train Epoch: 28 [8000/39785 (0%)]\tLoss: 3.966402\n",
      "Train Epoch: 28 [9000/39785 (0%)]\tLoss: 5.518482\n",
      "Train Epoch: 28 [10000/39785 (0%)]\tLoss: 5.641895\n",
      "Train Epoch: 28 [11000/39785 (0%)]\tLoss: 4.873379\n",
      "Train Epoch: 28 [12000/39785 (0%)]\tLoss: 4.593274\n",
      "Train Epoch: 28 [13000/39785 (0%)]\tLoss: 4.454921\n",
      "Train Epoch: 28 [14000/39785 (0%)]\tLoss: 6.062351\n",
      "Train Epoch: 28 [15000/39785 (0%)]\tLoss: 5.487926\n",
      "Train Epoch: 28 [16000/39785 (0%)]\tLoss: 3.900100\n",
      "Train Epoch: 28 [17000/39785 (0%)]\tLoss: 4.987282\n",
      "Train Epoch: 28 [18000/39785 (0%)]\tLoss: 4.518590\n",
      "Train Epoch: 28 [19000/39785 (0%)]\tLoss: 4.771930\n",
      "Train Epoch: 28 [20000/39785 (1%)]\tLoss: 4.125490\n",
      "Train Epoch: 28 [21000/39785 (1%)]\tLoss: 5.705091\n",
      "Train Epoch: 28 [22000/39785 (1%)]\tLoss: 3.583169\n",
      "Train Epoch: 28 [23000/39785 (1%)]\tLoss: 4.152105\n",
      "Train Epoch: 28 [24000/39785 (1%)]\tLoss: 4.334960\n",
      "Train Epoch: 28 [25000/39785 (1%)]\tLoss: 5.625959\n",
      "Train Epoch: 28 [26000/39785 (1%)]\tLoss: 4.065441\n",
      "Train Epoch: 28 [27000/39785 (1%)]\tLoss: 4.057720\n",
      "Train Epoch: 28 [28000/39785 (1%)]\tLoss: 5.550404\n",
      "Train Epoch: 28 [29000/39785 (1%)]\tLoss: 5.431864\n",
      "Train Epoch: 28 [30000/39785 (1%)]\tLoss: 4.329044\n",
      "Train Epoch: 28 [31000/39785 (1%)]\tLoss: 5.061804\n",
      "Train Epoch: 28 [32000/39785 (1%)]\tLoss: 4.557053\n",
      "Train Epoch: 28 [33000/39785 (1%)]\tLoss: 5.246410\n",
      "Train Epoch: 28 [34000/39785 (1%)]\tLoss: 5.056366\n",
      "Train Epoch: 28 [35000/39785 (1%)]\tLoss: 4.333203\n",
      "Train Epoch: 28 [36000/39785 (1%)]\tLoss: 4.090210\n",
      "Train Epoch: 28 [37000/39785 (1%)]\tLoss: 4.606287\n",
      "Train Epoch: 28 [38000/39785 (1%)]\tLoss: 6.539248\n",
      "Train Epoch: 28 [39000/39785 (1%)]\tLoss: 3.877353\n",
      "Train Epoch: 29 [1000/39785 (0%)]\tLoss: 2.968199\n",
      "Train Epoch: 29 [2000/39785 (0%)]\tLoss: 4.575549\n",
      "Train Epoch: 29 [3000/39785 (0%)]\tLoss: 4.959798\n",
      "Train Epoch: 29 [4000/39785 (0%)]\tLoss: 4.806987\n",
      "Train Epoch: 29 [5000/39785 (0%)]\tLoss: 4.281329\n",
      "Train Epoch: 29 [6000/39785 (0%)]\tLoss: 4.252307\n",
      "Train Epoch: 29 [7000/39785 (0%)]\tLoss: 4.147122\n",
      "Train Epoch: 29 [8000/39785 (0%)]\tLoss: 4.476912\n",
      "Train Epoch: 29 [9000/39785 (0%)]\tLoss: 3.720934\n",
      "Train Epoch: 29 [10000/39785 (0%)]\tLoss: 5.272571\n",
      "Train Epoch: 29 [11000/39785 (0%)]\tLoss: 4.894274\n",
      "Train Epoch: 29 [12000/39785 (0%)]\tLoss: 5.032410\n",
      "Train Epoch: 29 [13000/39785 (0%)]\tLoss: 5.578938\n",
      "Train Epoch: 29 [14000/39785 (0%)]\tLoss: 5.764725\n",
      "Train Epoch: 29 [15000/39785 (0%)]\tLoss: 4.635384\n",
      "Train Epoch: 29 [16000/39785 (0%)]\tLoss: 4.479449\n",
      "Train Epoch: 29 [17000/39785 (0%)]\tLoss: 3.750232\n",
      "Train Epoch: 29 [18000/39785 (0%)]\tLoss: 4.475955\n",
      "Train Epoch: 29 [19000/39785 (0%)]\tLoss: 4.238472\n",
      "Train Epoch: 29 [20000/39785 (1%)]\tLoss: 5.094443\n",
      "Train Epoch: 29 [21000/39785 (1%)]\tLoss: 5.148583\n",
      "Train Epoch: 29 [22000/39785 (1%)]\tLoss: 5.085872\n",
      "Train Epoch: 29 [23000/39785 (1%)]\tLoss: 4.284701\n",
      "Train Epoch: 29 [24000/39785 (1%)]\tLoss: 4.824966\n",
      "Train Epoch: 29 [25000/39785 (1%)]\tLoss: 3.905655\n",
      "Train Epoch: 29 [26000/39785 (1%)]\tLoss: 4.438477\n",
      "Train Epoch: 29 [27000/39785 (1%)]\tLoss: 4.487705\n",
      "Train Epoch: 29 [28000/39785 (1%)]\tLoss: 4.035639\n",
      "Train Epoch: 29 [29000/39785 (1%)]\tLoss: 4.588351\n",
      "Train Epoch: 29 [30000/39785 (1%)]\tLoss: 4.888294\n",
      "Train Epoch: 29 [31000/39785 (1%)]\tLoss: 5.766357\n",
      "Train Epoch: 29 [32000/39785 (1%)]\tLoss: 5.637740\n",
      "Train Epoch: 29 [33000/39785 (1%)]\tLoss: 6.106324\n",
      "Train Epoch: 29 [34000/39785 (1%)]\tLoss: 5.903324\n",
      "Train Epoch: 29 [35000/39785 (1%)]\tLoss: 5.387841\n",
      "Train Epoch: 29 [36000/39785 (1%)]\tLoss: 4.400264\n",
      "Train Epoch: 29 [37000/39785 (1%)]\tLoss: 3.568649\n",
      "Train Epoch: 29 [38000/39785 (1%)]\tLoss: 3.749002\n",
      "Train Epoch: 29 [39000/39785 (1%)]\tLoss: 5.352898\n",
      "Train Epoch: 30 [1000/39785 (0%)]\tLoss: 4.196721\n",
      "Train Epoch: 30 [2000/39785 (0%)]\tLoss: 4.465443\n",
      "Train Epoch: 30 [3000/39785 (0%)]\tLoss: 5.420955\n",
      "Train Epoch: 30 [4000/39785 (0%)]\tLoss: 4.146394\n",
      "Train Epoch: 30 [5000/39785 (0%)]\tLoss: 4.532179\n",
      "Train Epoch: 30 [6000/39785 (0%)]\tLoss: 4.081633\n",
      "Train Epoch: 30 [7000/39785 (0%)]\tLoss: 5.095364\n",
      "Train Epoch: 30 [8000/39785 (0%)]\tLoss: 4.373601\n",
      "Train Epoch: 30 [9000/39785 (0%)]\tLoss: 4.538093\n",
      "Train Epoch: 30 [10000/39785 (0%)]\tLoss: 5.980745\n",
      "Train Epoch: 30 [11000/39785 (0%)]\tLoss: 4.417464\n",
      "Train Epoch: 30 [12000/39785 (0%)]\tLoss: 4.120661\n",
      "Train Epoch: 30 [13000/39785 (0%)]\tLoss: 4.488091\n",
      "Train Epoch: 30 [14000/39785 (0%)]\tLoss: 5.027278\n",
      "Train Epoch: 30 [15000/39785 (0%)]\tLoss: 5.050255\n",
      "Train Epoch: 30 [16000/39785 (0%)]\tLoss: 4.701520\n",
      "Train Epoch: 30 [17000/39785 (0%)]\tLoss: 6.403455\n",
      "Train Epoch: 30 [18000/39785 (0%)]\tLoss: 4.775465\n",
      "Train Epoch: 30 [19000/39785 (0%)]\tLoss: 3.485144\n",
      "Train Epoch: 30 [20000/39785 (1%)]\tLoss: 3.564222\n",
      "Train Epoch: 30 [21000/39785 (1%)]\tLoss: 5.796464\n",
      "Train Epoch: 30 [22000/39785 (1%)]\tLoss: 5.214216\n",
      "Train Epoch: 30 [23000/39785 (1%)]\tLoss: 6.134292\n",
      "Train Epoch: 30 [24000/39785 (1%)]\tLoss: 4.759794\n",
      "Train Epoch: 30 [25000/39785 (1%)]\tLoss: 4.847731\n",
      "Train Epoch: 30 [26000/39785 (1%)]\tLoss: 4.969850\n",
      "Train Epoch: 30 [27000/39785 (1%)]\tLoss: 4.532294\n",
      "Train Epoch: 30 [28000/39785 (1%)]\tLoss: 4.760240\n",
      "Train Epoch: 30 [29000/39785 (1%)]\tLoss: 4.493418\n",
      "Train Epoch: 30 [30000/39785 (1%)]\tLoss: 4.805340\n",
      "Train Epoch: 30 [31000/39785 (1%)]\tLoss: 4.316317\n",
      "Train Epoch: 30 [32000/39785 (1%)]\tLoss: 4.431033\n",
      "Train Epoch: 30 [33000/39785 (1%)]\tLoss: 4.499670\n",
      "Train Epoch: 30 [34000/39785 (1%)]\tLoss: 4.885448\n",
      "Train Epoch: 30 [35000/39785 (1%)]\tLoss: 4.556095\n",
      "Train Epoch: 30 [36000/39785 (1%)]\tLoss: 5.309814\n",
      "Train Epoch: 30 [37000/39785 (1%)]\tLoss: 4.796640\n",
      "Train Epoch: 30 [38000/39785 (1%)]\tLoss: 4.701987\n",
      "Train Epoch: 30 [39000/39785 (1%)]\tLoss: 4.269050\n",
      "Train Epoch: 31 [1000/39785 (0%)]\tLoss: 4.450704\n",
      "Train Epoch: 31 [2000/39785 (0%)]\tLoss: 4.143466\n",
      "Train Epoch: 31 [3000/39785 (0%)]\tLoss: 3.781358\n",
      "Train Epoch: 31 [4000/39785 (0%)]\tLoss: 4.907699\n",
      "Train Epoch: 31 [5000/39785 (0%)]\tLoss: 4.534523\n",
      "Train Epoch: 31 [6000/39785 (0%)]\tLoss: 5.276743\n",
      "Train Epoch: 31 [7000/39785 (0%)]\tLoss: 4.981934\n",
      "Train Epoch: 31 [8000/39785 (0%)]\tLoss: 4.168896\n",
      "Train Epoch: 31 [9000/39785 (0%)]\tLoss: 4.530909\n",
      "Train Epoch: 31 [10000/39785 (0%)]\tLoss: 4.239709\n",
      "Train Epoch: 31 [11000/39785 (0%)]\tLoss: 4.194616\n",
      "Train Epoch: 31 [12000/39785 (0%)]\tLoss: 5.134305\n",
      "Train Epoch: 31 [13000/39785 (0%)]\tLoss: 4.492249\n",
      "Train Epoch: 31 [14000/39785 (0%)]\tLoss: 3.080183\n",
      "Train Epoch: 31 [15000/39785 (0%)]\tLoss: 4.063367\n",
      "Train Epoch: 31 [16000/39785 (0%)]\tLoss: 5.383777\n",
      "Train Epoch: 31 [17000/39785 (0%)]\tLoss: 5.405928\n",
      "Train Epoch: 31 [18000/39785 (0%)]\tLoss: 3.641872\n",
      "Train Epoch: 31 [19000/39785 (0%)]\tLoss: 4.722543\n",
      "Train Epoch: 31 [20000/39785 (1%)]\tLoss: 5.207073\n",
      "Train Epoch: 31 [21000/39785 (1%)]\tLoss: 2.856531\n",
      "Train Epoch: 31 [22000/39785 (1%)]\tLoss: 4.079458\n",
      "Train Epoch: 31 [23000/39785 (1%)]\tLoss: 4.989333\n",
      "Train Epoch: 31 [24000/39785 (1%)]\tLoss: 5.090047\n",
      "Train Epoch: 31 [25000/39785 (1%)]\tLoss: 4.710229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31 [26000/39785 (1%)]\tLoss: 4.051652\n",
      "Train Epoch: 31 [27000/39785 (1%)]\tLoss: 3.571855\n",
      "Train Epoch: 31 [28000/39785 (1%)]\tLoss: 3.602245\n",
      "Train Epoch: 31 [29000/39785 (1%)]\tLoss: 5.301577\n",
      "Train Epoch: 31 [30000/39785 (1%)]\tLoss: 5.108009\n",
      "Train Epoch: 31 [31000/39785 (1%)]\tLoss: 6.239379\n",
      "Train Epoch: 31 [32000/39785 (1%)]\tLoss: 4.565140\n",
      "Train Epoch: 31 [33000/39785 (1%)]\tLoss: 4.261871\n",
      "Train Epoch: 31 [34000/39785 (1%)]\tLoss: 3.754645\n",
      "Train Epoch: 31 [35000/39785 (1%)]\tLoss: 4.443115\n",
      "Train Epoch: 31 [36000/39785 (1%)]\tLoss: 5.882146\n",
      "Train Epoch: 31 [37000/39785 (1%)]\tLoss: 6.626326\n",
      "Train Epoch: 31 [38000/39785 (1%)]\tLoss: 4.204153\n",
      "Train Epoch: 31 [39000/39785 (1%)]\tLoss: 4.405591\n",
      "Train Epoch: 32 [1000/39785 (0%)]\tLoss: 4.633092\n",
      "Train Epoch: 32 [2000/39785 (0%)]\tLoss: 3.043011\n",
      "Train Epoch: 32 [3000/39785 (0%)]\tLoss: 5.957927\n",
      "Train Epoch: 32 [4000/39785 (0%)]\tLoss: 3.669952\n",
      "Train Epoch: 32 [5000/39785 (0%)]\tLoss: 3.747842\n",
      "Train Epoch: 32 [6000/39785 (0%)]\tLoss: 3.779496\n",
      "Train Epoch: 32 [7000/39785 (0%)]\tLoss: 3.812466\n",
      "Train Epoch: 32 [8000/39785 (0%)]\tLoss: 6.036455\n",
      "Train Epoch: 32 [9000/39785 (0%)]\tLoss: 4.415403\n",
      "Train Epoch: 32 [10000/39785 (0%)]\tLoss: 6.326968\n",
      "Train Epoch: 32 [11000/39785 (0%)]\tLoss: 4.470299\n",
      "Train Epoch: 32 [12000/39785 (0%)]\tLoss: 4.661187\n",
      "Train Epoch: 32 [13000/39785 (0%)]\tLoss: 4.704477\n",
      "Train Epoch: 32 [14000/39785 (0%)]\tLoss: 3.974143\n",
      "Train Epoch: 32 [15000/39785 (0%)]\tLoss: 4.475971\n",
      "Train Epoch: 32 [16000/39785 (0%)]\tLoss: 4.077319\n",
      "Train Epoch: 32 [17000/39785 (0%)]\tLoss: 3.436121\n",
      "Train Epoch: 32 [18000/39785 (0%)]\tLoss: 4.494975\n",
      "Train Epoch: 32 [19000/39785 (0%)]\tLoss: 5.027215\n",
      "Train Epoch: 32 [20000/39785 (1%)]\tLoss: 4.276015\n",
      "Train Epoch: 32 [21000/39785 (1%)]\tLoss: 4.980912\n",
      "Train Epoch: 32 [22000/39785 (1%)]\tLoss: 3.965933\n",
      "Train Epoch: 32 [23000/39785 (1%)]\tLoss: 4.744043\n",
      "Train Epoch: 32 [24000/39785 (1%)]\tLoss: 4.239023\n",
      "Train Epoch: 32 [25000/39785 (1%)]\tLoss: 4.303730\n",
      "Train Epoch: 32 [26000/39785 (1%)]\tLoss: 4.689253\n",
      "Train Epoch: 32 [27000/39785 (1%)]\tLoss: 4.277048\n",
      "Train Epoch: 32 [28000/39785 (1%)]\tLoss: 4.089064\n",
      "Train Epoch: 32 [29000/39785 (1%)]\tLoss: 3.385240\n",
      "Train Epoch: 32 [30000/39785 (1%)]\tLoss: 3.989823\n",
      "Train Epoch: 32 [31000/39785 (1%)]\tLoss: 7.530203\n",
      "Train Epoch: 32 [32000/39785 (1%)]\tLoss: 4.719702\n",
      "Train Epoch: 32 [33000/39785 (1%)]\tLoss: 5.152167\n",
      "Train Epoch: 32 [34000/39785 (1%)]\tLoss: 3.617435\n",
      "Train Epoch: 32 [35000/39785 (1%)]\tLoss: 4.475263\n",
      "Train Epoch: 32 [36000/39785 (1%)]\tLoss: 5.082574\n",
      "Train Epoch: 32 [37000/39785 (1%)]\tLoss: 4.219529\n",
      "Train Epoch: 32 [38000/39785 (1%)]\tLoss: 4.257414\n",
      "Train Epoch: 32 [39000/39785 (1%)]\tLoss: 5.027863\n",
      "Train Epoch: 33 [1000/39785 (0%)]\tLoss: 4.357462\n",
      "Train Epoch: 33 [2000/39785 (0%)]\tLoss: 4.850965\n",
      "Train Epoch: 33 [3000/39785 (0%)]\tLoss: 4.590512\n",
      "Train Epoch: 33 [4000/39785 (0%)]\tLoss: 5.762409\n",
      "Train Epoch: 33 [5000/39785 (0%)]\tLoss: 4.795365\n",
      "Train Epoch: 33 [6000/39785 (0%)]\tLoss: 3.606135\n",
      "Train Epoch: 33 [7000/39785 (0%)]\tLoss: 3.473573\n",
      "Train Epoch: 33 [8000/39785 (0%)]\tLoss: 3.700628\n",
      "Train Epoch: 33 [9000/39785 (0%)]\tLoss: 4.274387\n",
      "Train Epoch: 33 [10000/39785 (0%)]\tLoss: 3.984100\n",
      "Train Epoch: 33 [11000/39785 (0%)]\tLoss: 4.544491\n",
      "Train Epoch: 33 [12000/39785 (0%)]\tLoss: 3.500108\n",
      "Train Epoch: 33 [13000/39785 (0%)]\tLoss: 5.186056\n",
      "Train Epoch: 33 [14000/39785 (0%)]\tLoss: 3.980556\n",
      "Train Epoch: 33 [15000/39785 (0%)]\tLoss: 3.279860\n",
      "Train Epoch: 33 [16000/39785 (0%)]\tLoss: 3.924255\n",
      "Train Epoch: 33 [17000/39785 (0%)]\tLoss: 5.175178\n",
      "Train Epoch: 33 [18000/39785 (0%)]\tLoss: 3.767725\n",
      "Train Epoch: 33 [19000/39785 (0%)]\tLoss: 4.337921\n",
      "Train Epoch: 33 [20000/39785 (1%)]\tLoss: 3.893239\n",
      "Train Epoch: 33 [21000/39785 (1%)]\tLoss: 3.995478\n",
      "Train Epoch: 33 [22000/39785 (1%)]\tLoss: 4.881893\n",
      "Train Epoch: 33 [23000/39785 (1%)]\tLoss: 4.112467\n",
      "Train Epoch: 33 [24000/39785 (1%)]\tLoss: 3.869216\n",
      "Train Epoch: 33 [25000/39785 (1%)]\tLoss: 4.800406\n",
      "Train Epoch: 33 [26000/39785 (1%)]\tLoss: 4.368042\n",
      "Train Epoch: 33 [27000/39785 (1%)]\tLoss: 5.466326\n",
      "Train Epoch: 33 [28000/39785 (1%)]\tLoss: 3.499833\n",
      "Train Epoch: 33 [29000/39785 (1%)]\tLoss: 4.155709\n",
      "Train Epoch: 33 [30000/39785 (1%)]\tLoss: 4.383084\n",
      "Train Epoch: 33 [31000/39785 (1%)]\tLoss: 4.834481\n",
      "Train Epoch: 33 [32000/39785 (1%)]\tLoss: 4.075020\n",
      "Train Epoch: 33 [33000/39785 (1%)]\tLoss: 5.797853\n",
      "Train Epoch: 33 [34000/39785 (1%)]\tLoss: 5.763571\n",
      "Train Epoch: 33 [35000/39785 (1%)]\tLoss: 5.669532\n",
      "Train Epoch: 33 [36000/39785 (1%)]\tLoss: 5.328696\n",
      "Train Epoch: 33 [37000/39785 (1%)]\tLoss: 5.572464\n",
      "Train Epoch: 33 [38000/39785 (1%)]\tLoss: 4.230877\n",
      "Train Epoch: 33 [39000/39785 (1%)]\tLoss: 4.351266\n",
      "Train Epoch: 34 [1000/39785 (0%)]\tLoss: 3.797591\n",
      "Train Epoch: 34 [2000/39785 (0%)]\tLoss: 4.694949\n",
      "Train Epoch: 34 [3000/39785 (0%)]\tLoss: 3.811472\n",
      "Train Epoch: 34 [4000/39785 (0%)]\tLoss: 4.398731\n",
      "Train Epoch: 34 [5000/39785 (0%)]\tLoss: 4.245029\n",
      "Train Epoch: 34 [6000/39785 (0%)]\tLoss: 3.752484\n",
      "Train Epoch: 34 [7000/39785 (0%)]\tLoss: 3.504555\n",
      "Train Epoch: 34 [8000/39785 (0%)]\tLoss: 4.367217\n",
      "Train Epoch: 34 [9000/39785 (0%)]\tLoss: 4.927485\n",
      "Train Epoch: 34 [10000/39785 (0%)]\tLoss: 3.734233\n",
      "Train Epoch: 34 [11000/39785 (0%)]\tLoss: 4.072984\n",
      "Train Epoch: 34 [12000/39785 (0%)]\tLoss: 3.660247\n",
      "Train Epoch: 34 [13000/39785 (0%)]\tLoss: 3.807989\n",
      "Train Epoch: 34 [14000/39785 (0%)]\tLoss: 4.184129\n",
      "Train Epoch: 34 [15000/39785 (0%)]\tLoss: 4.018091\n",
      "Train Epoch: 34 [16000/39785 (0%)]\tLoss: 3.148893\n",
      "Train Epoch: 34 [17000/39785 (0%)]\tLoss: 4.901395\n",
      "Train Epoch: 34 [18000/39785 (0%)]\tLoss: 3.425868\n",
      "Train Epoch: 34 [19000/39785 (0%)]\tLoss: 3.970985\n",
      "Train Epoch: 34 [20000/39785 (1%)]\tLoss: 2.979243\n",
      "Train Epoch: 34 [21000/39785 (1%)]\tLoss: 4.251493\n",
      "Train Epoch: 34 [22000/39785 (1%)]\tLoss: 2.947081\n",
      "Train Epoch: 34 [23000/39785 (1%)]\tLoss: 3.242059\n",
      "Train Epoch: 34 [24000/39785 (1%)]\tLoss: 3.588527\n",
      "Train Epoch: 34 [25000/39785 (1%)]\tLoss: 3.939424\n",
      "Train Epoch: 34 [26000/39785 (1%)]\tLoss: 4.528444\n",
      "Train Epoch: 34 [27000/39785 (1%)]\tLoss: 4.965109\n",
      "Train Epoch: 34 [28000/39785 (1%)]\tLoss: 5.166018\n",
      "Train Epoch: 34 [29000/39785 (1%)]\tLoss: 3.997442\n",
      "Train Epoch: 34 [30000/39785 (1%)]\tLoss: 5.812097\n",
      "Train Epoch: 34 [31000/39785 (1%)]\tLoss: 5.249135\n",
      "Train Epoch: 34 [32000/39785 (1%)]\tLoss: 5.025104\n",
      "Train Epoch: 34 [33000/39785 (1%)]\tLoss: 4.811332\n",
      "Train Epoch: 34 [34000/39785 (1%)]\tLoss: 4.864338\n",
      "Train Epoch: 34 [35000/39785 (1%)]\tLoss: 4.075364\n",
      "Train Epoch: 34 [36000/39785 (1%)]\tLoss: 4.867663\n",
      "Train Epoch: 34 [37000/39785 (1%)]\tLoss: 4.140265\n",
      "Train Epoch: 34 [38000/39785 (1%)]\tLoss: 4.848523\n",
      "Train Epoch: 34 [39000/39785 (1%)]\tLoss: 4.195976\n",
      "Train Epoch: 35 [1000/39785 (0%)]\tLoss: 3.668621\n",
      "Train Epoch: 35 [2000/39785 (0%)]\tLoss: 4.503436\n",
      "Train Epoch: 35 [3000/39785 (0%)]\tLoss: 3.320354\n",
      "Train Epoch: 35 [4000/39785 (0%)]\tLoss: 4.662387\n",
      "Train Epoch: 35 [5000/39785 (0%)]\tLoss: 2.977511\n",
      "Train Epoch: 35 [6000/39785 (0%)]\tLoss: 4.967051\n",
      "Train Epoch: 35 [7000/39785 (0%)]\tLoss: 4.450245\n",
      "Train Epoch: 35 [8000/39785 (0%)]\tLoss: 3.982722\n",
      "Train Epoch: 35 [9000/39785 (0%)]\tLoss: 3.818591\n",
      "Train Epoch: 35 [10000/39785 (0%)]\tLoss: 5.138628\n",
      "Train Epoch: 35 [11000/39785 (0%)]\tLoss: 3.081382\n",
      "Train Epoch: 35 [12000/39785 (0%)]\tLoss: 5.227161\n",
      "Train Epoch: 35 [13000/39785 (0%)]\tLoss: 3.925133\n",
      "Train Epoch: 35 [14000/39785 (0%)]\tLoss: 4.795171\n",
      "Train Epoch: 35 [15000/39785 (0%)]\tLoss: 4.101618\n",
      "Train Epoch: 35 [16000/39785 (0%)]\tLoss: 3.514553\n",
      "Train Epoch: 35 [17000/39785 (0%)]\tLoss: 4.175636\n",
      "Train Epoch: 35 [18000/39785 (0%)]\tLoss: 4.679830\n",
      "Train Epoch: 35 [19000/39785 (0%)]\tLoss: 4.790760\n",
      "Train Epoch: 35 [20000/39785 (1%)]\tLoss: 4.125418\n",
      "Train Epoch: 35 [21000/39785 (1%)]\tLoss: 3.644914\n",
      "Train Epoch: 35 [22000/39785 (1%)]\tLoss: 3.517538\n",
      "Train Epoch: 35 [23000/39785 (1%)]\tLoss: 4.697736\n",
      "Train Epoch: 35 [24000/39785 (1%)]\tLoss: 5.407072\n",
      "Train Epoch: 35 [25000/39785 (1%)]\tLoss: 4.211931\n",
      "Train Epoch: 35 [26000/39785 (1%)]\tLoss: 4.525073\n",
      "Train Epoch: 35 [27000/39785 (1%)]\tLoss: 3.599696\n",
      "Train Epoch: 35 [28000/39785 (1%)]\tLoss: 3.413481\n",
      "Train Epoch: 35 [29000/39785 (1%)]\tLoss: 4.568805\n",
      "Train Epoch: 35 [30000/39785 (1%)]\tLoss: 4.677474\n",
      "Train Epoch: 35 [31000/39785 (1%)]\tLoss: 4.290578\n",
      "Train Epoch: 35 [32000/39785 (1%)]\tLoss: 3.609630\n",
      "Train Epoch: 35 [33000/39785 (1%)]\tLoss: 4.343777\n",
      "Train Epoch: 35 [34000/39785 (1%)]\tLoss: 4.873757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 35 [35000/39785 (1%)]\tLoss: 4.379299\n",
      "Train Epoch: 35 [36000/39785 (1%)]\tLoss: 3.716275\n",
      "Train Epoch: 35 [37000/39785 (1%)]\tLoss: 4.543982\n",
      "Train Epoch: 35 [38000/39785 (1%)]\tLoss: 4.471198\n",
      "Train Epoch: 35 [39000/39785 (1%)]\tLoss: 4.058135\n",
      "Train Epoch: 36 [1000/39785 (0%)]\tLoss: 3.643576\n",
      "Train Epoch: 36 [2000/39785 (0%)]\tLoss: 3.249705\n",
      "Train Epoch: 36 [3000/39785 (0%)]\tLoss: 4.175546\n",
      "Train Epoch: 36 [4000/39785 (0%)]\tLoss: 3.697476\n",
      "Train Epoch: 36 [5000/39785 (0%)]\tLoss: 3.509823\n",
      "Train Epoch: 36 [6000/39785 (0%)]\tLoss: 3.326844\n",
      "Train Epoch: 36 [7000/39785 (0%)]\tLoss: 3.856164\n",
      "Train Epoch: 36 [8000/39785 (0%)]\tLoss: 4.578734\n",
      "Train Epoch: 36 [9000/39785 (0%)]\tLoss: 4.721083\n",
      "Train Epoch: 36 [10000/39785 (0%)]\tLoss: 3.614054\n",
      "Train Epoch: 36 [11000/39785 (0%)]\tLoss: 3.959548\n",
      "Train Epoch: 36 [12000/39785 (0%)]\tLoss: 5.391181\n",
      "Train Epoch: 36 [13000/39785 (0%)]\tLoss: 4.949510\n",
      "Train Epoch: 36 [14000/39785 (0%)]\tLoss: 4.290684\n",
      "Train Epoch: 36 [15000/39785 (0%)]\tLoss: 5.702629\n",
      "Train Epoch: 36 [16000/39785 (0%)]\tLoss: 4.050321\n",
      "Train Epoch: 36 [17000/39785 (0%)]\tLoss: 4.196877\n",
      "Train Epoch: 36 [18000/39785 (0%)]\tLoss: 4.071764\n",
      "Train Epoch: 36 [19000/39785 (0%)]\tLoss: 4.228588\n",
      "Train Epoch: 36 [20000/39785 (1%)]\tLoss: 3.806073\n",
      "Train Epoch: 36 [21000/39785 (1%)]\tLoss: 5.176401\n",
      "Train Epoch: 36 [22000/39785 (1%)]\tLoss: 4.118052\n",
      "Train Epoch: 36 [23000/39785 (1%)]\tLoss: 4.132944\n",
      "Train Epoch: 36 [24000/39785 (1%)]\tLoss: 3.820404\n",
      "Train Epoch: 36 [25000/39785 (1%)]\tLoss: 5.039594\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(1)\n",
    "\n",
    "model_tenth_order = EquiNet().to(device)\n",
    "learning_rate = 5e-3\n",
    "optimizer = torch.optim.Adam(model_tenth_order.parameters(), lr=learning_rate)\n",
    "\n",
    "per_epoch = 10\n",
    "decr_rate = 0.995\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model_tenth_order, device, train_set, batch_size, optimizer, epoch, per_epoch, decr_rate)\n",
    "    # test(model_hard, device, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_test = model_tenth_order(torch.from_numpy(test_set._images[:100].reshape(batch_size,1,24,24,24)).type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(answer_test[i][:NUM_CLASSES])\n",
    "    print(torch.argmax(answer_test[i][:NUM_CLASSES]), answer_test[i][NUM_CLASSES:].data.tolist())\n",
    "    print(test_set._labels[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
